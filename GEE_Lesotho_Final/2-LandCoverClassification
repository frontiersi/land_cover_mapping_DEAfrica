// ****************************************************************************************************************** //
// ************************* 2. Automatic Land Cover Production Workbench - Lesotho ********************************* //
// ****************************************************************************************************************** //
// This workbench performs the Random Forest Classification of Land Cover for Lesotho, for a specified year

var params = require('users/ocsgeospatial/Lesotho:6-Parameters.js');
var legend_utils = require('users/ocsgeospatial/Lesotho:8-LegendUtils.js');
var LCParams = params.LCParams();

// Input data parameters for the land cover classification
// ****************************************************************************************************************** //
var ALGO = LCParams['ALGO']; // Algorithm to apply. Default is Random Forest, as sufficient training data is available for 2021.
var CLASS_NAME = LCParams['CLASS_NAME']; // Property name of the feature collection containing the crop type class attribute
var AGG_INTERVAL = LCParams['AGG_INTERVAL']; // Number of days to use to create the temporal composite for 2020
var S2_BAND_LIST = LCParams['BAND_LIST']; // S2 Bands to use as DTW input
//var S1_BAND_LIST = ['VV', 'VH', 'VVVH_ratio']; // In case Sentinel-1 is also used, needs to be uncommented
var BAND_NO = S2_BAND_LIST
              //.concat(S1_BAND_LIST) 
              .length; // Number of bands to use for the DTW. Currently,
var VERSION_NO = LCParams['VERSION_NO']; // Version number of the land cover outputs produced

// A dictionary that will be iterated over for multi-year land cover mapping.
// Comment out the years you do not wish to produce.
var year_dict = LCParams['LC_YEARS'];
// ****************************************************************************************************************** //

// Country Geometry
var county = ee.Feature(ee.FeatureCollection("users/ocsgeospatial/Lesotho/lesotho_boundaries").first()).simplify(100);

// Class list
var lc_classes = LCParams['LC_CLASSES'];
// The corresponding color hex keys for the land cover classes
var classification_palette = LCParams['LC_PALETTE'];

// ****************************************************************************************************************** //

// DTW-specific time parameters for the land cover classification
// ****************************************************************************************************************** //
var TIMESERIES_LEN = 6; // Number of timestamps in the time series
var PATTERNS_LEN = 6; // Number of timestamps for the reference data points
var BETA = 50; // Beta parameter for the Time-Weighted DTW, controlling the tolerance (in days) of the weighting.
var ALPHA = 0.1; // ALPHA parameter for the Time-Weighted DTW, controlling steepness of the logistic distribution
// ****************************************************************************************************************** //

// Import external dependencies
var palettes = require('users/gena/packages:palettes');
var wrapper = require('users/adugnagirma/gee_s1_ard:wrapper');
var S2Masks = require('users/ocsgeospatial/functions:s2_masks.js');
var composites = require('users/ocsgeospatial/functions:composites.js');

// Import the Dynamic Time Warping script
var DTW = require('users/ocsgeospatial/functions:dtw.js');

// Import external water mask dataset
var not_water = ee.Image("JRC/GSW1_2/GlobalSurfaceWater").select('max_extent').eq(0); // JRC Global Surface Water mask

// Import ALOS AW3D30 latest DEM version v3.2
//var dem = ee.Image("USGS/SRTMGL1_003");
var dem = ee.ImageCollection("projects/sat-io/open-datasets/FABDEM").mosaic();

//Remove mountain areas that are not suitable for crop growth
var slope = ee.Terrain.slope(dem); // Calculate slope from the DEM data
var dem_mask = dem.lt(3600); // Mask elevation above 3600m, where no crops grow.
var slope_mask = slope.lt(30); // Mask slopes steeper than 30Â°, where no crops grow.
var crop_mask = dem_mask.and(slope_mask); // Combine the two conditions

// Function to calculate the NDVI for planet mosaics
var addNDVI = function(img){
  return img.addBands(img.normalizedDifference(['B8','B4']).multiply(10000).toInt16().rename('NDVI'));
};

// Center map on the county and plot it on the map
Map.centerObject(county.geometry());
Map.layers().reset([ui.Map.Layer(county, {}, 'Lesotho')]);

// Apply land cover color scheme to reference data to plot them in their respective colors on the map
var setPointProperties = function(f){
  var class_val = f.get(CLASS_NAME);
  var mapDisplayColors = ee.List(classification_palette);

  // use the class as index to lookup the corresponding display color
  return f.set({style: {color: mapDisplayColors.get(ee.Number(class_val).subtract(1))}})
}

// Function that performs DTW land classification for a given year.
var DTWClassification = function(year, collection_type){
 
  // Load training data for a given year
  var signatures = ee.FeatureCollection('users/ocsgeospatial/Lesotho/trainingData'+year);
                                                                       
  var withRandom = signatures.randomColumn('random'); // Add a random column for train/test splitting
  
  // 80/20 train/test split
  var val_signatures = withRandom.filter(ee.Filter.and(ee.Filter.gte('random', 0), ee.Filter.lt('random', 0.2)))
  var train_signatures = withRandom.filter(ee.Filter.or(ee.Filter.lt('random', 0), ee.Filter.gte('random', 0.2)));
  
  // Pull forest, wetland and grassland classes apart as they are over-represented
  var train_signatures_forest = train_signatures.filter(ee.Filter.eq(CLASS_NAME, 4)).randomColumn('random');
  var train_signatures_wetland = train_signatures.filter(ee.Filter.eq(CLASS_NAME, 7)).randomColumn('random');
  var train_signatures_grassland = train_signatures.filter(ee.Filter.eq(CLASS_NAME, 10)).randomColumn('random');
  
  var train_signatures_len = train_signatures.size();
  
  //Limit their quantity to 100, 100 and 600 for forest, wetland and grassland respectively for training (to maintain a class balance)
  var val_signatures_forest = train_signatures_forest.sort('random', false).limit(train_signatures_len.subtract(100));
  var val_signatures_wetland = train_signatures_wetland.sort('random', false).limit(train_signatures_len.subtract(100));
  var val_signatures_grassland = train_signatures_grassland.sort('random', false).limit(train_signatures_len.subtract(600));
  train_signatures_forest = train_signatures_forest.sort('random').limit(100);
  train_signatures_wetland = train_signatures_wetland.sort('random').limit(100);
  train_signatures_grassland = train_signatures_grassland.sort('random').limit(600);
  
  // Merge the training and validation datasets back together
  train_signatures = train_signatures.filter(ee.Filter.inList(CLASS_NAME, [4, 7, 10]).not())
       .merge(train_signatures_forest)
       .merge(train_signatures_wetland)
       .merge(train_signatures_grassland);
  val_signatures = val_signatures
       .merge(val_signatures_forest)
       .merge(val_signatures_wetland)
       .merge(val_signatures_grassland);

  // Create a dictionary mapping land cover class to number of reference signatures per sample
  var reference_signatures_agg = train_signatures.aggregate_histogram(CLASS_NAME);
  
  // Add a summary chart.
  var training_data_chart = ui.Chart.array.values({
    array: ee.Dictionary(reference_signatures_agg).values(['1','2','4','6','7','9','10','12']), 
    axis: 0, 
    xLabels: ['Built-up', 'Cropland', 'Trees', 'Water Body', 'Wetland',
             'Shrubland', 'Grassland', 'Bare Surfaces']})
    .setChartType('ColumnChart')        
    .setOptions({
      title: 'Training data distribution',
      width: 200,
      height: 400,
      textPosition: "in",
      hAxis: {title: 'Classes', textStyle: {fontSize: 13}},
      vAxis: {title: 'Number of Points'},
      colors: classification_palette,
      sliceVisibilityThreshold: 0, // Don't group small slices.
    });
  print(training_data_chart);
  
  // apply the function and view the results on map
  var styled_td_train = train_signatures.map(setPointProperties);
  var styled_td_val = val_signatures.map(setPointProperties);
  
  // Add reference sample points location to the map with the appropriate color legend
  Map.addLayer(styled_td_train.style({styleProperty: "style"}), {}, 'land cover training points ' + year);
  Map.addLayer(styled_td_train.style({styleProperty: "style"}), {}, 'land cover validation points ' + year);

  var date_range = ee.Dictionary({'start': year +'-01-01', 'end': year + '-12-31'}); // Second half of year used only.
  // Load the Sentinel-2 collection for the time period and area requested
  var s2_cl = S2Masks.loadImageCollection(collection_type, date_range, county.geometry());

  // Perform cloud masking using the S2 cloud probabilities assets from s2cloudless,
  // courtesy of Sentinelhub/EU/Copernicus/ESA
  var masked_collection = s2_cl
                          .filterDate(date_range.get('start'), date_range.get('end'))
                          .map(S2Masks.addCloudShadowMask(not_water, 1e4))
                          .map(S2Masks.applyCloudShadowMask)
                          .map(addNDVI); // Add NDVI to band list

  // Generate a list of time intervals for which to generate a harmonized time series
  var time_intervals = composites.extractTimeRanges(date_range.get('start'), date_range.get('end'), AGG_INTERVAL);
  
  // Generate harmonized monthly time series of FCover as input to the vegetation factor V
  var s2_ts = composites.harmonizedTS(masked_collection, S2_BAND_LIST, time_intervals, {agg_type: 'geomedian'});

  // Replace masked pixels by the mean of the previous and next timestamps
  // And add a Day of Year (DOY) band
  // This is the linear interpolation approach,
  // which is more lightweight than other gap-filling approaches like Savitzky-Golay or harmonic regression
  var s2_stack = ee.Image(s2_ts
                          .map(function(image){
                            var currentDate = ee.Date(image.get('system:time_start'));
                            var meanImage = s2_ts.filterDate(currentDate.advance(-AGG_INTERVAL-1, 'day'),
                                                                 currentDate.advance(AGG_INTERVAL+1, 'day')).mean();
                            // replace all masked values
                            var ddiff = currentDate.difference(ee.Date(ee.String(date_range.get('start'))), 'day');
                            return meanImage.where(image, image).addBands(ee.Image(ddiff).rename('doy').toInt16());
                          })
                          .iterate(function(image, previous){return ee.Image(previous).addBands(image)}, ee.Image([])));
  
  /* //Commenting out the Sentinel-1 input generation. Only Sentinel-2 used for lesotho, mostly due to mountainous landscapes
     // Foreshortening effects are likely to occur over steep terrain
  // Define S1 preprocessing parameters, as per:
  // Version: v1.2
  // Date: 2021-03-10
  // Authors: Mullissa A., Vollrath A., Braun, C., Slagter B., Balling J., Gou Y., Gorelick N.,  Reiche J.
  // Sentinel-1 SAR Backscatter Analysis Ready Data Preparation in Google Earth Engine. Remote Sensing 13.10 (2021): 1954.
  // Description: This script creates an analysis ready S1 image collection.
  // License: This code is distributed under the MIT License.
  var parameter = {//1. Data Selection
                   START_DATE: date_range.get('start'),
                   STOP_DATE: date_range.get('end'),
                   POLARIZATION:'VVVH', // The polarization available may differ depending on where you are on the globe
                   ORBIT : 'ASCENDING', // The orbit availability may differ depending on where you are on the globe
                   // Check out this page to find out what parameters suit your area:
                   // https://sentinels.copernicus.eu/web/sentinel/missions/sentinel-1/observation-scenario
                   GEOMETRY: county.geometry(),
                   //2. Additional Border noise correction
                   APPLY_ADDITIONAL_BORDER_NOISE_CORRECTION: true,
                   //3.Speckle filter
                   APPLY_SPECKLE_FILTERING: true,
                   SPECKLE_FILTER_FRAMEWORK: 'MULTI',
                   SPECKLE_FILTER: 'LEE',
                   SPECKLE_FILTER_KERNEL_SIZE: 9,
                   SPECKLE_FILTER_NR_OF_IMAGES: 10,
                   //4. Radiometric terrain normalization
                   APPLY_TERRAIN_FLATTENING: true,
                   DEM: dem,
                   TERRAIN_FLATTENING_MODEL: 'VOLUME', // More desirable for vegetation monitoring.
                                                       //Use "SURFACE" if working on urban or bare soil applications
                   TERRAIN_FLATTENING_ADDITIONAL_LAYOVER_SHADOW_BUFFER: 0,
                   //5. Output
                   FORMAT : 'DB',
                   CLIP_TO_ROI: false,
                   SAVE_ASSETS: false
  }

  //Preprocess the S1 collection
  var s1_ts = wrapper.s1_preproc(parameter)[1]
              .map(function(image){return image.multiply(1e4).toInt16() // Convert to Int16 using 10000 scaling factor
                                          .set({'system:time_start': image.get('system:time_start')})});

  // Create equally-spaced temporal composites covering the date range and convert to multi-band image
  var s1_stack = ee.Image(composites.harmonizedTS(s1_ts, S1_BAND_LIST, time_intervals, {agg_type: 'geomedian'})
                          .iterate(function(image, previous){return ee.Image(previous).addBands(image)}, ee.Image([])));
                    
  // Re-order the stack order before converting it to a DTW-ready input array
  var s1s2_stack = s2_stack.addBands(s1_stack)
                   .select(ee.List(S2_BAND_LIST.concat(S1_BAND_LIST))
                   //.add('doy') // Make sure DOY band goes last
                   .map(function(band){return ee.String(band).cat('.*')})) // Add regex for band selection
                   .unmask(0) // DTW does not tolerate null values, so gap fill to 0 if gaps remain
                   .clip(county.geometry()); // Clip again to remask unmasked values outside of area of interest

  */
  
  var band_names = s2_stack.bandNames();
  
  // Sample the band values for each training data points
  // If reference signatures are already defined, it uses those signatures rather than sampling them again.
  var reference_signatures = s2_stack
                             .sampleRegions({
                               collection: train_signatures,
                               properties: [CLASS_NAME],
                               scale : 10,
                               tileScale: 4
                             });
  
  // Wrapper function for the DTW implementation, intended to iterate over each land cover/crop class
  // provided in the reference signatures
  var dtw_min_dist = function(key, val){
    key = ee.Number.parse(key);
    // Function to format the signatures to a DTW-ready EE array
    var training_data_list = DTW.prepareSignatures(reference_signatures,
                                                   CLASS_NAME,
                                                   key,
                                                   BAND_NO,
                                                   PATTERNS_LEN,
                                                   band_names);

    // Compute the class-wise DTW distance
    return ee.ImageCollection(DTW.DTWDist(training_data_list,
                                          ndvi_image_list,
                                          {patterns_no: val,
                                          band_no: BAND_NO,
                                          timeseries_len: TIMESERIES_LEN,
                                          patterns_len: PATTERNS_LEN,
                                          constraint_type: 'time-weighted',
                                          beta: BETA,
                                          alpha: ALPHA
                                          })
           ).min()
           .rename('dtw')
           // Add class band corresponding to the land cover/crop class computed.
           // This is useful/necessary to generate the hard classification map from the dissimilarity values
           .addBands(ee.Image(key).toByte().rename('band'));
  };

  // Prepare the input time series of images into a DTW-ready EE array
  var ndvi_image_list = ee.Image(DTW.prepareBands(s2_stack,
                                                  BAND_NO,
                                                  TIMESERIES_LEN,
                                                  band_names));

  // Map the DTW distance function over each land cover class
  var dtw_image_list = ee.Dictionary({1:1, 2:1, 3:1, 4:1, 5:1, 6:1, 7:1, 9:1, 10:1, 11:1, 12:1}).map(dtw_min_dist);

  // Turn image collection into an array
  var array = ee.ImageCollection(dtw_image_list.values()).toArray();

  // Sort array by the first band, keeping other bands
  var axes = {image:0, band:1};
  var sort = array.arraySlice(axes.band, 0, 1);  // select bands from index 0 to 1 (DTW dissimilarity score)
  var sorted = array.arraySort(sort);

  // Take the first image only
  var values = sorted.arraySlice(axes.image, 0, 1);

  // Convert back to an image
  var min = values.arrayProject([axes.band]).arrayFlatten([['dtw', 'band']]);

  // Extract the DTW dissimilarity score
  var dtw_score = min.select(0).rename('score_' + year);
  // Extract the DTW hard classification
  var dtw_class = min.select(1).rename('classification_' + year);
    
  // Generate validation data
  var validation_dtw = dtw_class.remap([1,2,4,6,7,9,10,12], [1,2,3,4,5,6,7,8]).sampleRegions({
    collection: val_signatures.remap([1,2,4,6,7,9,10,12], [1,2,3,4,5,6,7,8], CLASS_NAME),
    properties:[CLASS_NAME],
    scale : 10, 
    geometries: true,
    tileScale: 4
  });
  
  // Produce the Error Matrix
  var validationAccuracy = validation_dtw.errorMatrix(CLASS_NAME, 'classification_'+year);

  // 1. DTW outputs (dissimilarity score + classification map), 2. reference signatures, 3. stack of bands used as input to DTW
  return [dtw_class.addBands(dtw_score), reference_signatures, s2_stack, validationAccuracy];
};

// Function that performs DTW land classification for a given year.
var RFClassification = function(year, collection_type){
  
  // Load training data for a given year
  var signatures = ee.FeatureCollection('users/ocsgeospatial/Lesotho/trainingData'+year)//.filter(ee.Filter.neq('LC_Class_I', 9));
  var signatures_shrublandSurvey = ee.FeatureCollection('users/ocsgeospatial/Lesotho/trainingData2021_shrublandSurvey');
  
  var signatures_noninvasiveShrub = signatures_shrublandSurvey.filter(ee.Filter.and(ee.Filter.eq('land_cover', 'Shrubland'), 
                                                                             ee.Filter.eq('is_the_spe', 'Non_Invasive')))
                                                                             .map(function(feat){return feat.set('LC_Class_I', 9)});
  var signatures_invasiveShrub = signatures_shrublandSurvey.filter(ee.Filter.and(ee.Filter.eq('land_cover', 'Shrubland'), 
                                                                           ee.Filter.eq('is_the_spe', 'Invasive')))
                                                                           .map(function(feat){return feat.set('LC_Class_I', 9)});
  var signatures_trees = signatures_shrublandSurvey.filter(ee.Filter.eq('land_cover', 'Trees'))
                                                                         .map(function(feat){return feat.set('LC_Class_I', 4)});
  var signatures_grassland = signatures_shrublandSurvey.filter(ee.Filter.eq('land_cover', 'Grassland'))
                                                                        .map(function(feat){return feat.set('LC_Class_I', 10)});      
  var signatures_irrcropland = signatures_shrublandSurvey.filter(ee.Filter.eq('land_cover', 'Irrigated_Agriculture'))
                                                                      .map(function(feat){return feat.set('LC_Class_I', 14)});   
  signatures = signatures.merge(signatures_noninvasiveShrub)
                         .merge(signatures_invasiveShrub)
                         .merge(signatures_trees)
                         .merge(signatures_grassland)
                         .merge(signatures_irrcropland);
  
  var withRandom = signatures.randomColumn('random'); // Add a random column for train/test splitting
  
  // 80/20 train/test split
  var val_signatures = withRandom.filter(ee.Filter.and(ee.Filter.gte('random', 0), ee.Filter.lt('random', 0.2)));
  var train_signatures = withRandom.filter(ee.Filter.or(ee.Filter.lt('random', 0), ee.Filter.gte('random', 0.2)));
  
  // Pull forest, wetland and grassland classes apart as they are over-represented
  var train_signatures_forest = train_signatures.filter(ee.Filter.eq(CLASS_NAME, 4)).randomColumn('random');
  var train_signatures_wetland = train_signatures.filter(ee.Filter.eq(CLASS_NAME, 7)).randomColumn('random');
  //var train_signatures_grassland = train_signatures.filter(ee.Filter.eq(CLASS_NAME, 10)).randomColumn('random');
  
  var train_signatures_len = train_signatures.size();
  
  //Limit their quantity to 100, 100 and 600 for forest, wetland and grassland respectively for training (to maintain a class balance)
  var val_signatures_forest = train_signatures_forest.sort('random', false).limit(train_signatures_len.subtract(300));
  var val_signatures_wetland = train_signatures_wetland.sort('random', false).limit(train_signatures_len.subtract(150));
  //var val_signatures_grassland = train_signatures_grassland.sort('random', false).limit(train_signatures_len.subtract(800));
  train_signatures_forest = train_signatures_forest.sort('random').limit(300);
  train_signatures_wetland = train_signatures_wetland.sort('random').limit(150);
  //train_signatures_grassland = train_signatures_grassland.sort('random').limit(800);
  
  // Merge the training and validation datasets back together
  train_signatures = train_signatures.filter(ee.Filter.inList(CLASS_NAME, [4, 7]).not())
       .merge(train_signatures_forest)
       .merge(train_signatures_wetland)
       //.merge(train_signatures_grassland);
  val_signatures = val_signatures
       .merge(val_signatures_forest)
       .merge(val_signatures_wetland)
       //.merge(val_signatures_grassland);
  
  // Create a dictionary mapping land cover class to number of reference signatures per sample
  var reference_signatures_agg = train_signatures.aggregate_histogram(CLASS_NAME);
  
  // Add a summary chart.
  var training_data_chart = ui.Chart.array.values({array: ee.Dictionary(reference_signatures_agg).values(['1','2','4','6','7','9','10','12','14']), 
                                                   axis: 0, 
                                                   xLabels: ['Built-up', 'Cropland', 'Trees', 'Water Body', 'Wetland',
                                                             'Shrubland', 'Grassland', 'Bare Surfaces', 'Irrigated Cropland'
                                                             ]})
    .setChartType('ColumnChart')        
    .setOptions({
      title: 'Training data distribution',
      width: 200,
      height: 400,
      textPosition: "in",
      hAxis: {title: 'Classes', textStyle: {fontSize: 13}},
      vAxis: {title: 'Number of Points'},
      colors: classification_palette,
      sliceVisibilityThreshold: 0, // Don't group small slices.
    });
  print(training_data_chart);
  
  // apply the function and view the results on map
  var styled_td_train = train_signatures.map(setPointProperties);
  var styled_td_val = val_signatures.map(setPointProperties);

  // Add reference sample points location to the map with the appropriate color legend
  Map.addLayer(styled_td_train.style({styleProperty: "style"}), {}, 'land cover training points ' + year);
  Map.addLayer(styled_td_val.style({styleProperty: "style"}), {}, 'land cover validation points ' + year);
  
  var date_range = ee.Dictionary({'start': year + '-01-01', 'end': year + '-12-31'});
  // Load the Sentinel-2 collection for the time period and area requested
  var s2_cl = S2Masks.loadImageCollection(collection_type, date_range, county.geometry());

  // Perform cloud masking using the S2 cloud probabilities assets from s2cloudless,
  // courtesy of Sentinelhub/EU/Copernicus/ESA
  var masked_collection = s2_cl
                          .filterDate(date_range.get('start'), date_range.get('end'))
                          .map(S2Masks.addCloudShadowMask(not_water, 1e4))
                          .map(S2Masks.applyCloudShadowMask)
                          .map(addNDVI); // Add NDVI to band list

  // Generate a list of time intervals for which to generate a harmonized time series
  var time_intervals = composites.extractTimeRanges(date_range.get('start'), date_range.get('end'), AGG_INTERVAL);
  
  // Generate harmonized monthly time series of FCover as input to the vegetation factor V
  var s2_ts = composites.harmonizedTS(masked_collection, S2_BAND_LIST, time_intervals, {agg_type: 'geomedian'});

  // Replace masked pixels by the mean of the previous and next timestamps
  // And add a Day of Year (DOY) band
  // This is the linear interpolation approach,
  // which is more lightweight than other gap-filling approaches like Savitzky-Golay or harmonic regression
  var s2_stack = ee.Image(s2_ts
                          .map(function(image){
                            var currentDate = ee.Date(image.get('system:time_start'));
                            var meanImage = s2_ts.filterDate(currentDate.advance(-AGG_INTERVAL-1, 'day'),
                                                                 currentDate.advance(AGG_INTERVAL+1, 'day')).mean();
                            // replace all masked values
                            var ddiff = currentDate.difference(ee.Date(ee.String(date_range.get('start'))), 'day');
                            return meanImage.where(image, image).addBands(ee.Image(ddiff).rename('doy').toInt16());
                          })
                          .iterate(function(image, previous){return ee.Image(previous).addBands(image)}, ee.Image([])));
  
  /* //Commenting out the Sentinel-1 input generation. Only Sentinel-2 used for lesotho, mostly due to mountainous landscapes
     // Foreshortening effects are likely to occur over steep terrain
  // Define S1 preprocessing parameters, as per:
  // Version: v1.2
  // Date: 2021-03-10
  // Authors: Mullissa A., Vollrath A., Braun, C., Slagter B., Balling J., Gou Y., Gorelick N.,  Reiche J.
  // Sentinel-1 SAR Backscatter Analysis Ready Data Preparation in Google Earth Engine. Remote Sensing 13.10 (2021): 1954.
  // Description: This script creates an analysis ready S1 image collection.
  // License: This code is distributed under the MIT License.
  var parameter = {//1. Data Selection
                   START_DATE: date_range.get('start'),
                   STOP_DATE: date_range.get('end'),
                   POLARIZATION:'VVVH', // The polarization available may differ depending on where you are on the globe
                   ORBIT : 'ASCENDING', // The orbit availability may differ depending on where you are on the globe
                   // Check out this page to find out what parameters suit your area:
                   // https://sentinels.copernicus.eu/web/sentinel/missions/sentinel-1/observation-scenario
                   GEOMETRY: county.geometry(),
                   //2. Additional Border noise correction
                   APPLY_ADDITIONAL_BORDER_NOISE_CORRECTION: true,
                   //3.Speckle filter
                   APPLY_SPECKLE_FILTERING: true,
                   SPECKLE_FILTER_FRAMEWORK: 'MULTI',
                   SPECKLE_FILTER: 'LEE',
                   SPECKLE_FILTER_KERNEL_SIZE: 9,
                   SPECKLE_FILTER_NR_OF_IMAGES: 10,
                   //4. Radiometric terrain normalization
                   APPLY_TERRAIN_FLATTENING: true,
                   DEM: dem,
                   TERRAIN_FLATTENING_MODEL: 'VOLUME', // More desirable for vegetation monitoring.
                                                       //Use "SURFACE" if working on urban or bare soil applications
                   TERRAIN_FLATTENING_ADDITIONAL_LAYOVER_SHADOW_BUFFER: 0,
                   //5. Output
                   FORMAT : 'DB',
                   CLIP_TO_ROI: false,
                   SAVE_ASSETS: false
  }
  
  //Preprocess the S1 collection
  var s1_ts = wrapper.s1_preproc(parameter)[1]
              .map(function(image){return image
                                          .addBands(image.select('VH').divide(image.select('VH')).rename('Vratio'))
                                          .multiply(1e4).toInt16() // Convert to Int16 using 10000 scaling factor
                                          .set({'system:time_start': image.get('system:time_start')})});

  // Create equally-spaced temporal composites covering the date range and convert to multi-band image
  var s1_stack = ee.Image(composites.harmonizedTS(s1_ts, S1_BAND_LIST, time_intervals, {agg_type: 'geomedian'})
                          .iterate(function(image, previous){return ee.Image(previous).addBands(image)}, ee.Image([])));

  // Re-order the stack order before converting it to a DTW-ready input array
  var s1s2_stack = s1_stack.addBands(s2_stack)
                   .select(ee.List(S1_BAND_LIST.concat(S2_BAND_LIST))
                   //.add('doy) // Make sure DOY band goes last
                   .map(function(band){return ee.String(band).cat('.*')})) // Add regex for band selection
                   .unmask(0) // DTW does not tolerate null values, so gap fill to 0 if gaps remain
                   .clip(county.geometry()); // Clip again to remask unmasked values outside of area of interest

  */
  
  var band_names = s2_stack.bandNames();
  
  // Run for each fold and combine outputs to a single classification using the mode (majority vote).
  var classified_list = ee.List([0, 0.2, 0.4, 0.6, 0.8]).map(function(val){
    val = ee.Number(val);
    
    var val_signatures = withRandom.filter(ee.Filter.and(ee.Filter.gte('random', val), ee.Filter.lt('random', val.add(0.2))));
    var train_signatures = withRandom.filter(ee.Filter.or(ee.Filter.lt('random', val), ee.Filter.gte('random', val.add(0.2))));
    
    var train_signatures_forest = train_signatures.filter(ee.Filter.eq(CLASS_NAME, 4)).randomColumn('random');
    var train_signatures_wetland = train_signatures.filter(ee.Filter.eq(CLASS_NAME, 7)).randomColumn('random');
    //var train_signatures_grassland = train_signatures.filter(ee.Filter.eq(CLASS_NAME, 10)).randomColumn('random');
    
    var train_signatures_len = train_signatures.size();
    
    var val_signatures_forest = train_signatures_forest.sort('random', false).limit(train_signatures_len.subtract(300));
    var val_signatures_wetland = train_signatures_wetland.sort('random', false).limit(train_signatures_len.subtract(150));
    //var val_signatures_grassland = train_signatures_grassland.sort('random', false).limit(train_signatures_len.subtract(800));
        
    train_signatures_forest = train_signatures_forest.sort('random').limit(300);
    train_signatures_wetland = train_signatures_wetland.sort('random').limit(150);
    //train_signatures_grassland = train_signatures_grassland.sort('random').limit(800);
    
    train_signatures = train_signatures.filter(ee.Filter.inList(CLASS_NAME, [4, 7]).not())
         .merge(train_signatures_forest)
         .merge(train_signatures_wetland)
         //.merge(train_signatures_grassland);
    val_signatures = val_signatures
         .merge(val_signatures_forest)
         .merge(val_signatures_wetland)
         //.merge(val_signatures_grassland);
    
    // Sample the band values for each training data points
    // If reference signatures are already defined, it uses those signatures rather than sampling them again.
    var reference_signatures = s2_stack
                               .sampleRegions({
                                 collection: train_signatures,
                                 properties: [CLASS_NAME],
                                 scale : 10,
                                 tileScale: 4
                               });
  
    // Make a Random Forest classifier and train it.
    var classifier = ee.Classifier.smileRandomForest(50)
        .train(
          {features: reference_signatures, 
          classProperty:CLASS_NAME}
          );
    
    // Produce the classification map
    var classified = s2_stack.classify(classifier).rename('classification_' + year);
    
    // Generate validation data
    var validation_rf = classified.remap([1,2,4,6,7,9,10,12,14], [1,2,3,4,5,6,7,8,9])
                        .rename('classification_'+year).sampleRegions({
      collection: val_signatures.remap([1,2,4,6,7,9,10,12,14], [1,2,3,4,5,6,7,8,9], CLASS_NAME),
      properties:[CLASS_NAME],
      scale : 10, 
      geometries: true,
      tileScale: 4
    });
    
    // Produce the Error Matrix
    var validationAccuracy = validation_rf.errorMatrix(CLASS_NAME, 'classification_'+year);
    
    return ee.List([classified, validationAccuracy])
  });
  
  // Sample the band values for each training data points
  // If reference signatures are already defined, it uses those signatures rather than sampling them again.
  var reference_signatures = s2_stack
                             .sampleRegions({
                               collection: train_signatures,
                               properties: [CLASS_NAME],
                               scale : 10,
                               tileScale: 4
                             });
                                                     
  print('reference features used for model training:')
  print(reference_signatures);
  
  // Make a Random Forest classifier and train it.
  var classifier = ee.Classifier.smileRandomForest(50)
      .train(
        {features: reference_signatures, 
        classProperty:CLASS_NAME}
        );
  
  // Add a summary chart.
  training_data_chart = ui.Chart.array.values({
    array: ee.Dictionary(ee.Dictionary(classifier.explain()).get('importance')).values(band_names), 
    axis: 0, 
    xLabels: s2_stack.bandNames()})
  .setChartType('ColumnChart')        
  .setOptions({
    title: 'Random Forest Variable Importance',
    width: 200,
    height: 400,
    textPosition: "in",
    hAxis: {title: 'Spectral bands', textStyle: {fontSize: 13}},
    vAxis: {title: 'Score'},
    colors: classification_palette,
    sliceVisibilityThreshold: 0, // Don't group small slices.
  });
  print(training_data_chart);
  
  // Store feature importance and export it to CSV
  var importance_list = ee.Feature(null, ee.Dictionary(ee.Dictionary(classifier.explain()).get('importance')));

  Export.table.toDrive({
    collection: ee.FeatureCollection(importance_list),
    description: 'feature_importance_'+year+VERSION_NO,
    folder: 'GEE_folder',
    fileNamePrefix: 'feature_importance_'+year+VERSION_NO
  });
  
  // Merge the random forest classification folds into a single classification using mode
  var classified = ee.ImageCollection(classified_list.map(function(img){return ee.List(img).get(0)})).mode();
  
  // Print out the validation results of the respective folds
  var validation_results = classified_list.map(function(img){return ee.List(img).get(1)});
  
  Export.table.toDrive({
    collection: ee.FeatureCollection(ee.Feature(null, {matrix: ee.ConfusionMatrix(validation_results.get(0)).array()})),
    description: 'errorMatrix_'+year+VERSION_NO,
    folder: 'GEE_folder',
    fileNamePrefix: 'errorMatrix_'+year+VERSION_NO
  })
  
  print('Validation error matrix for DTW: ', validation_results.get(0));
  print('Validation producers accuracy for DTW: ', ee.ConfusionMatrix(validation_results.get(0)).producersAccuracy());
  print('Validation consumers accuracy for DTW: ', ee.ConfusionMatrix(validation_results.get(0)).consumersAccuracy());
  print('Validation overall accuracy for DTW: ', ee.ConfusionMatrix(validation_results.get(0)).accuracy());
  print('Validation kappa index for DTW: ', ee.ConfusionMatrix(validation_results.get(0)).kappa());
  
  print('Validation error matrix for DTW: ', validation_results.get(1));
  print('Validation producers accuracy for DTW: ', ee.ConfusionMatrix(validation_results.get(1)).producersAccuracy());
  print('Validation consumers accuracy for DTW: ', ee.ConfusionMatrix(validation_results.get(1)).consumersAccuracy());
  print('Validation overall accuracy for DTW: ', ee.ConfusionMatrix(validation_results.get(1)).accuracy());
  print('Validation kappa index for DTW: ', ee.ConfusionMatrix(validation_results.get(1)).kappa());
  
  print('Validation error matrix for DTW: ', validation_results.get(2));
  print('Validation producers accuracy for DTW: ', ee.ConfusionMatrix(validation_results.get(2)).producersAccuracy());
  print('Validation consumers accuracy for DTW: ', ee.ConfusionMatrix(validation_results.get(2)).consumersAccuracy());
  print('Validation overall accuracy for DTW: ', ee.ConfusionMatrix(validation_results.get(2)).accuracy());
  print('Validation kappa index for DTW: ', ee.ConfusionMatrix(validation_results.get(2)).kappa());
  
  print('Validation error matrix for DTW: ', validation_results.get(3));
  print('Validation producers accuracy for DTW: ', ee.ConfusionMatrix(validation_results.get(3)).producersAccuracy());
  print('Validation consumers accuracy for DTW: ', ee.ConfusionMatrix(validation_results.get(3)).consumersAccuracy());
  print('Validation overall accuracy for DTW: ', ee.ConfusionMatrix(validation_results.get(3)).accuracy());
  print('Validation kappa index for DTW: ', ee.ConfusionMatrix(validation_results.get(3)).kappa());
  
  print('Validation error matrix for DTW: ', validation_results.get(4));
  print('Validation producers accuracy for DTW: ', ee.ConfusionMatrix(validation_results.get(4)).producersAccuracy());
  print('Validation consumers accuracy for DTW: ', ee.ConfusionMatrix(validation_results.get(4)).consumersAccuracy());
  print('Validation overall accuracy for DTW: ', ee.ConfusionMatrix(validation_results.get(4)).accuracy());
  print('Validation kappa index for DTW: ', ee.ConfusionMatrix(validation_results.get(4)).kappa());
  
  // 1. DTW outputs (dissimilarity score + classification map), 2. reference signatures, 3. stack of bands used as input to DTW
  return [classified, reference_signatures, s2_stack];
};

// DTW Dissimilarity score palette
var score_palette = palettes.colorbrewer.RdYlGn[9].reverse();

// Initialize variables before running the loop 
var classification_list = ee.List([]);
var s1s2_list = ee.List([]);
var classification_outputs;
// Iterate over each land cover/crop class to compute outputs for each year
Object.keys(year_dict).forEach(function(i) {
  if (ALGO === 'RF'){
    classification_outputs = RFClassification(i, year_dict[i]);
  } else if (ALGO === 'DTW'){
    classification_outputs = DTWClassification(i, year_dict[i]);
  }
  classification_list = classification_list.add(classification_outputs[0]);
  
  // Export classified data. This is recommended to get the full extent of the data generated and saved,
  // so it can be explored and consulted seamlessly.
  Export.image.toAsset({
    image: classification_outputs[0].clip(county.geometry()).toByte(),
    description:ALGO + '_lesotho_s2_60_10bands_kfold_'+ i +VERSION_NO,
    region: county.geometry(),
    crs: 'EPSG:4326',
    scale: 10,
    maxPixels:1e13,
    assetId: 'users/ocsgeospatial/Lesotho/'+ALGO.toLowerCase()+'_lesotho_s2_60_10bands_kfold_'+i+VERSION_NO,
    pyramidingPolicy: 'MODE'
    //skipEmptyTiles: true, 
    //fileFormat: 'GeoTIFF',
    //formatOptions: {
    //  cloudOptimized: true
    //}
  });
  
  s1s2_list = s1s2_list.add(classification_outputs[2]);
});

// Merge classification outputs as part of a single image collection and retrieve the latest output
var classification = ee.Image(classification_list.slice(0,1).get(0));
var s1s2_stack = s1s2_stack || ee.ImageCollection.fromImages(s1s2_list).first();

// Image Visualization Parameters for the multi-temporal ndvi composite
var imageVisParam = {bands: ["NDVI_2", "NDVI_1", "NDVI"],
                     gamma: 1,
                     max: 7000,
                     min: 1000,
                     opacity: 1
};

// Add an RGB image of Sentinel-2 for reference
var image = ee.ImageCollection('COPERNICUS/S2_SR').filterDate('2021-10-14', '2021-10-30')
                                                  .filterBounds(county.geometry()).sort('system:time_start', false);
Map.addLayer(image.filterMetadata('SENSING_ORBIT_NUMBER', 'equals', 135).mosaic(), 
             {bands: ['B4', 'B3', 'B2'], min: 0, max: 4000}, "S2 raw image");

// The NDVI/EVI images are masked with the 2020 crop mask generated as part of the TCP project.
Map.addLayer(s1s2_stack, imageVisParam, 'NDVI stack 2021');

// Store classification and score as separate variables and add them to the map.
// Only DTW has a dissimilarity score
if (ALGO === 'DTW'){
  var score_latest = classification.select('score.*');
  Map.addLayer(score_latest,
               {palette: score_palette, min: 0, max: 20000},
               'DTW dissimilarity score (30 days signature, 30 days images)');
}

var class_latest = classification.select('classification.*');

// Load latest land cover classification
Map.addLayer(class_latest.clip(county.geometry()),
             {palette: classification_palette, min: 1, max: 14},
             ALGO + ' Classification');
//Map.addLayer(ee.Image('users/ocsgeospatial/Lesotho/rf_lesotho_s2_60_2021_full').clip(county.geometry()),
//             {palette: classification_palette, min: 1, max: 12},
//             ALGO + ' Classification old');// Plot signatures with corresponding color code to see their locations

if (ALGO === 'DTW'){
Export.image.toAsset({
  image: score_latest.toInt16(),
  description:ALGO+'_score_lesotho_s2_60_10bands_'+i,
  region: county.geometry(),
  crs: 'EPSG:4326',
  scale: 10,
  maxPixels:1e13,
  assetId: 'users/ocsgeospatial/Lesotho/'+ALGO+'_lesotho_s2_60_10bands_'+i,
  pyramidingPolicy: 'MODE'
  //skipEmptyTiles: true, 
  //fileFormat: 'GeoTIFF',
  //formatOptions: {
  //  cloudOptimized: true
  //}
  });
}

// Create a legend for the different crop types
// set position of panel
var legend = ui.Panel({
  style: {
    position: 'bottom-left',
    padding: '8px 15px'
  }
});

// Create legend title
var legendTitle = ui.Label({
  value: 'Legend',
  style: {
    fontWeight: 'bold',
    fontSize: '18px',
    margin: '0 0 4px 0',
    padding: '0'
    }
});

// Add the title to the panel
legend.add(legendTitle);

// Add color and and names
for (var i = 0; i <= classification_palette.length-1; i++) {
  legend.add(legend_utils.makeRow(classification_palette[i], Object.keys(lc_classes)[i]));
  }

// add legend to map (alternatively you can also print the legend to the console)
Map.add(legend);
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c11c7bc1-cf2b-4ab4-b4ac-41e77c426888",
   "metadata": {},
   "source": [
    "# Post-process for Entire District\n",
    "\n",
    "## Description\n",
    "Once you are happy with the post-processed results through previous notebook, you can then implement the same post-processing steps for the entire district of interest. To run this analysis, run all the cells in the notebook, starting with the \"Load packages\" cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae08b31c-ce36-4586-9f76-2e35700650e6",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a48295c-bc47-4280-80f4-cfda8c6b13fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import datacube\n",
    "import warnings\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "from rasterio.enums import Resampling\n",
    "from datacube.utils.cog import write_cog\n",
    "from deafrica_tools.spatial import xr_rasterize\n",
    "from deafrica_tools.plotting import rgb\n",
    "from deafrica_tools.bandindices import calculate_indices\n",
    "from deafrica_tools.coastal import get_coastlines\n",
    "from skimage.morphology import binary_dilation,disk\n",
    "from skimage.filters.rank import modal\n",
    "from odc.algo import xr_reproject\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "from matplotlib.colors import ListedColormap,BoundaryNorm\n",
    "from matplotlib.patches import Patch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0a1521-5ec6-408a-a98b-71ca1006571e",
   "metadata": {},
   "source": [
    "## Analysis parameters\n",
    "* `prediction_map_path`: File path and name of the classification map for the entire district.\n",
    "* `dict_map`: A dictionary map of class names corresponding to pixel values.\n",
    "* `output_crs`: Coordinate reference system for output raster files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba701ea-a476-48b8-b405-dd4131d5d2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_map_path='Results/Land_cover_prediction_entire_district.tif'\n",
    "dict_map={'Tree crops':11,'Field crops':12,'Forest plantations':21,'Grassland':31,\n",
    "                 'Aquatic or regularly flooded herbaceous vegetation':41,'Water body':44,\n",
    "                 'Settlements':51,'Bare soils':61,'Mangrove':70,'Mecrusse':71,\n",
    "                'Broadleaved (Semi-) evergreen forest':72,'Broadleaved (Semi-) deciduous forest':74,'Mopane':75}\n",
    "output_crs='epsg:32736' # WGS84/UTM Zone 36S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49842a88-af90-4297-ac3a-994388d702d2",
   "metadata": {},
   "source": [
    "## External Layers\n",
    "The country boundary shapefile and a few external layers were sourced and prepared in the 'Data/' folder, which are helpful to provide information on specific classes, e.g. Settlementss and Water Body. The data includes:\n",
    "* `country_boundary_shp`: Country boundary shapefile.\n",
    "* `hand_raster`: Hydrologically adjusted elevations, i.e. Height Above the Nearest Drainage (hand) derived from the [MERIT Hydro dataset](https://developers.google.com/earth-engine/datasets/catalog/MERIT_Hydro_v1_0_1#description).\n",
    "* `river_network_shp`: OSM river network shapefile. The OSM layers were sourced from the [Humanitarian OpenStreetMap Team (HOT)](https://data.humdata.org/organization/hot) website.\n",
    "* `road_network_shp`: OSM road network shapefile.\n",
    "* `google_building_raster`: A rasterised layer of [Google Open Building polygons](https://developers.google.com/earth-engine/datasets/catalog/GOOGLE_Research_open-buildings_v2_polygons), which consist of outlines of buildings derived from high-resolution 50 cm satellite imagery. As there are many polygons in the original vector layer, we rasterised the layer to 10 m resolution to reduce disk storage and memory required for processing.\n",
    "* `wsf2019_raster`: 2019 [World Settlement Footprint (WSF) layer](https://gee-community-catalog.org/projects/wsf/), a 10m resolution binary mask outlining the extent of human settlements globally derived by means of 2019 multitemporal Sentinel-1 and Sentinel-2 imagery.\n",
    "\n",
    "> Note: In this notebook we have made the data prepared for you to run through the demonstration. If you would like to apply it to your own project, you may need to spend some time sourcing the datasets and do some pre-processing if needed, e.g. clipping to your study area, filtering, rasterisation or vectorisation. Alternatively you can revise this notebook depending on your data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd651c80-094d-46be-9997-20e572e2f5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_boundary_shp='Data/Mozambique_boundary.shp' # country boundary shapefile\n",
    "river_network_shp='Data/hotosm_moz_waterways_lines_filtered.shp' # OSM river network data\n",
    "road_network_shp='Data/hotosm_moz_roads_lines_filtered.shp' # OSM road network data\n",
    "google_building_raster='Data/GoogleBuildingLayer_Mozambique_rasterised.tif' # rasterised google bulding mask layer\n",
    "hand_raster='Data/hand_Mozambique_UInt16.tif' # Hydrologically adjusted elevations, i.e. height above the nearest drainage (hand)\n",
    "wsf2019_raster='Data/WSF2019_v1_Mozambique_clipped.tif' # 2019 World Settlement Footprint layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9735c94d-251e-4a12-9456-3fdd10c31bb2",
   "metadata": {},
   "source": [
    "## Load land cover map and external layers\n",
    "First let's load the land cover map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17abe98-56ce-4042-ab57-ab6d6cd06b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import land cover map of 2021 and reproject\n",
    "lc_map=rioxarray.open_rasterio(prediction_map_path).astype(np.uint8).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d405bb-68da-4e8d-98f6-db3dfb6b0978",
   "metadata": {},
   "source": [
    "As the external raster layers cover the entire country, they can be too large to be loaded to your Sandbox memory (especially if you are using the default instance) and used for analysis. Therefore, in this notebook we first clipped the layers to the extent of the district using GDAL commands. We first create the shapefiles of the extents of the predicted maps using [`gdaltindex`](https://gdal.org/programs/gdaltindex.html), then clip the raster layers using [`gdalwarp`](https://gdal.org/programs/gdalwarp.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da83d6cd-80f1-4a26-8f3a-50ffaa30e165",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_building_clipped=google_building_raster[:-4]+'_clipped.tif' # clipped google bulding mask layer\n",
    "hand_raster_clipped=hand_raster[:-4]+'_clipped.tif' # clipped hand layer\n",
    "wsf2019_raster_clipped=wsf2019_raster[:-4]+'_clipped.tif' # clipped WSF 2019 layer\n",
    "tile_shp='Results/Mozambique_district_extent.shp' # output region extents\n",
    "subprocess.run(['gdaltindex',tile_shp,prediction_map_path])\n",
    "subprocess.run(['gdalwarp','-cutline',tile_shp,'-crop_to_cutline', google_building_raster,google_building_clipped,'-overwrite'])\n",
    "subprocess.run(['gdalwarp','-cutline',tile_shp,'-crop_to_cutline', hand_raster,hand_raster_clipped,'-overwrite'])\n",
    "subprocess.run(['gdalwarp','-cutline',tile_shp,'-crop_to_cutline', wsf2019_raster,wsf2019_raster_clipped,'-overwrite'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6517a6cb-9dfb-44aa-b465-794795422d4f",
   "metadata": {},
   "source": [
    "We then load other layers. The OSM road network layer contains multi-lines with various surface attributes. We'll select some major road types and buffer them by 10 metres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ea0541-4329-4ecb-826a-201553c17cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import OSM road network data and reproject\n",
    "road_network=gpd.read_file(road_network_shp).to_crs(output_crs) \n",
    "road_network=road_network.loc[road_network['surface'].isin(['asphalt', 'paved', 'compacted', 'cobblestone', \n",
    "                                                             'concrete', 'metal', 'paving_stones', \n",
    "                                                             'paving_stones:30'])] # select road network by attributes\n",
    "road_network.geometry=road_network.geometry.buffer(10) # buffer the road network by 10m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d742986-1235-426f-830b-a45359f91a76",
   "metadata": {},
   "source": [
    "Similarly we load and select major waterways from the OSM river network layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89fcadf-370b-47ca-ac45-f142c415ff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "river_network=gpd.read_file(river_network_shp).to_crs(output_crs) # import OSM river network data and reproject\n",
    "river_network=river_network.loc[river_network['waterway'].isin(['canal','river'])] # select river network by attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7f252e-996b-4601-85ae-d0de7a65fd18",
   "metadata": {},
   "source": [
    "Query and buffer coastline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e0cc09-2afe-4b06-8e7a-323ebd587384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mozambique boundary and get bounding box\n",
    "country_boundary=gpd.read_file(country_boundary_shp).to_crs(output_crs)\n",
    "# load coastline layer and buffer\n",
    "shorelines_gdf = get_coastlines(country_boundary.bounds.iloc[0],crs=output_crs,layer='shorelines').to_crs(output_crs)\n",
    "# select only 2021\n",
    "shorelines_gdf_2021=shorelines_gdf[shorelines_gdf['year']=='2021'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d0456f-74e6-4fc6-b921-55951b2d4412",
   "metadata": {},
   "source": [
    "## Morphological filtering and apply all rules\n",
    "We now apply the filtering and all the rules as implemented in the previous notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3491c9-d4ef-42a9-8823-0dd40046bcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "np_lc_map=lc_map.squeeze().to_numpy()\n",
    "# mode filtering for a smoother classification map\n",
    "np_lc_map_postproc=modal(np_lc_map,footprint=disk(2),mask=np_lc_map!=0)\n",
    "\n",
    "ds_geobox=lc_map.geobox\n",
    "\n",
    "# majority filtering for a smoother classification map\n",
    "np_lc_map_postproc=modal(np_lc_map,footprint=disk(2),mask=np_lc_map!=0)\n",
    "# get geobox\n",
    "ds_geobox=lc_map.geobox\n",
    "# load and reproject hand layer\n",
    "hand=xr.open_dataset(hand_raster_clipped,engine=\"rasterio\").squeeze()\n",
    "hand=xr_reproject(hand, ds_geobox, resampling=\"average\")\n",
    "# convert to numpy array\n",
    "np_hand=hand.to_array().squeeze().to_numpy()\n",
    "# rasterise river network layer\n",
    "river_network_mask=xr_rasterize(gdf=river_network,\n",
    "                                  da=lc_map.squeeze(),\n",
    "                                  transform=ds_geobox.transform,\n",
    "                                  crs=output_crs)\n",
    "# convert to numpy array\n",
    "np_river_network_mask=river_network_mask.to_numpy()\n",
    "# apply the rule\n",
    "np_lc_map_postproc[((np_lc_map==dict_map['Water body'])&(np_hand<=45))\n",
    "                   |(np_river_network_mask==1)]=dict_map['Water body']\n",
    "# get bounding box\n",
    "bbox=ds_geobox.extent.boundingbox\n",
    "dc = datacube.Datacube(app='s2_geomedian')\n",
    "query_geomedian= {\n",
    "    'time': ('2021'),\n",
    "    'x': (bbox[0],bbox[2]),\n",
    "    'y': (bbox[1],bbox[3]),\n",
    "    'resolution':(-10, 10),\n",
    "    'crs':output_crs,\n",
    "    'output_crs': output_crs,\n",
    "    'measurements':['green','swir_1']\n",
    "}\n",
    "ds_geomedian = dc.load(product=\"gm_s2_annual\", **query_geomedian)\n",
    "ds_MNDWI = calculate_indices(ds=ds_geomedian, index='MNDWI', satellite_mission='s2',drop=True).squeeze()\n",
    "# reassign water using NDWI calculated from annual S2 geomedian\n",
    "np_MNDWI=ds_MNDWI['MNDWI'].to_numpy()\n",
    "np_lc_map_postproc[np_MNDWI>=0]=dict_map['Water body']\n",
    "\n",
    "# load and reproject google buildings raster\n",
    "google_buildings=xr.open_dataset(google_building_clipped,engine=\"rasterio\").squeeze()\n",
    "google_buildings_mask=xr_reproject(google_buildings, ds_geobox, resampling=\"average\")\n",
    "# convert to numpy array\n",
    "np_google_buildings_mask=google_buildings_mask.to_array().squeeze().to_numpy()\n",
    "# load and reproject WSF 2019 layer\n",
    "wsf2019=xr.open_dataset(wsf2019_raster_clipped,engine=\"rasterio\").squeeze()\n",
    "wsf2019=xr_reproject(wsf2019, ds_geobox, resampling=\"nearest\")\n",
    "# convert to numpy array\n",
    "np_wsf2019=wsf2019.to_array().squeeze().to_numpy()\n",
    "# apply rule\n",
    "np_lc_map_postproc[(np_google_buildings_mask==1)|(np_wsf2019==1)]=dict_map['Settlements']\n",
    "# buffer Settlements areas\n",
    "urban_buffered=binary_dilation(np_lc_map==dict_map['Settlements'],footprint=disk(5))\n",
    "# apply rule\n",
    "np_lc_map_postproc[(urban_buffered==1)&(np_lc_map==dict_map['Aquatic or regularly flooded herbaceous vegetation'])]=dict_map['Field crops']\n",
    "# rasterise road network layer\n",
    "road_network_mask=xr_rasterize(gdf=road_network,\n",
    "                              da=lc_map.squeeze(),\n",
    "                              transform=ds_geobox.transform,\n",
    "                              crs=output_crs)\n",
    "# convert to numpy\n",
    "np_road_network_mask=road_network_mask.to_numpy()\n",
    "# apply the rule\n",
    "np_lc_map_postproc[np_road_network_mask==1]=dict_map['Settlements']\n",
    "\n",
    "\n",
    "# buffer the road network by 50km\n",
    "shorelines_gdf_2021.geometry=shorelines_gdf_2021.geometry.buffer(50000) \n",
    "# rasterise shoreline layer\n",
    "shorelines_2021_mask=xr_rasterize(gdf=shorelines_gdf_2021,da=lc_map.squeeze(),\n",
    "                                  transform=ds_geobox.transform,crs=output_crs) \n",
    "# clip shoreline mask layers\n",
    "shorelines_2021_mask_tile=xr_reproject(shorelines_2021_mask, ds_geobox, resampling=\"nearest\") \n",
    "\n",
    "\n",
    "# convert to numpy\n",
    "np_shorelines_2021_mask=shorelines_2021_mask_tile.squeeze().to_numpy()\n",
    "# apply rule\n",
    "np_lc_map_postproc[(np_shorelines_2021_mask==0)&(np_lc_map==dict_map['Mangrove'])]=dict_map['Forest plantations']\n",
    "\n",
    "# reconstruct dataArray\n",
    "lc_map_postproc=xr.DataArray(data=np_lc_map_postproc,dims=['y','x'],\n",
    "                         coords={'y':lc_map.y.to_numpy(), 'x':lc_map.x.to_numpy()})\n",
    "# set spatial reference\n",
    "lc_map_postproc.rio.write_crs(output_crs, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9835e5fa-57cd-43b6-8803-1da410033892",
   "metadata": {},
   "source": [
    "To compare the post-processed result with initial prediction without post-processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f434491-38a9-4b7e-bdb3-2399f7c7e18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "colours = {11:'gold', 12:'yellow', 21:'darkred',31:'bisque',41:'lightgreen',44:'blue',51:'black',61:'gray',\n",
    "           70:'red',71:'steelblue',72:'blueviolet',74:'green',75:'chocolate'}\n",
    "patches_list=[Patch(facecolor=colour) for colour in colours.values()]\n",
    "\n",
    "# set color legends and color maps parameters\n",
    "prediction_values=np.unique(lc_map)\n",
    "cmap=ListedColormap([colours[k] for k in prediction_values])\n",
    "norm = BoundaryNorm(list(prediction_values)+[np.max(prediction_values)+1], cmap.N)\n",
    "\n",
    "# Plot initial classified image\n",
    "lc_map.plot.imshow(ax=axes[0], \n",
    "               cmap=cmap,\n",
    "               norm=norm,\n",
    "               add_labels=True, \n",
    "               add_colorbar=False,\n",
    "               interpolation='none')\n",
    "\n",
    "# Plot post-processed classified image\n",
    "lc_map_postproc.plot.imshow(ax=axes[1], \n",
    "               cmap=cmap,\n",
    "               norm=norm,\n",
    "               add_labels=True, \n",
    "               add_colorbar=False,\n",
    "               interpolation='none')\n",
    "\n",
    "# Remove axis on middle and right plot\n",
    "axes[1].get_yaxis().set_visible(False)\n",
    "# add colour legends\n",
    "axes[1].legend(patches_list, list(dict_map.keys()),\n",
    "    loc='upper center', ncol =4, bbox_to_anchor=(0.5, -0.1))\n",
    "# Add plot titles\n",
    "axes[0].set_title('Classified Image')\n",
    "axes[1].set_title('Classified Image - Postprocessed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4514a0-28b2-49b3-8bd7-440aa9f494e3",
   "metadata": {},
   "source": [
    "## Save as geotiff\n",
    "We can now export our post-processed result to sandbox disk as Cloud-Optimised GeoTIFF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d683fa8-97fb-46b7-897e-fc10afab300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_cog(lc_map_postproc, 'Results/Land_cover_prediction_postprocessed_entire_district.tif', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d76dfa1-1b87-4ce1-8ee6-39b2173b01f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

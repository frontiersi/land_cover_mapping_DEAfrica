{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f13adbce-103d-40c4-88bd-bb94d3d848f1",
   "metadata": {},
   "source": [
    "# Post-process: Smoothing and Reclassify Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5fb223-9745-4711-9a51-a1384dbcc63e",
   "metadata": {},
   "source": [
    "## Background\n",
    "In real case studies machine learning may not lead to desired classification maps due to factors including limited training data and limited performance of the model for prediction. Therefore, post-processing is widely applied to the predicted classification results, based on assumptions or existing knowlegde of the ground truth. Commonly applied post-processing includes manual editing, filtering, reclassification and class merging, etc.   \n",
    "\n",
    "## Description\n",
    "In this notebook we will apply post-processing to the land cover maps we produced through the previous notebook. We will use external layers that contain reliable information on centain classes and/or have higher-spatial resolution to reclassify classes that may be misclassified by the random forest classifier. These external layers have been prepared and uploaded into 'Data/' folder. We'll also conduct a median filtering to reduce the 'salt and pepper' effect resulted from pixel-based classification. This notebook will demonstrate how to do implement these post-processings and visualise the comparison before and after the post-processing. The steps are as follows:\n",
    "1. Load the external layers and land cover maps produced at the testing locations\n",
    "2. Majority filtering of the maps to reduce salt-and-pepper effects\n",
    "3. Apply customised reclassification rules using the external layers\n",
    "4. Save the results to disk as COGs\n",
    "\n",
    "\n",
    "To run this analysis, run all the cells in the notebook, starting with the \"Load packages\" cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44f4e28-0a6a-4d30-973d-e2f1b20acf2a",
   "metadata": {},
   "source": [
    "### Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4986f5-2e04-4e64-8ff0-25119e9468ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import datacube\n",
    "import warnings\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "from rasterio.enums import Resampling\n",
    "from datacube.utils.cog import write_cog\n",
    "from deafrica_tools.spatial import xr_rasterize\n",
    "from deafrica_tools.plotting import rgb\n",
    "from deafrica_tools.bandindices import calculate_indices\n",
    "from deafrica_tools.coastal import get_coastlines\n",
    "from skimage.morphology import binary_dilation,disk\n",
    "from skimage.filters.rank import modal\n",
    "from odc.algo import xr_reproject\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "from matplotlib.colors import ListedColormap,BoundaryNorm\n",
    "from matplotlib.patches import Patch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e74765-a79f-4bb2-baa5-240c6cacc41e",
   "metadata": {},
   "source": [
    "## Analysis parameters\n",
    "* `prediction_maps_path`: A list of file paths and names of the classification maps produced in the previous notebook.\n",
    "* `rgb_images_path`: A list of file paths and names of the true colour images at the prediction locations exported in the previous notebook.\n",
    "* `dict_map`: A dictionary map of class names corresponding to pixel values.\n",
    "* `output_crs`: Coordinate reference system for output raster files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269eb27c-1692-4461-830b-185ffaa8008b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_maps_path=['Results/Land_cover_prediction_location_'+str(i)+'.tif' for i in range(3)] # list of prediction map files\n",
    "rgb_images_path=['Results/S2_RGB_image_location_'+str(i)+'.tif' for i in range(3)] # list of rgb images at the prediction locations\n",
    "dict_map={'Tree crops':11,'Field crops':12,'Forest plantations':21,'Grassland':31,\n",
    "                 'Aquatic or regularly flooded herbaceous vegetation':41,'Water body':44,\n",
    "                 'Settlements':51,'Bare soils':61,'Mangrove':70,'Mecrusse':71,\n",
    "                'Broadleaved (Semi-) evergreen forest':72,'Broadleaved (Semi-) deciduous forest':74,'Mopane':75} # a dictionary of pixel value for each class\n",
    "output_crs='epsg:32736' # WGS84/UTM Zone 36S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef9884a-c98d-4d0a-8dca-d1cadb986c36",
   "metadata": {},
   "source": [
    "## External Layers\n",
    "The country boundary shapefile and a few external layers were sourced and prepared in the 'Data/' folder, which are helpful to provide information on specific classes, e.g. Settlementss and Water Body. The data includes:\n",
    "* `country_boundary_shp`: Country boundary shapefile.\n",
    "* `hand_raster`: Hydrologically adjusted elevations, i.e. Height Above the Nearest Drainage (hand) derived from the [MERIT Hydro dataset](https://developers.google.com/earth-engine/datasets/catalog/MERIT_Hydro_v1_0_1#description).\n",
    "* `river_network_shp`: OSM river network shapefile. The OSM layers were sourced from the [Humanitarian OpenStreetMap Team (HOT)](https://data.humdata.org/organization/hot) website.\n",
    "* `road_network_shp`: OSM road network shapefile.\n",
    "* `google_building_raster`: A rasterised layer of [Google Open Building polygons](https://developers.google.com/earth-engine/datasets/catalog/GOOGLE_Research_open-buildings_v2_polygons), which consist of outlines of buildings derived from high-resolution 50 cm satellite imagery. As there are many polygons in the original vector layer, we rasterised the layer to 10 m resolution to reduce disk storage and memory required for processing.\n",
    "* `wsf2019_raster`: 2019 [World Settlement Footprint (WSF) layer](https://gee-community-catalog.org/projects/wsf/), a 10m resolution binary mask outlining the extent of human settlements globally derived by means of 2019 multitemporal Sentinel-1 and Sentinel-2 imagery.\n",
    "\n",
    "> Note: In this notebook we have made the data prepared for you to run through the demonstration. If you would like to apply it to your own project, you may need to spend some time sourcing the datasets and do some pre-processing if needed, e.g. clipping to your study area, filtering, rasterisation or vectorisation. Alternatively you can revise this notebook depending on your data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12234399-7fda-4885-bce2-478634840400",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_boundary_shp='Data/Mozambique_boundary.shp' # country boundary shapefile\n",
    "river_network_shp='Data/hotosm_moz_waterways_lines_filtered.shp' # OSM river network data\n",
    "road_network_shp='Data/hotosm_moz_roads_lines_filtered.shp' # OSM road network data\n",
    "google_building_raster='Data/GoogleBuildingLayer_Mozambique_rasterised.tif' # rasterised google bulding mask layer\n",
    "hand_raster='Data/hand_Mozambique_UInt16.tif' # Hydrologically adjusted elevations, i.e. height above the nearest drainage (hand)\n",
    "wsf2019_raster='Data/WSF2019_v1_Mozambique_clipped.tif' # 2019 World Settlement Footprint layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3fc619-a9ae-4ada-9c57-f82a1ec8a908",
   "metadata": {},
   "source": [
    "As the raster layers cover the entire country, they can be too large to be loaded to your Sandbox memory (especially if you are using the default instance) and used for analysis. Therefore, in this notebook we first clipped the layers to the extents of the test prediction locations using GDAL commands. We first create the shapefiles of the extents of the predicted maps using [`gdaltindex`](https://gdal.org/programs/gdaltindex.html), then clip the raster layers using [`gdalwarp`](https://gdal.org/programs/gdalwarp.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b7463d-95d8-48c4-ab4d-9eb4a874cfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_building_tiles=[google_building_raster[:-4]+'_location_'+str(i)+'.tif' for i in range(len(prediction_maps_path))] # clipped google bulding mask layer at test locations\n",
    "hand_raster_tiles=[hand_raster[:-4]+'_location_'+str(i)+'.tif' for i in range(len(prediction_maps_path))] # clipped hand layer at test locations\n",
    "wsf2019_raster_tiles=[wsf2019_raster[:-4]+'_location_'+str(i)+'.tif' for i in range(len(prediction_maps_path))] # clipped WSF 2019 layer at test locations\n",
    "for i in range(len(prediction_maps_path)):\n",
    "    tile_shp='Results/Mozambique_tile'+'_location_'+str(i)+'.shp' # output region extents\n",
    "    subprocess.run(['gdaltindex',tile_shp,prediction_maps_path[i]])\n",
    "    subprocess.run(['gdalwarp','-cutline',tile_shp,'-crop_to_cutline', google_building_raster,google_building_tiles[i],'-overwrite'])\n",
    "    subprocess.run(['gdalwarp','-cutline',tile_shp,'-crop_to_cutline', hand_raster,hand_raster_tiles[i],'-overwrite'])\n",
    "    subprocess.run(['gdalwarp','-cutline',tile_shp,'-crop_to_cutline', wsf2019_raster,wsf2019_raster_tiles[i],'-overwrite'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e2b93c-e69f-46b1-9df4-715dc11f0b04",
   "metadata": {},
   "source": [
    "## Load layers\n",
    "First let's load the land cover maps and true colour images generated from the previous notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775c855d-7100-4d48-8a8b-5219ddcf0f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import land cover map of 2021 and reproject\n",
    "prediction_maps=[]\n",
    "rgb_images=[]\n",
    "for i in range(len(prediction_maps_path)):\n",
    "    lc_map=rioxarray.open_rasterio(prediction_maps_path[i]).astype(np.uint8).squeeze()\n",
    "    prediction_maps.append(lc_map)\n",
    "    \n",
    "    rgb_image=rioxarray.open_rasterio(rgb_images_path[i])\n",
    "    rgb_images.append(rgb_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f64fc6c-856d-4185-926d-76d44872243c",
   "metadata": {},
   "source": [
    "We then load other layers. The OSM road network layer contains multi-lines with various surface attributes. We'll select some major road types and buffer them by 10 metres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616870ab-3aad-439d-bbae-9833ab9e3b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import OSM road network data and reproject\n",
    "road_network=gpd.read_file(road_network_shp).to_crs(output_crs) \n",
    "road_network=road_network.loc[road_network['surface'].isin(['asphalt', 'paved', 'compacted', 'cobblestone', \n",
    "                                                             'concrete', 'metal', 'paving_stones', \n",
    "                                                             'paving_stones:30'])] # select road network by attributes\n",
    "road_network.geometry=road_network.geometry.buffer(10) # buffer the road network by 10m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e53bad2-84e5-4f26-80ed-2009c9a98670",
   "metadata": {},
   "source": [
    "Similarly we load and select major waterways from the OSM river network layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c785f9c0-8461-47f9-94db-7015abcec29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "river_network=gpd.read_file(river_network_shp).to_crs(output_crs) # import OSM river network data and reproject\n",
    "river_network=river_network.loc[river_network['waterway'].isin(['canal','river'])] # select river network by attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6beb26-1701-4135-802f-53d65cd7cab8",
   "metadata": {},
   "source": [
    "## Morphological filtering\n",
    "Now we start the post-processing by applying a majority filtering, a commonly applied step to reduce salt-and-pepper noise typical in pixel-based classification. To demonstrate each post-processing step we will process the first prediction map, then put the steps together in an iterative loop to process all prediction. The majority filtering is applied within each local window with a given footprint. Here we use a disk with radius of two pixels. It is advised that you adjust the footprint depending on your prediction results and desired effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4e80c9-6a86-41f4-8548-d8fa505f0b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "lc_map=prediction_maps[i]\n",
    "# convert to numpy array\n",
    "np_lc_map=lc_map.squeeze().to_numpy()\n",
    "# mode filtering for a smoother classification map\n",
    "np_lc_map_postproc=modal(np_lc_map,footprint=disk(2),mask=np_lc_map!=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e2edbe-931e-4b9b-b6e0-b70831db4c59",
   "metadata": {},
   "source": [
    "We can plot and compare the maps before and after filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db33bbc-ccc6-4e4a-b567-fb3338e18c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct dataArray\n",
    "lc_map_postproc=xr.DataArray(data=np_lc_map_postproc,dims=['y','x'],\n",
    "                             coords={'y':lc_map.y.to_numpy(), 'x':lc_map.x.to_numpy()})\n",
    "# display colour for each class value\n",
    "colours = {11:'gold', 12:'yellow', 21:'darkred',31:'bisque',41:'lightgreen',44:'blue',51:'black',61:'gray',\n",
    "           70:'red',71:'steelblue',72:'blueviolet',74:'green',75:'chocolate'}\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(24, 8))\n",
    "\n",
    "# Plot classified image before filtering\n",
    "prediction_values=np.unique(lc_map)\n",
    "cmap=ListedColormap([colours[k] for k in prediction_values])\n",
    "norm = BoundaryNorm(list(prediction_values)+[np.max(prediction_values)+1], cmap.N)\n",
    "lc_map.plot.imshow(ax=axes[0], \n",
    "                   cmap=cmap,\n",
    "                   norm=norm,\n",
    "                   add_labels=True, \n",
    "                   add_colorbar=False,\n",
    "                   interpolation='none')\n",
    "\n",
    "# Plot classified image after filtering\n",
    "lc_map_postproc.plot.imshow(ax=axes[1], \n",
    "                   cmap=cmap,\n",
    "                   norm=norm,\n",
    "                   add_labels=True, \n",
    "                   add_colorbar=False,\n",
    "                   interpolation='none')\n",
    "# Remove axis on right plot\n",
    "axes[1].get_yaxis().set_visible(False)\n",
    "# add colour legend\n",
    "patches_list=[Patch(facecolor=colour) for colour in colours.values()]\n",
    "axes[1].legend(patches_list, list(dict_map.keys()),loc='upper center', ncol =3, bbox_to_anchor=(0.5, -0.1))\n",
    "# Add plot titles\n",
    "axes[0].set_title('Classified Image Before Majority Filtering')\n",
    "axes[1].set_title('Classified Image After Majority Filtering')\n",
    "\n",
    "# make a copy of intermediate result\n",
    "lc_map_filtered=lc_map_postproc.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce998fb4-8426-46a1-9684-e8c274884eb5",
   "metadata": {},
   "source": [
    "## Apply rules using external layers\n",
    "Before applying reclassification using other layers, one thing to note for raster-based calculation is to make sure all rasters are in the same spatial reference and align with each other. Here we extract the `geobox` of the land cover map, which defines the location and resolution of the grid data including spatial reference. We will use it to reproject other layers to be aligned with the land cover map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017aa374-8140-44df-96ad-bf6efbbe8a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_geobox=lc_map.geobox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213fa349-6f01-4b5d-b9ad-40ad17a3b07b",
   "metadata": {},
   "source": [
    "### Recalssify Water body"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee75ff37-955c-4304-9b2f-62d32d0aa0e2",
   "metadata": {},
   "source": [
    "Now let's reclassify some classes using the external layers. First, we reclassify all pixels classified as Water body and occuring at bottom of watersheds, i.e. height above nearest drainage below 45 m, or falling within OSM river networks as Water body class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47515c1-b690-4499-a2a4-3b8eb127b8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and reproject hand layer\n",
    "hand=xr.open_dataset(hand_raster_tiles[i],engine=\"rasterio\").squeeze()\n",
    "hand=xr_reproject(hand, ds_geobox, resampling=\"average\")\n",
    "# convert to numpy array\n",
    "np_hand=hand.to_array().squeeze().to_numpy()\n",
    "# rasterise river network layer\n",
    "river_network_mask=xr_rasterize(gdf=river_network,\n",
    "                                  da=lc_map.squeeze(),\n",
    "                                  transform=ds_geobox.transform,\n",
    "                                  crs=output_crs)\n",
    "# convert to numpy array\n",
    "np_river_network_mask=river_network_mask.to_numpy()\n",
    "# apply the rule\n",
    "np_lc_map_postproc[((np_lc_map==dict_map['Water body'])&(np_hand<=45))\n",
    "                   |(np_river_network_mask==1)]=dict_map['Water body']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f59760b-3400-4c0d-b861-a5e4975b57ed",
   "metadata": {},
   "source": [
    "We observed that some coastal water was not misclassified, possibly due to insufficient training samples for this type of water. To enhance water body and distinguish it from other classes, we calculate the Modified Normalised Difference Water Index (MNDWI), which is calculated using green and short-wave infrared bands. More information on MNDWI can be found in [this paper](https://www.tandfonline.com/doi/abs/10.1080/01431160600589179). To calculate MNDWI We extract the bounding box of the land cover map to query annual geomedian of Sentinel-2 image, then calcualte MNDWI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfb7d4f-7b58-4d7f-9ac6-381314a80fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox=ds_geobox.extent.boundingbox\n",
    "dc = datacube.Datacube(app='s2_geomedian')\n",
    "query_geomedian= {\n",
    "    'time': ('2021'),\n",
    "    'x': (bbox[0],bbox[2]),\n",
    "    'y': (bbox[1],bbox[3]),\n",
    "    'resolution':(-10, 10),\n",
    "    'crs':output_crs,\n",
    "    'output_crs': output_crs,\n",
    "    'measurements':['green','swir_1']\n",
    "}\n",
    "ds_geomedian = dc.load(product=\"gm_s2_annual\", **query_geomedian)\n",
    "ds_MNDWI = calculate_indices(ds=ds_geomedian, index='MNDWI', satellite_mission='s2',drop=True).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc5e19b-c154-4c7f-a824-e6ccd32faaaf",
   "metadata": {},
   "source": [
    "MNDWI has higher values at water body than the other classes, so here we use a threshold of 0 to derive a water body mask and apply it. You can also fine-tune this threshold depending on your area and observation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0015f2e8-e460-4108-a2f4-f00bcb3be745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reassign water using NDWI calculated from annual S2 geomedian\n",
    "np_MNDWI=ds_MNDWI['MNDWI'].to_numpy()\n",
    "np_lc_map_postproc[np_MNDWI>=0]=dict_map['Water body']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7277ce2a-363b-482c-b254-93da232b77eb",
   "metadata": {},
   "source": [
    "### Reclassify Settlements\n",
    "We then assign pixels overlapping google building polygons or WSF 2019 mask as Settlements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e72cd0-ee13-4332-b6b7-430873016db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and reproject google buildings raster\n",
    "google_buildings=xr.open_dataset(google_building_tiles[i],engine=\"rasterio\").squeeze()\n",
    "google_buildings_mask=xr_reproject(google_buildings, ds_geobox, resampling=\"average\")\n",
    "# convert to numpy array\n",
    "np_google_buildings_mask=google_buildings_mask.to_array().squeeze().to_numpy()\n",
    "\n",
    "# load and reproject WSF 2019 layer\n",
    "wsf2019=xr.open_dataset(wsf2019_raster_tiles[i],engine=\"rasterio\").squeeze()\n",
    "wsf2019=xr_reproject(wsf2019, ds_geobox, resampling=\"nearest\")\n",
    "# convert to numpy array\n",
    "np_wsf2019=wsf2019.to_array().squeeze().to_numpy()\n",
    "# apply rule\n",
    "np_lc_map_postproc[(np_google_buildings_mask==1)|(np_wsf2019==255)]=dict_map['Settlements']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6bd50b-0f09-4caa-a0a8-bc3ea81221ce",
   "metadata": {},
   "source": [
    "In addition, we reclassify pixels overlapping OSM road network as Settlements class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e41471-c80e-4686-9f6d-2b94e9884c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rasterise road network layer\n",
    "road_network_mask=xr_rasterize(gdf=road_network,\n",
    "                              da=lc_map.squeeze(),\n",
    "                              transform=ds_geobox.transform,\n",
    "                              crs=output_crs)\n",
    "# convert to numpy\n",
    "np_road_network_mask=road_network_mask.to_numpy()\n",
    "# apply the rule\n",
    "np_lc_map_postproc[np_road_network_mask==1]=dict_map['Settlements']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7da357-4159-4cda-91f6-03e170887daa",
   "metadata": {},
   "source": [
    "### Reclassify regularly flooded vegetation\n",
    "We assume that regularly flooded vegetation too close (e.g. within 50m) to Settlements are likely misclassified, so we reclassify them as Field crops instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c5f6ff-1d92-49a5-8335-96ef4188284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buffer Settlements areas\n",
    "urban_buffered=binary_dilation(np_lc_map==dict_map['Settlements'],footprint=disk(5))\n",
    "# apply rule\n",
    "np_lc_map_postproc[(urban_buffered==1)&(np_lc_map==dict_map['Aquatic or regularly flooded herbaceous vegetation'])]=dict_map['Field crops']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa4597e-aef4-4de6-92ca-46e33de92ed4",
   "metadata": {},
   "source": [
    "### Reclassify Mangrove\n",
    "We also observed that some inland forests are misclassified as Mangrove, which is unlikely as Mangrove grows in coastal areas. Therefore, we reclassify Mangrove pixels further than a pre-defined distance (e.g. 50 km) of the coastline as Forest Plantation. To do that we use the function `get_coastlines` to query the 2021 annual coastline product available in DE Africa. More information about the coastline product can be found in the [notebook](https://docs.digitalearthafrica.org/en/latest/sandbox/notebooks/Datasets/Coastlines.html?highlight=get_coastlines#id1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e0ee1d-1d20-4c27-9684-23a7049c7524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mozambique boundary and get bounding box\n",
    "country_boundary=gpd.read_file(country_boundary_shp).to_crs(output_crs)\n",
    "# load coastline layer and buffer\n",
    "shorelines_gdf = get_coastlines(country_boundary.bounds.iloc[0],crs=output_crs,layer='shorelines').to_crs(output_crs)\n",
    "# select only 2021\n",
    "shorelines_gdf_2021=shorelines_gdf[shorelines_gdf['year']=='2021'] \n",
    "# buffer the road network by 50km\n",
    "shorelines_gdf_2021.geometry=shorelines_gdf_2021.geometry.buffer(50000) \n",
    "# rasterise layer\n",
    "shorelines_2021_mask=xr_rasterize(gdf=shorelines_gdf_2021,da=lc_map.squeeze(),\n",
    "                                  transform=ds_geobox.transform,crs=output_crs) \n",
    "\n",
    "# load and clip shoreline mask layers\n",
    "shorelines_2021_mask_tile=xr_reproject(shorelines_2021_mask, ds_geobox, resampling=\"nearest\") \n",
    "# convert to numpy\n",
    "np_shorelines_2021_mask=shorelines_2021_mask_tile.squeeze().to_numpy()\n",
    "# apply rule\n",
    "np_lc_map_postproc[(np_shorelines_2021_mask==0)&(np_lc_map==dict_map['Mangrove'])]=dict_map['Forest plantations']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3918b4-ad54-47e4-a7e4-ff11bc23c6ae",
   "metadata": {},
   "source": [
    "### Plot the results\n",
    "We can plot the maps to see a comparison before and after applying the above rules using the external layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173e248c-d5dc-4d3b-bc27-0362e452edce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(24, 8))\n",
    "\n",
    "# Plot classified image before applying rules\n",
    "prediction_values=np.unique(lc_map_filtered)\n",
    "cmap=ListedColormap([colours[k] for k in prediction_values])\n",
    "norm = BoundaryNorm(list(prediction_values)+[np.max(prediction_values)+1], cmap.N)\n",
    "lc_map_filtered.plot.imshow(ax=axes[0], \n",
    "                   cmap=cmap,\n",
    "                   norm=norm,\n",
    "                   add_labels=True, \n",
    "                   add_colorbar=False,\n",
    "                   interpolation='none')\n",
    "\n",
    "# Plot classified image after applying rules\n",
    "# reconstruct dataArray\n",
    "lc_map_postproc=xr.DataArray(data=np_lc_map_postproc,dims=['y','x'],\n",
    "                             coords={'y':lc_map.y.to_numpy(), 'x':lc_map.x.to_numpy()})\n",
    "lc_map_postproc.plot.imshow(ax=axes[1], \n",
    "                   cmap=cmap,\n",
    "                   norm=norm,\n",
    "                   add_labels=True, \n",
    "                   add_colorbar=False,\n",
    "                   interpolation='none')\n",
    "# Remove axis on right plot\n",
    "axes[1].get_yaxis().set_visible(False)\n",
    "# add colour legend\n",
    "axes[1].legend(patches_list, list(dict_map.keys()),\n",
    "    loc='upper center', ncol =3, bbox_to_anchor=(0.5, -0.1))\n",
    "# Add plot titles\n",
    "axes[0].set_title('Classified Image Before Applying Rules')\n",
    "axes[1].set_title('Classified Image After Applying Rules')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f113f9-9a6b-414e-8973-8682f5309103",
   "metadata": {},
   "source": [
    "## Process all testing locations\n",
    "Now let's process all three locations by simply copying and putting together all the post-processing steps, and iterating through all three locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a606485-d563-479d-a7e5-6d59f859a5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_maps_postproc=[] # post-processed results\n",
    "for i in range(0,len(prediction_maps)):\n",
    "    lc_map=prediction_maps[i]\n",
    "    # convert to numpy array\n",
    "    np_lc_map=lc_map.squeeze().to_numpy()\n",
    "    # majority filtering for a smoother classification map\n",
    "    np_lc_map_postproc=modal(np_lc_map,footprint=disk(2),mask=np_lc_map!=0)\n",
    "    # get geobox\n",
    "    ds_geobox=lc_map.geobox\n",
    "    # load and reproject hand layer\n",
    "    hand=xr.open_dataset(hand_raster_tiles[i],engine=\"rasterio\").squeeze()\n",
    "    hand=xr_reproject(hand, ds_geobox, resampling=\"average\")\n",
    "    # convert to numpy array\n",
    "    np_hand=hand.to_array().squeeze().to_numpy()\n",
    "    # rasterise river network layer\n",
    "    river_network_mask=xr_rasterize(gdf=river_network,\n",
    "                                      da=lc_map.squeeze(),\n",
    "                                      transform=ds_geobox.transform,\n",
    "                                      crs=output_crs)\n",
    "    # convert to numpy array\n",
    "    np_river_network_mask=river_network_mask.to_numpy()\n",
    "    # apply the rule\n",
    "    np_lc_map_postproc[((np_lc_map==dict_map['Water body'])&(np_hand<=45))\n",
    "                       |(np_river_network_mask==1)]=dict_map['Water body']\n",
    "    # get bounding box\n",
    "    bbox=ds_geobox.extent.boundingbox\n",
    "    dc = datacube.Datacube(app='s2_geomedian')\n",
    "    query_geomedian= {\n",
    "        'time': ('2021'),\n",
    "        'x': (bbox[0],bbox[2]),\n",
    "        'y': (bbox[1],bbox[3]),\n",
    "        'resolution':(-10, 10),\n",
    "        'crs':output_crs,\n",
    "        'output_crs': output_crs,\n",
    "        'measurements':['green','swir_1']\n",
    "    }\n",
    "    ds_geomedian = dc.load(product=\"gm_s2_annual\", **query_geomedian)\n",
    "    ds_MNDWI = calculate_indices(ds=ds_geomedian, index='MNDWI', satellite_mission='s2',drop=True).squeeze()\n",
    "    # reassign water using NDWI calculated from annual S2 geomedian\n",
    "    np_MNDWI=ds_MNDWI['MNDWI'].to_numpy()\n",
    "    np_lc_map_postproc[np_MNDWI>=0]=dict_map['Water body']\n",
    "\n",
    "    # load and reproject google buildings raster\n",
    "    google_buildings=xr.open_dataset(google_building_tiles[i],engine=\"rasterio\").squeeze()\n",
    "    google_buildings_mask=xr_reproject(google_buildings, ds_geobox, resampling=\"average\")\n",
    "    # convert to numpy array\n",
    "    np_google_buildings_mask=google_buildings_mask.to_array().squeeze().to_numpy()\n",
    "    # load and reproject WSF 2019 layer\n",
    "    wsf2019=xr.open_dataset(wsf2019_raster_tiles[i],engine=\"rasterio\").squeeze()\n",
    "    wsf2019=xr_reproject(wsf2019, ds_geobox, resampling=\"nearest\")\n",
    "    # convert to numpy array\n",
    "    np_wsf2019=wsf2019.to_array().squeeze().to_numpy()\n",
    "    # apply rule\n",
    "    np_lc_map_postproc[(np_google_buildings_mask==1)|(np_wsf2019==1)]=dict_map['Settlements']\n",
    "    # buffer Settlements areas\n",
    "    urban_buffered=binary_dilation(np_lc_map==dict_map['Settlements'],footprint=disk(5))\n",
    "    # apply rule\n",
    "    np_lc_map_postproc[(urban_buffered==1)&(np_lc_map==dict_map['Aquatic or regularly flooded herbaceous vegetation'])]=dict_map['Field crops']\n",
    "    # rasterise road network layer\n",
    "    road_network_mask=xr_rasterize(gdf=road_network,\n",
    "                                  da=lc_map.squeeze(),\n",
    "                                  transform=ds_geobox.transform,\n",
    "                                  crs=output_crs)\n",
    "    # convert to numpy\n",
    "    np_road_network_mask=road_network_mask.to_numpy()\n",
    "    # apply the rule\n",
    "    np_lc_map_postproc[np_road_network_mask==1]=dict_map['Settlements']\n",
    "\n",
    "    # rasterise shoreline layer\n",
    "    shorelines_2021_mask=xr_rasterize(gdf=shorelines_gdf_2021,da=lc_map.squeeze(),\n",
    "                                      transform=ds_geobox.transform,crs=output_crs) \n",
    "    # clip shoreline mask layers\n",
    "    shorelines_2021_mask_tile=xr_reproject(shorelines_2021_mask, ds_geobox, resampling=\"nearest\") \n",
    "    # convert to numpy\n",
    "    np_shorelines_2021_mask=shorelines_2021_mask_tile.squeeze().to_numpy()\n",
    "    # apply rule\n",
    "    np_lc_map_postproc[(np_shorelines_2021_mask==0)&(np_lc_map==dict_map['Mangrove'])]=dict_map['Forest plantations']\n",
    "\n",
    "    # reconstruct dataArray\n",
    "    lc_map_postproc=xr.DataArray(data=np_lc_map_postproc,dims=['y','x'],\n",
    "                             coords={'y':lc_map.y.to_numpy(), 'x':lc_map.x.to_numpy()})\n",
    "    # set spatial reference\n",
    "    lc_map_postproc.rio.write_crs(output_crs, inplace=True)\n",
    "    # append to list\n",
    "    prediction_maps_postproc.append(lc_map_postproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc9e53c-0b31-4fdc-b613-23da0c566a78",
   "metadata": {},
   "source": [
    "We can plot and compare all final post-processed results with initial predictions without post-processing, along with the satellite images for comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fab9e08-ec61-43e2-a05e-33a8865be61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(prediction_maps)):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(24, 8))\n",
    "\n",
    "    # Plot true colour image\n",
    "    rgb(rgb_images[i].to_dataset(dim='band'),bands=[1,2,3],\n",
    "        ax=axes[0], percentile_stretch=(0.01, 0.99))\n",
    "    \n",
    "    # Plot initial classified image\n",
    "    prediction_values=np.unique(prediction_maps[i])\n",
    "    cmap=ListedColormap([colours[k] for k in prediction_values])\n",
    "    norm = BoundaryNorm(list(prediction_values)+[np.max(prediction_values)+1], cmap.N)\n",
    "    prediction_maps[i].plot.imshow(ax=axes[1], \n",
    "                   cmap=cmap,\n",
    "                   norm=norm,\n",
    "                   add_labels=True, \n",
    "                   add_colorbar=False,\n",
    "                   interpolation='none')\n",
    "    \n",
    "    # Plot post-processed classified image\n",
    "    prediction_maps_postproc[i].plot.imshow(ax=axes[2], \n",
    "                   cmap=cmap,\n",
    "                   norm=norm,\n",
    "                   add_labels=True, \n",
    "                   add_colorbar=False,\n",
    "                   interpolation='none')\n",
    "                   \n",
    "    # Remove axis on middle and right plot\n",
    "    axes[1].get_yaxis().set_visible(False)\n",
    "    axes[2].get_yaxis().set_visible(False)\n",
    "    # add colour legend\n",
    "    patches_list=[Patch(facecolor=colour) for colour in colours.values()]\n",
    "    axes[1].legend(patches_list, list(dict_map.keys()),\n",
    "        loc='upper center', ncol =3, bbox_to_anchor=(0.5, -0.1))\n",
    "    # Add plot titles\n",
    "    axes[0].set_title('True Colour Geomedian')\n",
    "    axes[1].set_title('Classified Image')\n",
    "    axes[2].set_title('Classified Image - Postprocessed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5690f01c-0333-4da0-8c22-c66cbf347be8",
   "metadata": {},
   "source": [
    "## Save as geotiff\n",
    "One you finish the post-processing you can now export our post-processed results to sandbox disk as Cloud-Optimised GeoTIFFs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2077ff-46cb-47c0-8889-3739cf0a3afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(prediction_maps_postproc)):\n",
    "    write_cog(prediction_maps_postproc[i], 'Results/Mozambique_land_cover_prediction_postprocessed_2021_location_'+str(i)+'.tif', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fca9a2-0565-4363-80b7-ab0fb02ddfe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "01a9736267bf300689e8e016092cd01f0c67384dd94651ae6e139a291bc8cc97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f13adbce-103d-40c4-88bd-bb94d3d848f1",
   "metadata": {},
   "source": [
    "# Post-process: Smoothing and Reclassify Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5fb223-9745-4711-9a51-a1384dbcc63e",
   "metadata": {},
   "source": [
    "## Background\n",
    "In real case studies machine learning may not predict desired classification maps due to factors including limited training data and limited performance of the model for prediction. Therefore, post-processing is widely applied to the predicted classification results, based on assumptions or existing knowlegde of the ground truth. Commonly applied post-processing includes manual editing, filtering, reclassification and class merging, etc.  \n",
    "\n",
    "## Description\n",
    "In this notebook we will apply post-processing to the land cover maps we produced through the previous notebook. We will use external layers that contain reliable information on centain classes and/or have higher-spatial resolution to reclassify classes that may be misclassified by the random forest classifier. These external layers have been prepared and uploaded into 'Data/' folder. We'll also conduct a median filtering to reduce the 'salt and pepper' effect resulted from pixel-based classification. This notebook will demonstrate how to do implement these post-processings and visualise the comparison before and after the post-processing. The steps are as follows:\n",
    "1. Load the external layers and land cover maps produced at the testing locations\n",
    "2. Majority filtering of the maps to reduce salt-and-pepper effects\n",
    "3. Apply customised reclassification rules using the external layers\n",
    "4. Save the results to disk as COGs\n",
    "\n",
    "To run this analysis, run all the cells in the notebook, starting with the \"Load packages\" cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44f4e28-0a6a-4d30-973d-e2f1b20acf2a",
   "metadata": {},
   "source": [
    "### Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4986f5-2e04-4e64-8ff0-25119e9468ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "from datacube.utils.cog import write_cog\n",
    "from deafrica_tools.spatial import xr_rasterize\n",
    "from deafrica_tools.plotting import rgb\n",
    "from skimage.morphology import binary_dilation,disk\n",
    "from skimage.filters.rank import modal\n",
    "from odc.algo import xr_reproject\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap,BoundaryNorm\n",
    "from matplotlib.patches import Patch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e74765-a79f-4bb2-baa5-240c6cacc41e",
   "metadata": {},
   "source": [
    "## Analysis parameters\n",
    "* `prediction_maps_path`: A list of file paths and names of the classification maps produced in the previous notebook.\n",
    "* `rgb_images_path`: A list of file paths and names of the true colour images at the prediction locations exported in the previous notebook.\n",
    "* `dict_map`: A dictionary map of class names corresponding to pixel values.\n",
    "* `output_crs`: Coordinate reference system for output raster files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269eb27c-1692-4461-830b-185ffaa8008b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_maps_path=['Results/Rwanda_land_cover_prediction_2021_location_'+str(i)+'.tif' for i in range(3)] # list of prediction map files\n",
    "rgb_images_path=['Results/Rwanda_satellite_image_2021_location_'+str(i)+'.tif' for i in range(3)] # list of rgb images at the prediction locations\n",
    "dict_map={'Forest':1,'Grassland':5,'Shrubland':7,'Perennial Cropland':9,'Annual Cropland':10,\n",
    "          'Wetland':11,'Water Body':12,'Urban Settlement':13} # a dictionary of pixel value for each class\n",
    "output_crs='epsg:32735' # WGS84/UTM Zone 35S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef9884a-c98d-4d0a-8dca-d1cadb986c36",
   "metadata": {},
   "source": [
    "## External Layers\n",
    "A few external layers were sourced and prepared in the 'Data/' folder, which are helpful to provide information on specific classes, e.g. Urban Settlements and Water Body. which include:\n",
    "* `hand_raster`: Hydrologically adjusted elevations, i.e. Height Above the Nearest Drainage (hand) derived from the [MERIT Hydro dataset](https://developers.google.com/earth-engine/datasets/catalog/MERIT_Hydro_v1_0_1#description).\n",
    "* `river_network_shp`: OSM river network shapefile. The OSM layers were sourced from the [Humanitarian OpenStreetMap Team (HOT)](https://data.humdata.org/organization/hot) website.\n",
    "* `road_network_shp`: OSM road network shapefile.\n",
    "* `google_building_raster`: A rasterised layer of [Google Open Building polygons](https://developers.google.com/earth-engine/datasets/catalog/GOOGLE_Research_open-buildings_v2_polygons), which consist of outlines of buildings derived from high-resolution 50 cm satellite imagery. As there are many polygons in the original vector layer, we rasterised the layer to 10 m resolution to reduce disk storage and memory required for processing.\n",
    "* `wsf2019_raster`: 2019 [World Settlement Footprint (WSF) layer](https://gee-community-catalog.org/projects/wsf/), a 10m resolution binary mask outlining the extent of human settlements globally derived by means of 2019 multitemporal Sentinel-1 and Sentinel-2 imagery.  \n",
    "\n",
    "> Note: In this notebook we have made the data prepared for you to run through the demonstration. If you would like to apply it to your own project, you may need to spend some time sourcing the datasets and do some pre-processing if needed, e.g. clipping to your study area, filtering, rasterisation or vectorisation. Alternatively you can revise this notebook depending on your data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12234399-7fda-4885-bce2-478634840400",
   "metadata": {},
   "outputs": [],
   "source": [
    "river_network_shp='Data/hotosm_rwa_waterways_lines_filtered.shp' # OSM river network data\n",
    "road_network_shp='Data/hotosm_rwa_roads_lines_filtered.shp' # OSM road network data\n",
    "google_building_raster='Data/GoogleBuildingLayer_Rwanda_reprojected_rasterised.tif' # rasterised google bulding layer\n",
    "hand_raster='Data/hand_Rwanda.tif' # Hydrologically adjusted elevations, i.e. height above the nearest drainage (hand)\n",
    "wsf2019_raster='Data/WSF2019_v1_Rwanda_clipped.tif' # 2019 World Settlement Footprint layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e2b93c-e69f-46b1-9df4-715dc11f0b04",
   "metadata": {},
   "source": [
    "## Load layers\n",
    "First let's load the land cover maps and true colour images generated from the previous notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775c855d-7100-4d48-8a8b-5219ddcf0f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import land cover map of 2021 and reproject\n",
    "prediction_maps=[]\n",
    "rgb_images=[]\n",
    "for i in range(0, len(prediction_maps_path)):\n",
    "    lc_map=rioxarray.open_rasterio(prediction_maps_path[i]).astype(np.uint8).squeeze()\n",
    "    prediction_maps.append(lc_map)\n",
    "    \n",
    "    rgb_image=rioxarray.open_rasterio(rgb_images_path[i])\n",
    "    rgb_images.append(rgb_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f64fc6c-856d-4185-926d-76d44872243c",
   "metadata": {},
   "source": [
    "We then load other layers. The OSM road network layer contains multi-lines with various surface attributes. We'll select some major road types and buffer them by 10 metres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616870ab-3aad-439d-bbae-9833ab9e3b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import OSM road network data and reproject\n",
    "road_network=gpd.read_file(road_network_shp).to_crs(output_crs) \n",
    "road_network=road_network.loc[road_network['surface'].isin(['asphalt', 'paved', 'compacted', 'cobblestone', \n",
    "                                                             'concrete', 'metal', 'paving_stones', \n",
    "                                                             'paving_stones:30'])] # select road network by attributes\n",
    "road_network.geometry=road_network.geometry.buffer(10) # buffer the road network by 10m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e53bad2-84e5-4f26-80ed-2009c9a98670",
   "metadata": {},
   "source": [
    "Similarly we load and select major waterways from the OSM river network layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c785f9c0-8461-47f9-94db-7015abcec29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "river_network=gpd.read_file(river_network_shp).to_crs(output_crs) # import OSM river network data and reproject\n",
    "river_network=river_network.loc[river_network['waterway'].isin(['canal','river'])] # select river network by attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8469a6-6e9b-44f1-a975-622f258eb170",
   "metadata": {},
   "source": [
    "We now load the Google buildings, WSF 2019 and 'hand' rasters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c28d0d-b5a2-4a83-9567-6e2e17a6b42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_buildings=xr.open_dataset(google_building_raster,engine=\"rasterio\").squeeze() # import google bulding layer\n",
    "hand=xr.open_dataset(hand_raster,engine=\"rasterio\").squeeze() # import hand layer\n",
    "wsf2019=xr.open_dataset(wsf2019_raster,engine=\"rasterio\").squeeze().astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6beb26-1701-4135-802f-53d65cd7cab8",
   "metadata": {},
   "source": [
    "## Morphological filtering\n",
    "Now we start the post-processing by applying a majority filtering, a commonly applied step to reduce salt-and-pepper noise typical in pixel-based classification. To demonstrate each post-processing step we will process the first prediction map, then put the steps together in an iterative loop to process all prediction. The majority filtering is applied within each local window with a given footprint. Here we use a disk with radius of two pixels. It is advised that you adjust the footprint depending on your prediction results and desired effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4e80c9-6a86-41f4-8548-d8fa505f0b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "lc_map=prediction_maps[i]\n",
    "# convert to numpy array\n",
    "np_lc_map=lc_map.squeeze().to_numpy()\n",
    "# mode filtering for a smoother classification map\n",
    "np_lc_map_postproc=modal(np_lc_map,footprint=disk(2),mask=np_lc_map!=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e2edbe-931e-4b9b-b6e0-b70831db4c59",
   "metadata": {},
   "source": [
    "We can plot and compare the maps before and after filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db33bbc-ccc6-4e4a-b567-fb3338e18c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct dataArray\n",
    "lc_map_postproc=xr.DataArray(data=np_lc_map_postproc,dims=['y','x'],\n",
    "                             coords={'y':lc_map.y.to_numpy(), 'x':lc_map.x.to_numpy()})\n",
    "# display colour for each class value\n",
    "colours = {1:'green', 5:'gold', 7:'chocolate',9:'violet',10:'pink',11:'cyan',12:'blue',13:'gray'}\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(24, 8))\n",
    "\n",
    "# Plot classified image before filtering\n",
    "prediction_values=np.unique(lc_map)\n",
    "cmap=ListedColormap([colours[k] for k in prediction_values])\n",
    "norm = BoundaryNorm(list(prediction_values)+[np.max(prediction_values)+1], cmap.N)\n",
    "lc_map.plot.imshow(ax=axes[0], \n",
    "                   cmap=cmap,\n",
    "                   norm=norm,\n",
    "                   add_labels=True, \n",
    "                   add_colorbar=False,\n",
    "                   interpolation='none')\n",
    "\n",
    "# Plot classified image after filtering\n",
    "lc_map_postproc.plot.imshow(ax=axes[1], \n",
    "                   cmap=cmap,\n",
    "                   norm=norm,\n",
    "                   add_labels=True, \n",
    "                   add_colorbar=False,\n",
    "                   interpolation='none')\n",
    "# Remove axis on right plot\n",
    "axes[1].get_yaxis().set_visible(False)\n",
    "# add colour legend\n",
    "patches_list=[Patch(facecolor=colour) for colour in colours.values()]\n",
    "axes[1].legend(patches_list, list(dict_map.keys()),loc='upper center', ncol =4, bbox_to_anchor=(0.5, -0.1))\n",
    "# Add plot titles\n",
    "axes[0].set_title('Classified Image Before Majority Filtering')\n",
    "axes[1].set_title('Classified Image After Majority Filtering')\n",
    "\n",
    "# make a copy of intermediate result\n",
    "lc_map_filtered=lc_map_postproc.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce998fb4-8426-46a1-9684-e8c274884eb5",
   "metadata": {},
   "source": [
    "## Apply rules using external layers\n",
    "Before applying reclassification using other layers, one thing to note for raster-based calculation is to make sure all rasters are in the same spatial reference and align with each other. Here we extract the `geobox` of the land cover map, which defines the location and resolution of the grid data including spatial reference. We will use it to reproject other layers to be aligned with the land cover map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017aa374-8140-44df-96ad-bf6efbbe8a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_geobox=lc_map.geobox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee75ff37-955c-4304-9b2f-62d32d0aa0e2",
   "metadata": {},
   "source": [
    "Now let's reclassify some classes using the external layers. First, we reclassify pixels classified as Water Body occuring at bottom of watersheds, i.e. height above nearest drainage below 45 m, or falling within OSM river networks as Water Body class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47515c1-b690-4499-a2a4-3b8eb127b8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproject hand layer\n",
    "hand=xr_reproject(hand, ds_geobox, resampling=\"average\")\n",
    "# convert to numpy array\n",
    "np_hand=hand.to_array().squeeze().to_numpy()\n",
    "# rasterise river network layer\n",
    "river_network_mask=xr_rasterize(gdf=river_network,\n",
    "                                  da=lc_map.squeeze(),\n",
    "                                  transform=ds_geobox.transform,\n",
    "                                  crs=output_crs)\n",
    "# convert to numpy array\n",
    "np_river_network_mask=river_network_mask.to_numpy()\n",
    "# apply the rule\n",
    "np_lc_map_postproc[((np_lc_map==dict_map['Water Body'])&(np_hand<=45))\n",
    "                   |(np_river_network_mask==1)]=dict_map['Water Body']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7277ce2a-363b-482c-b254-93da232b77eb",
   "metadata": {},
   "source": [
    "We then assign pixels overlapping google building polygons or WSF 2019 mask as built-up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e72cd0-ee13-4332-b6b7-430873016db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproject google buildings raster\n",
    "google_buildings_mask=xr_reproject(google_buildings, ds_geobox, resampling=\"average\")\n",
    "# convert to numpy array\n",
    "np_google_buildings_mask=google_buildings_mask.to_array().squeeze().to_numpy()\n",
    "# reproject WSF 2019 layer\n",
    "wsf2019=xr_reproject(wsf2019, ds_geobox, resampling=\"nearest\")\n",
    "# convert to numpy array\n",
    "np_wsf2019=wsf2019.to_array().squeeze().to_numpy()\n",
    "# apply rule\n",
    "np_lc_map_postproc[(np_google_buildings_mask==1)|(np_wsf2019==255)]=dict_map['Urban Settlement']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7da357-4159-4cda-91f6-03e170887daa",
   "metadata": {},
   "source": [
    "Moreover, we assume that Wetland too close (e.g. within 50m) to Settlements are likely misclassified, so we reclassify them as Annual Cropland instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c5f6ff-1d92-49a5-8335-96ef4188284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buffer Urban Settlement areas\n",
    "urban_buffered=binary_dilation(np_lc_map==dict_map['Urban Settlement'],footprint=disk(5))\n",
    "# apply rule\n",
    "np_lc_map_postproc[(urban_buffered==1)&(np_lc_map==dict_map['Wetland'])]=dict_map['Annual Cropland']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e009f314-7a4e-4e07-83b8-c2879e09fcfb",
   "metadata": {},
   "source": [
    "In addition, we assign pixels overlapping OSM road network as Urban Settlement class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65662eec-9b48-400b-bac1-c24465bec233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rasterise road network layer\n",
    "road_network_mask=xr_rasterize(gdf=road_network,\n",
    "                              da=lc_map.squeeze(),\n",
    "                              transform=ds_geobox.transform,\n",
    "                              crs=output_crs)\n",
    "# convert to numpy\n",
    "np_road_network_mask=road_network_mask.to_numpy()\n",
    "# apply the rule\n",
    "np_lc_map_postproc[np_road_network_mask==1]=dict_map['Urban Settlement']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3918b4-ad54-47e4-a7e4-ff11bc23c6ae",
   "metadata": {},
   "source": [
    "We can plot the maps to see a comparison before and after applying the rules using the external layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173e248c-d5dc-4d3b-bc27-0362e452edce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(24, 8))\n",
    "\n",
    "# Plot classified image before applying rules\n",
    "prediction_values=np.unique(lc_map_filtered)\n",
    "cmap=ListedColormap([colours[k] for k in prediction_values])\n",
    "norm = BoundaryNorm(list(prediction_values)+[np.max(prediction_values)+1], cmap.N)\n",
    "lc_map_filtered.plot.imshow(ax=axes[0], \n",
    "                   cmap=cmap,\n",
    "                   norm=norm,\n",
    "                   add_labels=True, \n",
    "                   add_colorbar=False,\n",
    "                   interpolation='none')\n",
    "\n",
    "# Plot classified image after applying rules\n",
    "# reconstruct dataArray\n",
    "lc_map_postproc=xr.DataArray(data=np_lc_map_postproc,dims=['y','x'],\n",
    "                             coords={'y':lc_map.y.to_numpy(), 'x':lc_map.x.to_numpy()})\n",
    "lc_map_postproc.plot.imshow(ax=axes[1], \n",
    "                   cmap=cmap,\n",
    "                   norm=norm,\n",
    "                   add_labels=True, \n",
    "                   add_colorbar=False,\n",
    "                   interpolation='none')\n",
    "# Remove axis on right plot\n",
    "axes[1].get_yaxis().set_visible(False)\n",
    "# add colour legend\n",
    "axes[1].legend(patches_list, list(dict_map.keys()),\n",
    "    loc='upper center', ncol =4, bbox_to_anchor=(0.5, -0.1))\n",
    "# Add plot titles\n",
    "axes[0].set_title('Classified Image Before Applying Rules')\n",
    "axes[1].set_title('Classified Image After Applying Rules')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f113f9-9a6b-414e-8973-8682f5309103",
   "metadata": {},
   "source": [
    "Now let's process all three locations by simply copying and putting together all the post-processing steps, and iterating through all three locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a606485-d563-479d-a7e5-6d59f859a5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_maps_postproc=[] # post-processed results\n",
    "for i in range(0,len(prediction_maps)):\n",
    "    lc_map=prediction_maps[i]\n",
    "    # convert to numpy array\n",
    "    np_lc_map=lc_map.squeeze().to_numpy()\n",
    "    # majority filtering for a smoother classification map\n",
    "    np_lc_map_postproc=modal(np_lc_map,footprint=disk(2),mask=np_lc_map!=0)\n",
    "    # get geobox\n",
    "    ds_geobox=lc_map.geobox\n",
    "    # reproject hand layer\n",
    "    hand=xr_reproject(hand, ds_geobox, resampling=\"average\")\n",
    "    # convert to numpy array\n",
    "    np_hand=hand.to_array().squeeze().to_numpy()\n",
    "    # rasterise river network layer\n",
    "    river_network_mask=xr_rasterize(gdf=river_network,\n",
    "                                      da=lc_map.squeeze(),\n",
    "                                      transform=ds_geobox.transform,\n",
    "                                      crs=output_crs)\n",
    "    # convert to numpy array\n",
    "    np_river_network_mask=river_network_mask.to_numpy()\n",
    "    # apply the rule\n",
    "    np_lc_map_postproc[((np_lc_map==dict_map['Water Body'])&(np_hand<=45))\n",
    "                       |(np_river_network_mask==1)]=dict_map['Water Body']\n",
    "    # reproject google buildings raster\n",
    "    google_buildings_mask=xr_reproject(google_buildings, ds_geobox, resampling=\"average\")\n",
    "    # convert to numpy array\n",
    "    np_google_buildings_mask=google_buildings_mask.to_array().squeeze().to_numpy()\n",
    "    # reproject WSF 2019 layer\n",
    "    wsf2019=xr_reproject(wsf2019, ds_geobox, resampling=\"nearest\")\n",
    "    # convert to numpy array\n",
    "    np_wsf2019=wsf2019.to_array().squeeze().to_numpy()\n",
    "    # apply rule\n",
    "    np_lc_map_postproc[(np_google_buildings_mask==1)|(np_wsf2019==1)]=dict_map['Urban Settlement']\n",
    "    # buffer Urban Settlement areas\n",
    "    urban_buffered=binary_dilation(np_lc_map==dict_map['Urban Settlement'],footprint=disk(5))\n",
    "    # apply rule\n",
    "    np_lc_map_postproc[(urban_buffered==1)&(np_lc_map==dict_map['Wetland'])]=dict_map['Annual Cropland']\n",
    "    # rasterise road network layer\n",
    "    road_network_mask=xr_rasterize(gdf=road_network,\n",
    "                                  da=lc_map.squeeze(),\n",
    "                                  transform=ds_geobox.transform,\n",
    "                                  crs=output_crs)\n",
    "    # convert to numpy\n",
    "    np_road_network_mask=road_network_mask.to_numpy()\n",
    "    # apply the rule\n",
    "    np_lc_map_postproc[np_road_network_mask==1]=dict_map['Urban Settlement']\n",
    "    \n",
    "    # reconstruct dataArray\n",
    "    lc_map_postproc=xr.DataArray(data=np_lc_map_postproc,dims=['y','x'],\n",
    "                             coords={'y':lc_map.y.to_numpy(), 'x':lc_map.x.to_numpy()})\n",
    "    # set spatial reference\n",
    "    lc_map_postproc.rio.write_crs(output_crs, inplace=True)\n",
    "    # append to list\n",
    "    prediction_maps_postproc.append(lc_map_postproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc9e53c-0b31-4fdc-b613-23da0c566a78",
   "metadata": {},
   "source": [
    "We can compare all final post-processed results with initial predictions without post-processing, along with the satellite images for comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fab9e08-ec61-43e2-a05e-33a8865be61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(prediction_maps)):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(24, 8))\n",
    "\n",
    "    # Plot true colour image\n",
    "    rgb(rgb_images[i].to_dataset(dim='band'),bands=[1,2,3],\n",
    "        ax=axes[0], percentile_stretch=(0.01, 0.99))\n",
    "    \n",
    "    # Plot initial classified image\n",
    "    prediction_values=np.unique(prediction_maps[i])\n",
    "    cmap=ListedColormap([colours[k] for k in prediction_values])\n",
    "    norm = BoundaryNorm(list(prediction_values)+[np.max(prediction_values)+1], cmap.N)\n",
    "    prediction_maps[i].plot.imshow(ax=axes[1], \n",
    "                   cmap=cmap,\n",
    "                   norm=norm,\n",
    "                   add_labels=True, \n",
    "                   add_colorbar=False,\n",
    "                   interpolation='none')\n",
    "    \n",
    "    # Plot post-processed classified image\n",
    "    prediction_maps_postproc[i].plot.imshow(ax=axes[2], \n",
    "                   cmap=cmap,\n",
    "                   norm=norm,\n",
    "                   add_labels=True, \n",
    "                   add_colorbar=False,\n",
    "                   interpolation='none')\n",
    "                   \n",
    "    # Remove axis on middle and right plot\n",
    "    axes[1].get_yaxis().set_visible(False)\n",
    "    axes[2].get_yaxis().set_visible(False)\n",
    "    # add colour legend\n",
    "    patches_list=[Patch(facecolor=colour) for colour in colours.values()]\n",
    "    axes[1].legend(patches_list, list(dict_map.keys()),\n",
    "        loc='upper center', ncol =4, bbox_to_anchor=(0.5, -0.1))\n",
    "    # Add plot titles\n",
    "    axes[0].set_title('True Colour Geomedian')\n",
    "    axes[1].set_title('Classified Image')\n",
    "    axes[2].set_title('Classified Image - Postprocessed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5690f01c-0333-4da0-8c22-c66cbf347be8",
   "metadata": {},
   "source": [
    "## Save as geotiff\n",
    "We can now export our post-processed results to sandbox disk as Cloud-Optimised GeoTIFFs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2077ff-46cb-47c0-8889-3739cf0a3afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(prediction_maps_postproc)):\n",
    "    write_cog(prediction_maps_postproc[i], 'Results/Rwanda_land_cover_prediction_postprocessed_2021_location_'+str(i)+'.tif', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fca9a2-0565-4363-80b7-ab0fb02ddfe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "01a9736267bf300689e8e016092cd01f0c67384dd94651ae6e139a291bc8cc97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

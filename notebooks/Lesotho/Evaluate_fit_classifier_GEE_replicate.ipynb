{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fe63114-79b1-46c6-931a-cbc2ea760e3b",
   "metadata": {},
   "source": [
    "This notebook implements class balancing before splitting the training data into subsets, training a random forest classifier on each split, evaluating model performance and saving the fitted models. For Lesotho this notebook is used twice in the workflow, first to train models to produce a reference/baseline land cover map using the unfiltered training data, second to train models to produce a land cover map for a target year (2021) using the filtered training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f5fe91-015f-42c7-8968-b6b7d631bfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import datacube\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score,cohen_kappa_score,confusion_matrix,ConfusionMatrixDisplay,balanced_accuracy_score\n",
    "from joblib import dump\n",
    "\n",
    "# file paths and attributes\n",
    "dict_map={1:'Urban',2:'Cropland',4:'Trees',6:'Water',7:'Wetland',9:'Shrubland',10:'Grassland',12:'Barren',14:'Irrigated_Agriculture'} # dictionary of class name corresponding to each class value\n",
    "# training_data='Results/landcover_training_data_2021_GEE.txt' # unfiltered training data\n",
    "training_data='Results/landcover_td2021_filtered.txt' # filtered training data\n",
    "class_name = 'LC_Class_I' # class label in integer format\n",
    "\n",
    "# define features used for training and prediction\n",
    "measurements = ['blue','green','red','red_edge_1','red_edge_2', 'red_edge_3','nir_1','nir_2','swir_1','swir_2','NDVI'] # band measurements and index\n",
    "column_names=[class_name]\n",
    "for measurement in measurements:\n",
    "    for i in range(6):\n",
    "        column_names.append(measurement+'_'+str(i))\n",
    "\n",
    "# import training data\n",
    "df_training_data= pd.read_csv(training_data,delimiter=' ') # read as pandas dataframe\n",
    "df_training_data=df_training_data[column_names] # keep only useful attributes\n",
    "print('training data:\\n',df_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9db741b-8373-469d-903b-d80304670029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of training samples by class\n",
    "class_counts=df_training_data[class_name].value_counts()\n",
    "class_indices=class_counts.index\n",
    "class_legends=[dict_map[class_indices[i]] for i in range(len(class_indices))]\n",
    "plt.figure(figsize=(10,5))\n",
    "ax=plt.bar(class_legends,height=class_counts.to_numpy())\n",
    "plt.bar_label(ax)\n",
    "plt.gca().set_ylabel('Number of training samples')\n",
    "plt.gca().set_xlabel('Land cover class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9518325-9162-441f-8aa0-72a425e7382b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/geopandas/_compat.py:112: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ncpus = 62\n",
      "      LC_Class_I  blue_0  blue_1  blue_2  blue_3  blue_4  blue_5  green_0  \\\n",
      "0            1.0   530.0   526.0   772.0   876.0   640.0   602.0    862.0   \n",
      "1            1.0   923.0   835.0   834.0   918.0  1020.0  1108.0   1185.0   \n",
      "2            1.0   616.0   525.0   574.0   603.0   676.0   884.0    875.0   \n",
      "3            1.0   885.0   652.0   821.0   988.0   957.0   836.0   1211.0   \n",
      "4            1.0  1267.0  1093.0  1062.0  1128.0  1286.0  1395.0   1803.0   \n",
      "...          ...     ...     ...     ...     ...     ...     ...      ...   \n",
      "3132        14.0   346.0   382.0   476.0   575.0   729.0   474.0    720.0   \n",
      "3133        14.0   380.0   375.0   400.0   742.0   838.0   584.0    790.0   \n",
      "3134        14.0   429.0   358.0   446.0   563.0   684.0   424.0    839.0   \n",
      "3135        14.0   453.0   354.0   349.0   389.0   418.0   501.0    691.0   \n",
      "3136        14.0   462.0   306.0   317.0   300.0   386.0   429.0    698.0   \n",
      "\n",
      "      green_1  green_2  ...  swir_2_3  swir_2_4  swir_2_5  NDVI_0  NDVI_1  \\\n",
      "0       897.0   1050.0  ...    2257.0    1934.0    1746.0  5665.0  4575.0   \n",
      "1      1170.0   1120.0  ...    2641.0    2876.0    3061.0  2606.0  2179.0   \n",
      "2       834.0    857.0  ...    2196.0    2282.0    2016.0  4976.0  4188.0   \n",
      "3      1024.0   1172.0  ...    2299.0    2243.0    1897.0  4204.0  5501.0   \n",
      "4      1626.0   1577.0  ...    2307.0    2568.0    2385.0   787.0   843.0   \n",
      "...       ...      ...  ...       ...       ...       ...     ...     ...   \n",
      "3132    797.0    776.0  ...    2604.0    3028.0    2123.0  6033.0  4620.0   \n",
      "3133    789.0    676.0  ...    2650.0    2764.0    1869.0  6783.0  4318.0   \n",
      "3134    783.0    776.0  ...    2628.0    2926.0    1971.0  4667.0  4172.0   \n",
      "3135    581.0    535.0  ...    1744.0    1869.0    1735.0  5319.0  4503.0   \n",
      "3136    515.0    450.0  ...    1295.0    1619.0    1538.0  5974.0  4801.0   \n",
      "\n",
      "      NDVI_2  NDVI_3  NDVI_4  NDVI_5    random  \n",
      "0     2224.0  1776.0  3175.0  4405.0  0.150924  \n",
      "1     1521.0  1361.0  1423.0  1610.0  0.526948  \n",
      "2     2716.0  2000.0  2140.0  2904.0  0.349158  \n",
      "3     3535.0  2119.0  3040.0  5309.0  0.785947  \n",
      "4      238.0  -106.0    76.0   467.0  0.778171  \n",
      "...      ...     ...     ...     ...       ...  \n",
      "3132  2317.0  2183.0  2516.0  2979.0  0.506644  \n",
      "3133  2500.0  2121.0  2327.0  4214.0  0.926156  \n",
      "3134  1981.0  1700.0  1818.0  2151.0  0.917078  \n",
      "3135  3291.0  2509.0  2250.0  3633.0  0.713510  \n",
      "3136  3494.0  2523.0  2427.0  4560.0  0.688219  \n",
      "\n",
      "[3137 rows x 68 columns]\n",
      "dimension of training data:  (2177, 67)\n",
      "dimension of training data:  (2243, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48715/877782029.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_training_split['random']=np.random.uniform(size=df_training_split.shape[0])\n",
      "/tmp/ipykernel_48715/877782029.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_training_split['random']=np.random.uniform(size=df_training_split.shape[0])\n",
      "/tmp/ipykernel_48715/877782029.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_training_split['random']=np.random.uniform(size=df_training_split.shape[0])\n",
      "/tmp/ipykernel_48715/877782029.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_training_split['random']=np.random.uniform(size=df_training_split.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension of training data:  (2173, 67)\n",
      "dimension of training data:  (2193, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48715/877782029.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_training_split['random']=np.random.uniform(size=df_training_split.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension of training data:  (2192, 67)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Results/RF_models_using_filtered_td_GEE_replicate.joblib']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split training data into five subsets, train and evaluate random forest classification model on each subset\n",
    "rf_models=[] # initialise a list of fitted models\n",
    "mean_acc=[] # initialise a list of overall accuracies\n",
    "df_training_data['random']=np.random.uniform(size=df_training_data.shape[0]) # add a uniform distribution random number attribte which will be used for random splitting\n",
    "for val in [0,0.2,0.4,0.6,0.8]:\n",
    "    # split training data into training and validation subsets\n",
    "    df_training_split=df_training_data[(df_training_data['random']<val)|(df_training_data['random']>=(val+0.2))] # extract training subset\n",
    "    df_validation_split=df_training_data[(df_training_data['random']>=val)&(df_training_data['random']<(val+0.2))] # extract validation subset\n",
    "#     df_training_split=df_training_data # using all data for training instead\n",
    "    df_training_split['random']=np.random.uniform(size=df_training_split.shape[0]) # update the random numbers for training split\n",
    "    \n",
    "    # reduce sample sizes of trees and wetland classes as they are over-represented\n",
    "    n_trees_train=len(df_training_split[df_training_split[class_name]==4])\n",
    "    n_wetland_train=len(df_training_split[df_training_split[class_name]==7])\n",
    "    if n_trees_train>300: # limit to 300\n",
    "        indices_drop=df_training_split[df_training_split[class_name]==4].sample(n=n_trees_train-300).index\n",
    "        df_training_split=df_training_split.drop(indices_drop).reset_index(drop=True)\n",
    "    if n_wetland_train>150: # limit to 150\n",
    "        indices_drop=df_training_split[df_training_split[class_name]==7].sample(n=n_wetland_train-150).index\n",
    "        df_training_split=df_training_split.drop(indices_drop).reset_index(drop=True)\n",
    "    df_training_split=df_training_split[column_names] # keep only useful attributes\n",
    "    model_input=df_training_split.to_numpy() # convert training subset from pandas dataframe to numpy array\n",
    "    print('dimension of training data: ',model_input.shape)\n",
    "    \n",
    "    # fit a random classifier\n",
    "    rf=RandomForestClassifier(n_estimators=50,max_samples=0.5,min_samples_leaf=1,bootstrap=True,n_jobs=-1)\n",
    "    rf.fit(model_input[:,1:],model_input[:,0])\n",
    "    \n",
    "    # append the fitted model to the models list\n",
    "    rf_models.append(rf)\n",
    "    \n",
    "    # plot and print feature importance\n",
    "    order=np.argsort(rf.feature_importances_)\n",
    "    plt.figure(figsize=(5,30))\n",
    "    plt.barh(y=np.array(df_training_split.columns[1:])[order],width=rf.feature_importances_[order])\n",
    "    plt.gca().set_ylabel('Importance', labelpad=10)\n",
    "    plt.gca().set_xlabel('Variable', labelpad=10)\n",
    "    feat_importance_indices=np.argsort(rf.feature_importances_)[-20:]\n",
    "    print('most importance features: \\n',df_training_split.columns[1:][feat_importance_indices])\n",
    "    \n",
    "    # evaluate using validation split\n",
    "    df_validation_split=df_validation_split[column_names] # keep only useful attributes\n",
    "    model_test=df_validation_split.to_numpy() # convert validation subset from pandas dataframe to numpy array\n",
    "    print('dimension of validation data: ',model_test.shape)\n",
    "    predictions = rf.predict(model_test[:,1:])\n",
    "    overall_acc=accuracy_score(model_test[:, 0],predictions)\n",
    "    balanced_accuracy=balanced_accuracy_score(model_test[:, 0],predictions)\n",
    "    kappa=cohen_kappa_score(predictions,model_test[:, 0])\n",
    "    cm=confusion_matrix(model_test[:, 0], predictions)\n",
    "    disp=ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=[dict_map[rf.classes_[i]] for i in range(len(rf.classes_))])\n",
    "    mean_acc.append(overall_acc*100)\n",
    "    print('Overall accuracy: ',overall_acc*100,'%')\n",
    "    print('Balanced accuracy: ',balanced_accuracy*100,'%')\n",
    "    print('Kappa coefficient: ',kappa)\n",
    "    print('Confusion matrix:\\n')\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    disp.plot(ax=ax)\n",
    "    \n",
    "print('mean accuracy: ',np.mean(mean_acc),'%')\n",
    "# save the models\n",
    "# dump(rf_models, 'Results/RF_models_GEE_replicate.joblib') # model trained on the unfiltered training data\n",
    "dump(rf_models, 'Results/RF_models_using_filtered_td_GEE_replicate.joblib') # model trained on the filtered training data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

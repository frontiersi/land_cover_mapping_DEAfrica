{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62f4aa7b-6c59-4db3-8d77-16aca619f107",
   "metadata": {},
   "source": [
    "This notebook implements reclassification of irrigated croplands based on kmeans clustering, phenology and external layers information. More information on vegetation phenology in DE Africa: https://docs.digitalearthafrica.org/en/latest/sandbox/notebooks/Real_world_examples/Phenology_optical.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2c4c23d-2125-4b7a-892e-e6989451d0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ncpus = 62\n",
      "Lethoso bbox:  27.011232336601374 -30.67784748254426 29.4573649650311 -28.57059736718119\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import datacube\n",
    "import warnings\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "from rasterio.enums import Resampling\n",
    "from odc.io.cgroups import get_cpu_quota\n",
    "from odc.algo import xr_geomedian\n",
    "from datacube.utils.cog import write_cog\n",
    "from deafrica_tools.datahandling import load_ard\n",
    "from deafrica_tools.bandindices import calculate_indices\n",
    "from deafrica_tools.classification import collect_training_data\n",
    "from deafrica_tools.spatial import xr_vectorize\n",
    "from sklearn.cluster import KMeans\n",
    "from skimage.measure import label,regionprops\n",
    "from odc.algo import xr_reproject\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from deafrica_tools.temporal import xr_phenology\n",
    "\n",
    "# get number of CPUs available\n",
    "ncpus=round(get_cpu_quota()) \n",
    "print('ncpus = '+str(ncpus))\n",
    "\n",
    "# parameters\n",
    "crs='epsg:32735' # output crs: WGS84/UTM Zone 35S\n",
    "class_name = 'LC_Class_I' # class label in integer format\n",
    "fill_nan_value=-999 # value to replace nans in query results\n",
    "\n",
    "# file paths of produced and external data\n",
    "lesotho_tiles_shp='Data/Lesotho_boundaries_projected_epsg32735_tiles.shp' # Lesotho tiles\n",
    "crops_shp='Data/signatures_crop.shp' # crop signature data\n",
    "lacowiki_irrigated_shp='Data/lacowiki_irrigated.shp' # irrigated crops locations collected using laco wiki\n",
    "manual_irrigated_shp='Data/manual_irrigated.shp' # manually selected irrigated cropland points\n",
    "classification2021_raster='Results/Land_cover_prediction_balanced_newest_DEAfrica_2021_mosaic.tif' # land cover map of 2021\n",
    "hand_raster='Data/hand_Lesotho.tif' # Hydrologically adjusted elevations, i.e. height above the nearest drainage (hand)\n",
    "path_crop_signatures = \"Results/signatures_crop_masked.txt\" # crop signature file\n",
    "\n",
    "# import Lesotho tiles and get bounding boxes\n",
    "lesotho_tiles=gpd.read_file(lesotho_tiles_shp).to_crs(crs) # get bounding boxes of tiles covering Lesotho\n",
    "tile_bboxes=lesotho_tiles.bounds\n",
    "\n",
    "# load produced land cover map and hydrology layer\n",
    "landcover2021=rioxarray.open_rasterio(classification2021_raster).astype(np.uint8).squeeze() # import land cover map of 2021\n",
    "hand=xr.open_dataset(hand_raster,engine=\"rasterio\").squeeze() # import hand layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74054131-ab2e-491e-97f9-1ce26231bed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names of extracted crop signature data:\n",
      " ['LC_Class_I', 'NDVI_0', 'NDVI_1', 'NDVI_2', 'NDVI_3', 'NDVI_4', 'NDVI_5']\n",
      "Extracted crop signature data:\n",
      " [[ 2.          0.77307844  0.60772556 ...  0.15909576  0.17368871\n",
      "   0.23625842]\n",
      " [ 2.          0.62086058  0.5040369  ...  0.22507554  0.21043773\n",
      "   0.37491533]\n",
      " [ 2.          0.76117373  0.64610529 ...  0.2214182   0.24623114\n",
      "   0.41516247]\n",
      " ...\n",
      " [14.          0.72985578  0.62210095 ...  0.16638842  0.21920387\n",
      "   0.3135564 ]\n",
      " [14.          0.69225812  0.63471973 ...  0.16636637  0.2257608\n",
      "   0.38130739]\n",
      " [14.          0.69706637  0.60305339 ...  0.20926754  0.20780741\n",
      "   0.34756258]]\n",
      "[[0.39837986 0.40138236 0.24828665 0.1896367  0.1895221  0.24874808]\n",
      " [0.64913964 0.59250927 0.29207408 0.21088655 0.21407048 0.34632248]]\n",
      "cluster corresponding to irrigated croplands:  1\n"
     ]
    }
   ],
   "source": [
    "# extract or load signatures of the reference crop locations (only geomedians of NDVI)\n",
    "if os.path.exists(path_crop_signatures): # if crop signature file exists, load data\n",
    "    # read in generated signature data\n",
    "    crop_signatures_data= pd.read_csv(path_crop_signatures,delimiter=' ')\n",
    "    column_names_crops=list(crop_signatures_data.columns)\n",
    "    crop_signatures_data=crop_signatures_data.to_numpy()\n",
    "else: # otherwise extract crop signature data using crop location points\n",
    "    # import crop refrence points from various sources\n",
    "    crops=gpd.read_file(crops_shp).to_crs('epsg:4326')\n",
    "    lacowiki_irrigated=gpd.read_file(lacowiki_irrigated_shp).to_crs('epsg:4326')\n",
    "    manual_irrigated=gpd.read_file(manual_irrigated_shp).to_crs('epsg:4326')\n",
    "    \n",
    "    # subset,assign class and merge crop signature geodataframes\n",
    "    crops=crops.loc[crops[class_name]==2]\n",
    "    lacowiki_irrigated=lacowiki_irrigated.loc[lacowiki_irrigated['ValValue']=='14']\n",
    "    lacowiki_irrigated[class_name]=14\n",
    "    manual_irrigated[class_name]=14\n",
    "    crop_signatures=pd.concat([crops,lacowiki_irrigated,manual_irrigated]).reset_index(drop=True)\n",
    "    crop_signatures=crop_signatures[[class_name,'geometry']] # drop unused columns\n",
    "    print('Cropland reference points:\\n',crop_signatures)\n",
    "    \n",
    "    # filtering out training points not classified as croplands on 2021 land cover map\n",
    "    indices_remove=[] # indices of rows to remove\n",
    "    for i in range(len(crop_signatures)):\n",
    "        lc_class=landcover2021.sel({'x':[crop_signatures.iloc[i].geometry.x],\n",
    "                                    'y':[crop_signatures.iloc[i].geometry.y]}, \n",
    "                                   method=\"nearest\").to_numpy().squeeze() # identify pixel values corresponding to the crop points\n",
    "        if lc_class!=2:\n",
    "            indices_remove.append(i)\n",
    "    crop_signatures_filtered=crop_signatures.drop(indices_remove).reset_index(drop=True) # remove these points\n",
    "    print('Cropland reference points after filtering:\\n',crop_signatures_filtered)\n",
    "    \n",
    "    # extract crop features (only geomedians of NDVI) using the crop reference locations\n",
    "    # set up ODC query: only two bands for NDVI calculation\n",
    "    query = {\n",
    "        'time': ('2021-01', '2021-12'),\n",
    "        'measurements': ['red','nir_1'],\n",
    "        'output_crs': crs,\n",
    "        'resolution': (-10, 10)\n",
    "    } \n",
    "    # define a function to feature layers\n",
    "    def feature_func_crops(query):\n",
    "        #connect to the datacube\n",
    "        dc = datacube.Datacube(app='feature_layers_crops')\n",
    "        # query bands\n",
    "        ds = load_ard(dc=dc,\n",
    "                      products=['s2_l2a'],\n",
    "                      group_by='solar_day',\n",
    "                      verbose=False,\n",
    "                      **query)\n",
    "        # calculate NDVI\n",
    "        ds = calculate_indices(ds,\n",
    "                               index=['NDVI'],\n",
    "                               drop=True, \n",
    "                               satellite_mission='s2')\n",
    "        # calculate geomedians within each two-month interval\n",
    "        ds=ds.resample(time='2MS').map(xr_geomedian)\n",
    "        # stack multi-temporal measurements and rename them\n",
    "        n_time=ds.dims['time']\n",
    "        list_measurements=list(ds.keys())\n",
    "        ds_stacked=None\n",
    "        for j in range(len(list_measurements)):\n",
    "            for k in range(n_time):\n",
    "                variable_name=list_measurements[j]+'_'+str(k)\n",
    "                measure_single=ds[list_measurements[j]].isel(time=k).rename(variable_name)\n",
    "                if ds_stacked is None:\n",
    "                    ds_stacked=measure_single\n",
    "                else:\n",
    "                    ds_stacked=xr.merge([ds_stacked,measure_single],compat='override')\n",
    "        return ds_stacked\n",
    "    # extract features using the crop points\n",
    "    column_names_crops, crop_signatures_data = collect_training_data(gdf=crop_signatures_filtered,\n",
    "                                                               dc_query=query,\n",
    "#                                                                ncpus=ncpus,\n",
    "                                                               ncpus=10,\n",
    "                                                               field=class_name,\n",
    "                                                               zonal_stats=None,\n",
    "                                                               feature_func=feature_func_crops,\n",
    "                                                               return_coords=False)\n",
    "    pd_crop_signatures=pd.DataFrame(data=crop_signatures_data,columns=column_names_crops)\n",
    "    pd_crop_signatures.to_csv(path_crop_signatures, header=True, index=None, sep=' ') # save as txt file\n",
    "print('Column names of extracted crop signature data:\\n',column_names_crops)\n",
    "print('Extracted crop signature data:\\n',crop_signatures_data)\n",
    "\n",
    "# fit a kmeans clustering model and identify cluster corresponding to irrigated croplands\n",
    "kmeans_model=KMeans(n_clusters=2, random_state=1).fit(crop_signatures_data[:,1:].astype('float32')) # fit a kmeans clusterer of 2 clusters\n",
    "print(kmeans_model.cluster_centers_)\n",
    "cluster_irrigated=0 # initialise cluster of irrigated crops\n",
    "if np.sum(kmeans_model.cluster_centers_[0,:])>np.sum(kmeans_model.cluster_centers_[1,:]): # find cluster with larger mean NDVI\n",
    "    cluster_irrigated=0\n",
    "else:\n",
    "    cluster_irrigated=1\n",
    "print('cluster corresponding to irrigated croplands: ',cluster_irrigated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1a2539-9dac-438e-98d1-7a4e29130309",
   "metadata": {},
   "source": [
    "loop through tiles: identify irrigated croplands based on:\n",
    "1.clustering 2. small NDVI integral over time 3. external layers 4. connected region size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91c4325-2e5d-4eb9-8213-02ef32e33453",
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_stats = ['SOS','EOS','LOS','Trough'] # phenology statistics needed for small NDVI integral calculation\n",
    "for i in range(len(tile_bboxes)):\n",
    "    x_min,y_min,x_max,y_max=tile_bboxes.iloc[i]\n",
    "    print('Processing tile ',i,'with bbox of ',x_min,y_min,x_max,y_max)\n",
    "    \n",
    "    # calculate small integrated NDVI\n",
    "    # set up ODC query: only two bands for NDVI calculation\n",
    "    query = {\n",
    "        'x': (x_min,x_max),\n",
    "        'y': (y_min,y_max),\n",
    "        'time': ('2021-01', '2021-12'),\n",
    "        'measurements': ['red','nir_1'],\n",
    "        'resolution': (-10, 10),\n",
    "        'crs':crs,\n",
    "        'output_crs':crs\n",
    "    }\n",
    "    start_time = time.time() # start timing how long it takes\n",
    "    # connect to the datacube\n",
    "    dc = datacube.Datacube(app='integrated_NDVI')\n",
    "    # query bands\n",
    "    ds_multitime = load_ard(dc=dc,\n",
    "                  products=['s2_l2a'],\n",
    "                  group_by='solar_day',\n",
    "                  verbose=False,\n",
    "                  **query)\n",
    "     # calculate NDVI\n",
    "    ds_multitime = calculate_indices(ds_multitime,\n",
    "                           index=['NDVI'],\n",
    "                           drop=True, # NOTE: here keeps only NDVI band\n",
    "                           satellite_mission='s2')\n",
    "    # fill nodata by linear interpolation\n",
    "    ds_multitime=ds_multitime.interpolate_na(dim='time',method='linear',use_coordinate=True,fill_value='extrapolate')\n",
    "    print(\"%s seconds spent on data query for one tile\" % (time.time() - start_time))\n",
    "    print('multi-temporal dataset: \\n',ds_multitime)\n",
    "    \n",
    "    # calculate phenology stats using multi-temporal NDVI\n",
    "    \n",
    "#     # my understanding of how NDVI small integral should be calculated:\n",
    "#     stats=xr_phenology(ds_multitime['NDVI'],method_sos='first',\n",
    "#                        method_eos='last',stats=pheno_stats,verbose=False)\n",
    "#     ds_growing_season=xr.where((ds_multitime['time.dayofyear']>=stats['SOS'])&(ds_multitime['time.dayofyear']<=stats['EOS']),\n",
    "#             ds_multitime,0) # set out of growing season values as 0 so that they won't be included in integral calculation\n",
    "#     integrated_ndvi=ds_growing_season.assign_coords(time=ds_multitime['time.dayofyear'].values/365.0).integrate(coord='time') # calculate integral\n",
    "#     del ds_growing_season\n",
    "#     integrated_ndvi['NDVI']=integrated_ndvi['NDVI']*365.0/stats['LOS'] # normalise integral\n",
    "#     integrated_ndvi['NDVI']=integrated_ndvi['NDVI']-stats['Trough'] # small integral\n",
    "\n",
    "    # GEE's calculation of NDVI small integral calculation:\n",
    "    ds_multitime=ds_multitime.resample(time='2MS').map(xr_geomedian) # calculate geomedians within each two-month interval\n",
    "    integrated_ndvi=ds_multitime.isel(time=[0,1,2]).assign_coords(time=[0,0.5,1]).integrate(coord='time') # assign 'time' for integration calculation\n",
    "#     integrated_ndvi=ds_multitime.assign_coords(time=[0,0.2,0.4,0.6,0.8,1]).integrate(coord='time') # assign 'time' for integration calculation\n",
    "\n",
    "    np_integrated_ndvi=integrated_ndvi['NDVI'].to_numpy()\n",
    "    del integrated_ndvi\n",
    "    \n",
    "    # apply clustering into irrigated/non-irrigated crops using the trained kmeans clusterer\n",
    "    # first need to calculate input feature for clustering using the time-series NDVI\n",
    "#     ds_multitime=ds_multitime.resample(time='2MS').map(xr_geomedian) # calculate geomedians within each two-month interval\n",
    "    ds_geobox=ds_multitime.geobox # get geobox\n",
    "    print('geobox for integrated NDVI dataset: ',ds_geobox)\n",
    "    # convert multi-temporal S2 dataset to multiband dataset\n",
    "    n_time=ds_multitime.dims['time']\n",
    "    list_measurements=list(ds_multitime.keys())\n",
    "    ds_stacked=None\n",
    "    for j in range(len(list_measurements)):\n",
    "        for k in range(n_time):\n",
    "            variable_name=list_measurements[j]+'_'+str(k)\n",
    "            measure_single=ds_multitime[list_measurements[j]].isel(time=k).rename(variable_name)\n",
    "            if ds_stacked is None:\n",
    "                ds_stacked=measure_single\n",
    "            else:\n",
    "                ds_stacked=xr.merge([ds_stacked,measure_single],compat='override')\n",
    "    print('stacked geomedian dataset: \\n',ds_stacked)\n",
    "    \n",
    "    # then apply kmeans clustering using trained clusterer for all pixels\n",
    "    np_all_data=ds_stacked.to_dataframe()[column_names_crops[1:]].to_numpy() # exclude class column which won't be used for clustering\n",
    "#     indices_nan=np.argwhere(np.isnan(np_all_data).any(axis=1)) # identify rows with nan\n",
    "#     print('number of pixels with nan: ',len(indices_nan))\n",
    "#     np_all_data[np.isnan(np_all_data)]=fill_nan_value # fill nans so that kmeans can be used\n",
    "    labels=kmeans_model.predict(np_all_data)\n",
    "#     labels[indices_nan]=2 # change the cluster values of those nan pixels to be excluded from irrigated crops\n",
    "    labels=np.reshape(labels,(ds_stacked.dims['y'],ds_stacked.dims['x'])) # reshape clustering results to 2D array\n",
    "\n",
    "    \n",
    "    # apply rules to reclassify irrigated/non-irrigated crops based on the clustering result and external layers\n",
    "    landcover2021_tile=xr_reproject(landcover2021.to_dataset(name='band_data'), \n",
    "                                    ds_geobox, resampling=\"nearest\") # clip land cover result to tile boundary\n",
    "    np_landcover2021=landcover2021_tile.to_array().squeeze().to_numpy() # covert to numpy array\n",
    "    np_landcover2021_post=np_landcover2021.copy() # initialise post-processed land cover array\n",
    "    # query dem slope layer withim title bbox\n",
    "    dc = datacube.Datacube(app='slope_layer')\n",
    "    query_dem= {\n",
    "        'x': (x_min,x_max),\n",
    "        'y': (y_max,y_min),\n",
    "        'resolution':(-10, 10),\n",
    "        'crs':crs,\n",
    "        'output_crs': crs,\n",
    "        'measurements':['slope']\n",
    "    }\n",
    "    dem_slope = dc.load(product=\"dem_srtm_deriv\", **query_dem).squeeze()\n",
    "    np_dem_slope=dem_slope['slope'].to_numpy() # convert to numpy array\n",
    "    # load hand layer within tile bbox\n",
    "    hand=xr_reproject(hand, ds_geobox, resampling=\"average\")\n",
    "    np_hand=hand.to_array().squeeze().to_numpy() # convert to numpy array\n",
    "    # apply rules using clustering result and the loaded layers\n",
    "    irrigated_mask=(labels==cluster_irrigated)&(np_integrated_ndvi>=0.5)&(np_dem_slope<=10)&(np_hand<=45)&(np_landcover2021==2)\n",
    "    \n",
    "    # only keeping irrigated corps regions with number of pixels >= 100\n",
    "    irrigated_mask_filtered=np.zeros_like(irrigated_mask) # initialise a copy of irrigated crop mask\n",
    "    irrigated_counts=np.zeros_like(irrigated_mask,dtype='uint32') # initialise region count array\n",
    "    label_image=label(irrigated_mask) # label regions\n",
    "    for region_prop in regionprops(label_image): # loop through regions to calculate area property\n",
    "        irrigated_counts[label_image==region_prop.label]=region_prop.area\n",
    "    irrigated_mask_filtered[irrigated_counts>=100]=1 # update mask based on region size\n",
    "    np_landcover2021_post[irrigated_mask_filtered]=14 # update the land cover map\n",
    "\n",
    "    # convert updated numpy array back result back to DataArray\n",
    "    landcover2021_tile_post=xr.DataArray(data=np_landcover2021_post,\n",
    "                                         dims=['y','x'],\n",
    "                                         coords={'y':landcover2021_tile.y.to_numpy(),\n",
    "                                                 'x':landcover2021_tile.x.to_numpy()})\n",
    "    landcover2021_tile_post.rio.write_crs(crs, inplace=True) # add crs\n",
    "    \n",
    "    # export as geotiff\n",
    "    write_cog(landcover2021_tile_post, 'Results/Land_cover2021_postproc_step1_tile_'+str(i)+'.tif', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aad85c5-0f11-4bd6-86ec-ea55cd9e44c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "# merge into a mosaic once all tiles are processed\n",
    "! gdal_merge.py -o Results/Land_cover2021_postproc_step1_mosaic.tif -co COMPRESS=Deflate -ot Byte Results/Land_cover2021_postproc_step1_tile_*.tif"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

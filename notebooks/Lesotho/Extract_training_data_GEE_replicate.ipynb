{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8653278a-aba4-4115-8b88-e60f9f5e8d0a",
   "metadata": {},
   "source": [
    "This notebook extracts training data (feature layers) from the Open Data Cube (ODC) of Sentinel-2 multispectral images, using the (unfiltered) training datasets in 2021. The extracted training signatures will then be used to train a classifier and produce a reference/baseline land cover map, which will be used for training data filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91455c43-3ee0-4231-b066-8952b022df7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/geopandas/_compat.py:112: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/usr/local/lib/python3.8/dist-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/usr/local/lib/python3.8/dist-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ncpus = 62\n",
      "merged reference land cover survey points:\n",
      "       LC_Class_I                    geometry\n",
      "0              1  POINT (28.13225 -29.91072)\n",
      "1              1  POINT (28.58356 -30.07347)\n",
      "2              1  POINT (28.64013 -29.58167)\n",
      "3              1  POINT (28.35737 -30.04837)\n",
      "4              1  POINT (28.62472 -29.58144)\n",
      "...          ...                         ...\n",
      "3576           9  POINT (28.49727 -30.05149)\n",
      "3577           9  POINT (28.49652 -30.04917)\n",
      "3578           9  POINT (28.49811 -30.05004)\n",
      "3579           9  POINT (28.49828 -30.05074)\n",
      "3580           9  POINT (27.85065 -29.42685)\n",
      "\n",
      "[3581 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import datacube\n",
    "import warnings\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from odc.io.cgroups import get_cpu_quota\n",
    "from odc.algo import geomedian_with_mads, xr_geomedian\n",
    "from deafrica_tools.datahandling import load_ard\n",
    "from deafrica_tools.bandindices import calculate_indices\n",
    "from deafrica_tools.classification import collect_training_data\n",
    "\n",
    "# get number of cpus\n",
    "ncpus=round(get_cpu_quota())\n",
    "print('ncpus = '+str(ncpus))\n",
    "\n",
    "# file paths and attributes\n",
    "traning_points_path = 'Data/landcover_td2021.shp' # training data 2021\n",
    "shrubland_points_path = 'Data/signatures_shrublandSurvey.shp' # shrubland survey points\n",
    "lesotho_shp='Data/Lesotho_boundaries.shp' # Lesotho boundary shapefile\n",
    "class_name = 'LC_Class_I' # class label in integer format\n",
    "output_crs='epsg:32735' # output crs: WGS84/UTM Zone 35S\n",
    "crs='epsg:4326' # input crs: WGS84\n",
    "\n",
    "# Load reference land cover survey points and reproject\n",
    "training_data2021= gpd.read_file(traning_points_path).to_crs(crs) # read training points as geopandas dataframe\n",
    "training_data2021=training_data2021[[class_name,'geometry']] # select attributes\n",
    "df_shrubs=gpd.read_file(shrubland_points_path).to_crs(crs) # read shrubland survey points\n",
    "df_shrubs=df_shrubs[['land_cover','geometry']] # select attributes\n",
    "dict_map={'Shrubland':9,'Trees':4,'Grassland':10,'Irrigated_Agriculture':14}\n",
    "df_shrubs[class_name]=df_shrubs['land_cover'].map(dict_map) # mapping land attributes\n",
    "df_shrubs=df_shrubs[[class_name,'geometry']] # select attributes\n",
    "training_data2021=pd.concat([training_data2021,df_shrubs]).reset_index(drop=True) # concatenate training data\n",
    "print('merged reference land cover survey points:\\n',training_data2021)\n",
    "# print('filtered training points:\\n',training_data2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41087039-c157-465c-8487-534a77cd1f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting training data in parallel mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1f608a019f14b89be74e174dc2e9749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3581 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/odc/algo/_geomedian.py:106: RuntimeWarning: Mean of empty slice\n",
      "  data = nangeomedian_pcm(xx_data, **kw)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of possible fails after run 1 = 0.0 %\n",
      "Removed 0 rows wth NaNs &/or Infs\n",
      "Output shape:  (3581, 69)\n",
      "['LC_Class_I', 'blue_0', 'blue_1', 'blue_2', 'blue_3', 'blue_4', 'blue_5', 'green_0', 'green_1', 'green_2', 'green_3', 'green_4', 'green_5', 'red_0', 'red_1', 'red_2', 'red_3', 'red_4', 'red_5', 'red_edge_1_0', 'red_edge_1_1', 'red_edge_1_2', 'red_edge_1_3', 'red_edge_1_4', 'red_edge_1_5', 'red_edge_2_0', 'red_edge_2_1', 'red_edge_2_2', 'red_edge_2_3', 'red_edge_2_4', 'red_edge_2_5', 'red_edge_3_0', 'red_edge_3_1', 'red_edge_3_2', 'red_edge_3_3', 'red_edge_3_4', 'red_edge_3_5', 'nir_1_0', 'nir_1_1', 'nir_1_2', 'nir_1_3', 'nir_1_4', 'nir_1_5', 'nir_2_0', 'nir_2_1', 'nir_2_2', 'nir_2_3', 'nir_2_4', 'nir_2_5', 'swir_1_0', 'swir_1_1', 'swir_1_2', 'swir_1_3', 'swir_1_4', 'swir_1_5', 'swir_2_0', 'swir_2_1', 'swir_2_2', 'swir_2_3', 'swir_2_4', 'swir_2_5', 'NDVI_0', 'NDVI_1', 'NDVI_2', 'NDVI_3', 'NDVI_4', 'NDVI_5', 'x_coord', 'y_coord']\n",
      "[[      1.     530.     526. ...    4405.  655055. 6739795.]\n",
      " [      1.     588.     536. ...    2746.  630855. 6675075.]\n",
      " [      1.     923.     835. ...    1610.  652625. 6672015.]\n",
      " ...\n",
      " [      9.     418.     300. ...    4674.  526835. 6692935.]\n",
      " [      9.     546.     371. ...    3647.  582515. 6744425.]\n",
      " [      9.     585.     314. ...    5201.  608305. 6659595.]]\n"
     ]
    }
   ],
   "source": [
    "# define ODC query\n",
    "zonal_stats = None\n",
    "measurements = ['blue','green','red','red_edge_1','red_edge_2', 'red_edge_3','nir_1','nir_2','swir_1','swir_2']\n",
    "query = {\n",
    "    'time': ('2021-01', '2021-12'),\n",
    "    'measurements': measurements,\n",
    "    'output_crs': output_crs,\n",
    "    'resolution': (-10, 10)\n",
    "}\n",
    "\n",
    "# define a function to feature layers\n",
    "def feature_layers(query): \n",
    "    #connect to the datacube\n",
    "    dc = datacube.Datacube(app='feature_layers')\n",
    "    # query bands\n",
    "    ds = load_ard(dc=dc,\n",
    "                  products=['s2_l2a'],\n",
    "                  group_by='solar_day',\n",
    "                  verbose=False,\n",
    "#                   mask_filters=[(\"opening\", 2)], # morphological opening by 2 pixels to remove small masked regions\n",
    "                  **query)\n",
    "    # calculate NDVI\n",
    "    ds = calculate_indices(ds,\n",
    "                           index=['NDVI'],\n",
    "                           drop=False,\n",
    "                           satellite_mission ='s2')\n",
    "    # scale NDVI\n",
    "    ds['NDVI']=ds['NDVI']*10000\n",
    "    # calculate geomedians within each two-month interval\n",
    "    ds=ds.resample(time='2MS').map(xr_geomedian)\n",
    "    # interpolate nodata using mean of previous and next observation\n",
    "    ds=ds.interpolate_na(dim='time',method='linear',use_coordinate=False,fill_value='extrapolate').astype(np.int16)\n",
    "#     ds=ds.interpolate_na(dim='time',method='linear',use_coordinate=False)\n",
    "    # stack multi-temporal measurements and rename them\n",
    "    n_time=ds.dims['time']\n",
    "    list_measurements=list(ds.keys())\n",
    "    list_stack_measures=[]\n",
    "    for j in range(len(list_measurements)):\n",
    "        for k in range(n_time):\n",
    "            variable_name=list_measurements[j]+'_'+str(k)\n",
    "            measure_single=ds[list_measurements[j]].isel(time=k).rename(variable_name)\n",
    "            list_stack_measures.append(measure_single)\n",
    "    ds_stacked=xr.merge(list_stack_measures,compat='override')\n",
    "    return ds_stacked\n",
    "\n",
    "# extract features of training data\n",
    "column_names, model_input = collect_training_data(\n",
    "    gdf=training_data2021,\n",
    "    dc_query=query,\n",
    "#     ncpus=ncpus,\n",
    "    ncpus=35,\n",
    "    field=class_name,\n",
    "    zonal_stats=zonal_stats,\n",
    "    feature_func=feature_layers,\n",
    "    return_coords=True)\n",
    "print(column_names)\n",
    "print(np.array_str(model_input, precision=2, suppress_small=True))\n",
    "\n",
    "# export the filtered training data as txt file\n",
    "training_data2021_filtered=pd.DataFrame(data=model_input,columns=column_names)\n",
    "output_file = \"Results/landcover_training_data_2021_GEE.txt\"\n",
    "training_data2021_filtered.to_csv(output_file, header=True, index=None, sep=' ')\n",
    "\n",
    "# # export the filtered training data as a geojson\n",
    "# training_data2021_filtered=pd.DataFrame(data=model_input,columns=column_names)\n",
    "training_data2021_filtered=gpd.GeoDataFrame(training_data2021_filtered, \n",
    "                                            geometry=gpd.points_from_xy(training_data2021_filtered.x_coord,\n",
    "                                                                        training_data2021_filtered.y_coord,\n",
    "                                                                        crs=output_crs))\n",
    "output_file = \"Results/landcover_training_data_2021_GEE.geojson\"\n",
    "training_data2021_filtered.to_file(output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

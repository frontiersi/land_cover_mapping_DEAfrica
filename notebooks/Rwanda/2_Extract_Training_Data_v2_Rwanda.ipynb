{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bed71faf-13df-4e20-a384-a115d19e8baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ncpus = 31\n",
      "Training points in 2017:\n",
      "       LC_Class_I                        geometry\n",
      "0             10  POINT (143984.701 9752718.423)\n",
      "1             10  POINT (153889.277 9820168.209)\n",
      "2              2  POINT (114918.108 9704042.923)\n",
      "3              1   POINT (91083.953 9760423.815)\n",
      "4             10   POINT (86020.463 9789990.810)\n",
      "...          ...                             ...\n",
      "1995          10  POINT (210927.032 9800310.913)\n",
      "1996           6  POINT (143596.085 9810781.117)\n",
      "1997          10  POINT (146616.724 9786349.534)\n",
      "1998          12   POINT (79559.240 9800276.218)\n",
      "1999          10  POINT (235762.766 9795099.955)\n",
      "\n",
      "[2000 rows x 2 columns]\n",
      "Training points in 2017 after merging:\n",
      "       LC_Class_I                        geometry\n",
      "0             10  POINT (143984.701 9752718.423)\n",
      "1             10  POINT (153889.277 9820168.209)\n",
      "2              1  POINT (114918.108 9704042.923)\n",
      "3              1   POINT (91083.953 9760423.815)\n",
      "4             10   POINT (86020.463 9789990.810)\n",
      "...          ...                             ...\n",
      "1995          10  POINT (210927.032 9800310.913)\n",
      "1996           6  POINT (143596.085 9810781.117)\n",
      "1997          10  POINT (146616.724 9786349.534)\n",
      "1998          12   POINT (79559.240 9800276.218)\n",
      "1999          10  POINT (235762.766 9795099.955)\n",
      "\n",
      "[2000 rows x 2 columns]\n",
      "Collecting training data in parallel mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c1355a4901435886596914ede5553a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of possible fails after run 1 = 0.0 %\n",
      "Removed 0 rows wth NaNs &/or Infs\n",
      "Output shape:  (1789, 69)\n",
      "Number of training data after removing Nans and Infs:  1789\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import datacube\n",
    "import warnings\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from odc.io.cgroups import get_cpu_quota\n",
    "from odc.algo import xr_geomedian\n",
    "from deafrica_tools.datahandling import load_ard\n",
    "from deafrica_tools.bandindices import calculate_indices\n",
    "from deafrica_tools.classification import collect_training_data\n",
    "\n",
    "ncpus=round(get_cpu_quota())\n",
    "print('ncpus = '+str(ncpus))\n",
    "\n",
    "# file paths and attributes\n",
    "traning_points_path = 'Data/yearly_point_data_ Rwanda_2017.shp'\n",
    "class_name = 'LC_Class_I' # class label in integer format\n",
    "crs='epsg:32736' # WGS84/UTM Zone 36S\n",
    "zonal_stats = None\n",
    "\n",
    "training_points_2017= gpd.read_file(traning_points_path).to_crs(crs) # read training points as geopandas dataframe\n",
    "training_points_2017=training_points_2017[[class_name,'geometry']] # select attributes\n",
    "print('Training points in 2017:\\n',training_points_2017)\n",
    "\n",
    "# merge classes\n",
    "training_points_2017.loc[training_points_2017[class_name]==2,class_name]=1 # Open Forest (2) merged with Dense Forest (1) as Forest (1)\n",
    "# training_points_2017.loc[training_points_2017[class_name]==8,class_name]=6 # Wooded Grassland (8) merged with Open Grassland (6) as Grassland (6)\n",
    "print('Training points in 2017 after merging:\\n',training_points_2017)\n",
    "\n",
    "measurements = ['blue','green','red','red_edge_1','red_edge_2', 'red_edge_3','nir_1','nir_2','swir_1','swir_2']\n",
    "query = {\n",
    "    'time': ('2017-01', '2017-12'),\n",
    "    'measurements': measurements,\n",
    "    'output_crs': crs,\n",
    "    'resolution': (-10, 10)\n",
    "}\n",
    "# define a function to feature layers\n",
    "def feature_layers(query): \n",
    "    #connect to the datacube\n",
    "    dc = datacube.Datacube(app='feature_layers')\n",
    "    ds = load_ard(dc=dc,\n",
    "                  products=['s2_l2a'],\n",
    "                  group_by='solar_day',\n",
    "                  verbose=False,\n",
    "#                   mask_filters=[(\"opening\", 2)], # morphological opening by 2 pixels to remove small masked regions\n",
    "                  **query)\n",
    "    ds = calculate_indices(ds,\n",
    "                           index=['NDVI'],\n",
    "                           drop=False,\n",
    "                           satellite_mission='s2')\n",
    "    # interpolate nodata using mean of previous and next observation\n",
    "#     ds=ds.interpolate_na(dim='time',method='linear',use_coordinate=False,fill_value='extrapolate')\n",
    "    ds=ds.interpolate_na(dim='time',method='linear',use_coordinate=False)\n",
    "    # calculate geomedians within each two-month interval\n",
    "    ds=ds.resample(time='2MS').map(xr_geomedian)\n",
    "    # replace nan with a value so that the collect_training_data function will work\n",
    "#     ds=ds.fillna(fill_nan_value)\n",
    "    # stack multi-temporal measurements and rename them\n",
    "    n_time=ds.dims['time']\n",
    "    list_measurements=list(ds.keys())\n",
    "    ds_stacked=None\n",
    "    for j in range(len(list_measurements)):\n",
    "        for k in range(n_time):\n",
    "            variable_name=list_measurements[j]+'_'+str(k)\n",
    "            # print ('Stacking band ',list_measurements[j],' at time ',k)\n",
    "            measure_single=ds[list_measurements[j]].isel(time=k).rename(variable_name)\n",
    "            if ds_stacked is None:\n",
    "                ds_stacked=measure_single\n",
    "            else:\n",
    "                ds_stacked=xr.merge([ds_stacked,measure_single],compat='override')\n",
    "    return ds_stacked\n",
    "\n",
    "column_names, model_input = collect_training_data(gdf=training_points_2017,\n",
    "                                                  dc_query=query,\n",
    "                                                  ncpus=ncpus,\n",
    "                                                  field=class_name,\n",
    "                                                  zonal_stats=zonal_stats,\n",
    "                                                  feature_func=feature_layers,\n",
    "                                                  return_coords=True)\n",
    "print('Number of training data after removing Nans and Infs: ',model_input.shape[0])\n",
    "training_data_2017=pd.DataFrame(data=model_input,columns=column_names)\n",
    "# export the filtered training data as txt file\n",
    "output_file = \"Results/Rwanda_landcover_td2017_7_classes.txt\"\n",
    "training_data_2017.to_csv(output_file, header=True, index=None, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b4e45a-3a9f-456d-90fc-d1a4ad6436e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

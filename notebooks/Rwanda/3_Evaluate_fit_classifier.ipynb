{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48baac42-3f5b-40da-ac08-c785f27fa105",
   "metadata": {},
   "source": [
    "This notebook fits a random forest model using all the training data, inspects feature importance and evaluate model performance using five-fold cross validation. The trained model is saved and will be used to predict land cover of Rwanda using the filtered training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a990d69b",
   "metadata": {},
   "source": [
    "### load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4192b293-4aa7-4a21-9b93-5fe8bdf726ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import datacube\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score,cohen_kappa_score,confusion_matrix,ConfusionMatrixDisplay,balanced_accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc,balanced_accuracy_score, f1_score, precision_score, recall_score\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589bd1be",
   "metadata": {},
   "source": [
    "### load training data and set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acff7b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths and attributes\n",
    "dict_map={1:'Forest',5:'Grassland',7:'Shrubland',9:'Perennial Cropland',10:'Annual Cropland',11:'Wetland',12:'Water Body',13:'Urban Settlement',14:'Other Land'} # dictionary of class name corresponding to each class value\n",
    "training_data='Results/Training_features_Rwanda_filtered.txt' # filtered training data\n",
    "class_name = 'LC_Class_I' # class label in integer format\n",
    "\n",
    "# define features used for training and prediction\n",
    "measurements = ['blue','green','red','red_edge_1','red_edge_2', 'red_edge_3','nir_1','nir_2','swir_1','swir_2','NDVI']\n",
    "column_names=[class_name]\n",
    "for measurement in measurements:\n",
    "    for i in range(6):\n",
    "        column_names.append(measurement+'_'+str(i))\n",
    "\n",
    "# load training data as dataframe\n",
    "df_training_data= pd.read_csv(training_data,delimiter=' ') # read as pandas dataframe\n",
    "df_training_data=df_training_data[column_names] # keep only useful attributes\n",
    "print('training data \\n',df_training_data)\n",
    "\n",
    "# remove NaNs which were somehow export as zeros during extraction of training data\n",
    "df_training_data=df_training_data.loc[(df_training_data!=0).all(axis=1)].reset_index(drop=True)\n",
    "print('training data after removing nans\\n',df_training_data)\n",
    "\n",
    "# convert to numpy array\n",
    "model_input=df_training_data.to_numpy()\n",
    "print('dimension of loaded training data: ',model_input.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639b9536",
   "metadata": {},
   "source": [
    "### plot training samples distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b2669c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of training samples by class\n",
    "class_counts=df_training_data[class_name].value_counts()\n",
    "class_indices=class_counts.index\n",
    "class_legends=[dict_map[class_indices[i]] for i in range(len(class_indices))]\n",
    "plt.figure(figsize=(15,5))\n",
    "ax=plt.bar(class_legends,height=class_counts.to_numpy())\n",
    "plt.bar_label(ax)\n",
    "plt.gca().set_ylabel('Number of training samples')\n",
    "plt.gca().set_xlabel('Land cover class')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dd3de8",
   "metadata": {},
   "source": [
    "### fit classifier using optimal or pre-defined hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b1b641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # grid search to find optimal random forest classifier hyperparameters\n",
    "# cv=model_selection.StratifiedShuffleSplit(n_splits=5,random_state=1) # stratified shuffle K-fold splitting\n",
    "# rf = RandomForestClassifier()\n",
    "# grid_parameters={'n_estimators': [int(x) for x in np.linspace(start = 50, stop = 300, num = 10)],\n",
    "#                  'min_samples_split':[2,4],'max_features': ['sqrt', 'log2'], 'criterion':['gini', 'entropy', 'log_loss'],\n",
    "#                 'class_weight':['balanced', None]}\n",
    "# print('Grid searching best hyper-parameters...')\n",
    "# grid_search=model_selection.GridSearchCV(estimator = rf,param_grid=grid_parameters,cv=cv,scoring='f1_micro')\n",
    "# grid_search.fit(model_input[:,1:],model_input[:,0])\n",
    "# print('Optimal parameters: \\n',grid_search.best_params_)\n",
    "# rf = RandomForestClassifier(**grid_search.best_params_, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c792f664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a random classifier using pre-defined hyperparameters\n",
    "rf=RandomForestClassifier(n_estimators=200,max_samples=None,min_samples_leaf=1,bootstrap=True)\n",
    "rf.fit(model_input[:,1:],model_input[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850a8b2a",
   "metadata": {},
   "source": [
    "### plot feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343f1b2c-a90c-4e11-b29e-387a7bd09f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot and print feature importance\n",
    "order=np.argsort(rf.feature_importances_)\n",
    "plt.figure(figsize=(5,30))\n",
    "plt.barh(y=np.array(df_training_data.columns[1:])[order],width=rf.feature_importances_[order])\n",
    "plt.gca().set_ylabel('Importance', labelpad=10)\n",
    "plt.gca().set_xlabel('Variable', labelpad=10)\n",
    "feat_importance_indices=np.argsort(rf.feature_importances_)[-20:]\n",
    "print('most importance features: \\n',df_training_data.columns[1:][feat_importance_indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4d9cff",
   "metadata": {},
   "source": [
    "### save the fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff76ee42-97f7-4114-90c6-c261a0f24837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "dump(rf, 'Results/RF_model_Rwanda.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4234b409",
   "metadata": {},
   "source": [
    "### evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9f3e40-5028-4246-a51c-d9a2cbfe33f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model through cross validation\n",
    "skf=model_selection.StratifiedKFold(n_splits=5,shuffle=True,random_state=1) # stratified K-fold splitting\n",
    "overall_acc=model_selection.cross_val_score(rf,model_input[:,1:],model_input[:,0],cv=skf,scoring='accuracy')\n",
    "print('Overall accuracy from cv scores: ',np.mean(overall_acc))\n",
    "# print('Overall accuracy: ',np.mean(overall_acc)*100,'%')\n",
    "\n",
    "f1_macro=model_selection.cross_val_score(rf,model_input[:,1:],model_input[:,0],cv=skf,scoring='f1_macro')\n",
    "print('f1_macro from cv scores: ',np.mean(f1_macro))\n",
    "\n",
    "predictions=model_selection.cross_val_predict(rf,model_input[:,1:],model_input[:,0],cv=skf)\n",
    "print('Overall accuracy from cv predict: ',accuracy_score(model_input[:, 0],predictions))\n",
    "print('Balanced accuracy from cv predict: ',balanced_accuracy_score(model_input[:, 0],predictions))\n",
    "\n",
    "values=list(dict_map.keys())\n",
    "precision=precision_score(model_input[:,0],predictions,labels=values,average=None)\n",
    "print('Precision for each class: \\n',dict(zip([dict_map[value] for value in values],np.around(precision,3))))\n",
    "\n",
    "recall=recall_score(model_input[:,0],predictions,labels=values,average=None)\n",
    "print('Recall for each class: \\n',dict(zip([dict_map[value] for value in values],np.around(recall,3))))\n",
    "\n",
    "f1_scores=f1_score(model_input[:,0],predictions,labels=values,average=None)\n",
    "print('f1 score for each class: \\n',dict(zip([dict_map[value] for value in values],np.around(f1_scores,3))))\n",
    "\n",
    "cm=confusion_matrix(model_input[:, 0], predictions)\n",
    "disp=ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=[dict_map[rf.classes_[i]] for i in range(len(rf.classes_))])\n",
    "print('Confusion matrix:\\n')\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "disp.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bfe0b9-06b3-41fc-9954-cb4bdc737729",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "01a9736267bf300689e8e016092cd01f0c67384dd94651ae6e139a291bc8cc97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

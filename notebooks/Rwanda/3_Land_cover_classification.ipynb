{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "123f3d02-21f7-45e1-9b7a-a47b67ac03e7",
   "metadata": {},
   "source": [
    "This notebook loads in satellite data, predict national land cover of Rwanda using the pre-trained random forest model saved in previous notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fe68d4",
   "metadata": {},
   "source": [
    "### load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f25a5f8-7a17-43cf-b69f-87b46e8939aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import datacube\n",
    "import warnings\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from odc.algo import xr_geomedian\n",
    "import xarray as xr\n",
    "from joblib import load\n",
    "from deafrica_tools.classification import predict_xr\n",
    "from deafrica_tools.dask import create_local_dask_cluster\n",
    "from deafrica_tools.datahandling import load_ard\n",
    "from deafrica_tools.bandindices import calculate_indices\n",
    "from deafrica_tools.plotting import display_map\n",
    "from datacube.utils.cog import write_cog"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d02cdc2",
   "metadata": {},
   "source": [
    "### set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f5f2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths and attributes\n",
    "\n",
    "rwanda_tiles_shp='Data/Rwanda_tiles_epsg32736_smaller.shp' # tiles covering the entire country\n",
    "\n",
    "rf_model_path='Results/RF_model_Rwanda.joblib' # trained random forest model\n",
    "\n",
    "class_name = 'LC_Class_I' # class label in integer format\n",
    "crs='epsg:4326' # input crs: WGS84\n",
    "output_crs='epsg:32735' # output crs: WGS84/UTM Zone 35S\n",
    "# band mesurements for query\n",
    "measurements = ['blue','green','red','red_edge_1','red_edge_2', 'red_edge_3','nir_1','nir_2','swir_1','swir_2']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb3c7cde",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fecb2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and get bounding boxes of tiles covering Rwanda\n",
    "rwanda_tiles=gpd.read_file(rwanda_tiles_shp).to_crs(crs)\n",
    "tile_bboxes=rwanda_tiles.bounds\n",
    "print('tile boundaries for Rwanda: \\n',tile_bboxes)\n",
    "\n",
    "# load trained model\n",
    "rf_model = load(rf_model_path).set_params(n_jobs=1)\n",
    "print('loaded random forest models:\\n',rf_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d39e62f9",
   "metadata": {},
   "source": [
    "### define feature layer function - same as features for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222c8c86-bb7e-40e7-a653-351a938144de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to define features\n",
    "def feature_layers(query): \n",
    "    #connect to the datacube\n",
    "    dc = datacube.Datacube(app='feature_layers')\n",
    "    # query bands\n",
    "    ds = load_ard(dc=dc,\n",
    "                  products=['s2_l2a'],\n",
    "                  group_by='solar_day',\n",
    "                  verbose=False,\n",
    "                  **query)\n",
    "    # calculate NDVI\n",
    "    ds = calculate_indices(ds,index=['NDVI'],drop=False,satellite_mission='s2')\n",
    "    # calculate geomedians within each two-month interval\n",
    "    ds=ds.resample(time='2MS').map(xr_geomedian)\n",
    "\n",
    "    # stack multi-temporal measurements and rename them\n",
    "    n_time=ds.dims['time']\n",
    "    list_measurements=list(ds.keys())\n",
    "    list_stack_measures=[]\n",
    "    for j in range(len(list_measurements)):\n",
    "        for k in range(n_time):\n",
    "            variable_name=list_measurements[j]+'_'+str(k)\n",
    "            measure_single=ds[list_measurements[j]].isel(time=k).rename(variable_name)\n",
    "            list_stack_measures.append(measure_single)\n",
    "    ds_stacked=xr.merge(list_stack_measures,compat='override')\n",
    "    return ds_stacked"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a463da3",
   "metadata": {},
   "source": [
    "### set up dask cluster for parallel processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f2f932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a dask cluster\n",
    "create_local_dask_cluster(n_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff544e3",
   "metadata": {},
   "source": [
    "### run prediction for all tiles and export geotiffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d782ae8b-bcc8-4b3e-8e67-2fa2f910daef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loop through all tiles to predict land cover across the country\n",
    "for i in range(0,len(tile_bboxes)):\n",
    "    # get bounding box\n",
    "    minx,miny,maxx,maxy=tile_bboxes.iloc[i]\n",
    "    print('bounding box for tile ',i,': minx: ',minx,'miny: ',miny,'maxx: ',maxx,'maxy: ',maxy)\n",
    "\n",
    "    # load Sentinel-2 data\n",
    "    query = {\n",
    "        'x': (minx,maxx),\n",
    "        'y': (miny,maxy),\n",
    "        'time': ('2021-01', '2021-12'),\n",
    "        'measurements': measurements,\n",
    "        'resolution': (-10, 10),\n",
    "        'crs':crs,\n",
    "        'output_crs':output_crs,\n",
    "        'dask_chunks' : {'x':1000, 'y':1000} # update here as needed depending on tile size and sandbox instance\n",
    "    }\n",
    "\n",
    "    # calculate features\n",
    "    all_data = feature_layers(query) \n",
    "    print('stacked Sentinel-2 dataset:\\n',all_data)\n",
    "\n",
    "    # timing how long it takes for the prediction\n",
    "    start_time = time.time() \n",
    "    predicted = predict_xr(rf_model,all_data,proba=True,persist=False,clean=True).compute() # predict classes of all data using the RF model\n",
    "    print(\"%s seconds spent on predicting\" % (time.time() - start_time))  # print time spent on prediction\n",
    "    \n",
    "    # write final prediction as cog file\n",
    "    print('writing cog file...')\n",
    "    outname_prediction='Results/Land_cover_prediction_Rwanda_2021_tile_'+str(i)+'.tif'\n",
    "    outname_probability='Results/Land_cover_probability_Rwanda_2021_tile_'+str(i)+'.tif'\n",
    "    write_cog(predicted.Predictions, outname_prediction, overwrite=True)\n",
    "    write_cog(predicted.Probabilities.astype(int), outname_probability, overwrite=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9521bcf8",
   "metadata": {},
   "source": [
    "### do mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c682dd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gdal_merge.py -o Results/Land_cover_prediction_Rwanda_2021_tiles_mosaic.tif -co COMPRESS=Deflate -ot Byte Results/Land_cover_prediction_Rwanda_2021_tile_*.tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f571c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gdal_merge.py -o Results/Land_cover_probability_Rwanda_2021_tiles_mosaic.tif -co COMPRESS=Deflate -ot Byte Results/Land_cover_probability_Rwanda_2021_tile_*.tif"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "01a9736267bf300689e8e016092cd01f0c67384dd94651ae6e139a291bc8cc97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

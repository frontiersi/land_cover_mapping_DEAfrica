{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements training data filtering using kmeans method. The filtered training data will then be used to train a classifier and produce a land cover classification map in 2021."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import datacube\n",
    "import warnings\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "from odc.io.cgroups import get_cpu_quota\n",
    "from datacube.utils.cog import write_cog\n",
    "from odc.algo import xr_geomedian\n",
    "from deafrica_tools.datahandling import load_ard\n",
    "from deafrica_tools.bandindices import calculate_indices\n",
    "from deafrica_tools.classification import collect_training_data\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from rasterio.enums import Resampling\n",
    "from random_sampling import random_sampling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameters and file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths and attributes\n",
    "training_signature_path='Results/Training_features_Rwanda.txt'\n",
    "\n",
    "rf2017_path='Results/rwanda_landcover_2015_scheme_ii_classes_merged.tif'\n",
    "\n",
    "crs='epsg:32735' # WGS84/UTM Zone 35S\n",
    "measurements = ['blue','green','red','red_edge_1','red_edge_2', 'red_edge_3','nir_1','nir_2','swir_1','swir_2','NDVI']\n",
    "class_attr = 'LC_Class_I' # class label in integer format\n",
    "column_names=[class_attr]\n",
    "for measurement in measurements:\n",
    "    for i in range(6):\n",
    "        column_names.append(measurement+'_'+str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load training data, tiles and reference map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features= pd.read_csv(training_signature_path,sep=' ')\n",
    "training_features=training_features[column_names] # select attributes\n",
    "training_features[class_attr]=training_features[class_attr].astype(int)\n",
    "print('land cover survey points 2017:\\n',training_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_map = xr.open_dataset(rf2017_path,engine=\"rasterio\").astype(np.uint8).squeeze(\"band\", drop=True)\n",
    "# # reproject the raster\n",
    "reference_map= reference_map.rio.reproject(resolution=30, dst_crs=crs,resampling=Resampling.nearest)\n",
    "reference_map=reference_map.band_data\n",
    "print('Reference land cover classifcation raster:\\n',reference_map)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define queries and feature layer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    'time': ('2021-01', '2021-12'),\n",
    "    'output_crs': crs,\n",
    "    'resolution': (-10, 10)\n",
    "}\n",
    "# define a function to feature layers\n",
    "def feature_layers(query):\n",
    "    measurements = ['blue','green','red','red_edge_1','red_edge_2', 'red_edge_3','nir_1','nir_2','swir_1','swir_2']\n",
    "    #connect to the datacube\n",
    "    dc = datacube.Datacube(app='feature_layers')\n",
    "    ds = load_ard(dc=dc,\n",
    "                  products=['s2_l2a'],\n",
    "                  measurements=measurements,\n",
    "                  group_by='solar_day',\n",
    "                  verbose=False,\n",
    "#                   mask_filters=[(\"opening\", 2)], # morphological opening by 2 pixels to remove small masked regions\n",
    "                  **query)\n",
    "    ds = calculate_indices(ds,\n",
    "                           index=['NDVI'],\n",
    "                           drop=False,\n",
    "                           satellite_mission='s2')\n",
    "    # calculate geomedians within each two-month interval\n",
    "    ds=ds.resample(time='2MS').map(xr_geomedian)\n",
    "    # stack multi-temporal measurements and rename them\n",
    "    n_time=ds.dims['time']\n",
    "    list_measurements=list(ds.keys())\n",
    "    ds_stacked=None\n",
    "    for j in range(len(list_measurements)):\n",
    "        for k in range(n_time):\n",
    "            variable_name=list_measurements[j]+'_'+str(k)\n",
    "            measure_single=ds[list_measurements[j]].isel(time=k).rename(variable_name)\n",
    "            if ds_stacked is None:\n",
    "                ds_stacked=measure_single\n",
    "            else:\n",
    "                ds_stacked=xr.merge([ds_stacked,measure_single],compat='override')\n",
    "    return ds_stacked"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate random samples - stratified by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_classes=training_features[class_attr].unique() # get class labels\n",
    "n_class=len(lc_classes)\n",
    "print('land cover classes:\\n',lc_classes)\n",
    "n_samples=1000 # number of random samples per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_fname='Results/Random_samples_Rwanda.geojson'\n",
    "gpd_random_samples=random_sampling(da=reference_map,n=1000,sampling='stratified_random',\n",
    "                                   min_sample_n=50,out_fname=out_fname,class_attr=class_attr,drop_value=0)\n",
    "gpd_random_samples[class_attr]=gpd_random_samples[class_attr].astype(int)\n",
    "gpd_random_samples=gpd_random_samples.set_crs(reference_map.rio.crs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features for the random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect the number of CPUs\n",
    "ncpus=round(get_cpu_quota())\n",
    "print('ncpus = '+str(ncpus))\n",
    "# collect training data\n",
    "column_names, model_input = collect_training_data(\n",
    "    gdf=gpd_random_samples,\n",
    "    dc_query=query,\n",
    "    ncpus=ncpus,\n",
    "    field=class_attr,\n",
    "    zonal_stats=None,\n",
    "    feature_func=feature_layers,\n",
    "    return_coords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_samples_features=pd.DataFrame(data=model_input,columns=column_names)\n",
    "#set the name and location of the output file\n",
    "output_file = 'Results/Random_samples_features_Rwanda.txt'\n",
    "#Export files to disk\n",
    "rand_samples_features.to_csv(output_file, header=True, index=None, sep=' ')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_clusters_KMeans(data,min_cluster=5,max_cluster=20):\n",
    "    highest_score=-999\n",
    "    n_cluster_optimal=min_cluster\n",
    "    kmeans_model_optimal=None # initialise optimal model parameters\n",
    "    labels_optimal=None\n",
    "    if min_cluster==max_cluster:\n",
    "        print('Implementing kmeans clustering with number of clusters: ',max_cluster)\n",
    "        kmeans_model_optimal = KMeans(n_clusters=max_cluster, random_state=1).fit(data)\n",
    "        labels_optimal=kmeans_model_optimal.predict(data)\n",
    "        n_cluster_optimal=max_cluster\n",
    "    else:\n",
    "        for n_cluster in range(min_cluster,max_cluster+1):\n",
    "            kmeans_model = KMeans(n_clusters=n_cluster, random_state=1).fit(data)\n",
    "            labels=kmeans_model.predict(data)\n",
    "            score=metrics.calinski_harabasz_score(data, labels)\n",
    "            print('Calinski-Harabasz score for ',n_cluster,' clusters is: ',score)\n",
    "            if (highest_score==-999)or(highest_score<score):\n",
    "                highest_score=score\n",
    "                n_cluster_optimal=n_cluster\n",
    "                kmeans_model_optimal=kmeans_model\n",
    "                labels_optimal=labels\n",
    "        print('Best number of clusters: %s'%(n_cluster_optimal))\n",
    "    return n_cluster_optimal,kmeans_model_optimal,labels_optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features_filtered=None # filtered training data for all classes\n",
    "frequency_threshold=0.1 # threshold of cluter frequency\n",
    "optimal_clusters={1:None, 5: None, 7: None,  9: None, 10: None, 11: None,  12: None,  13: None,  14: None}\n",
    "for class_value in lc_classes: # filtering training data for each class\n",
    "    #i=1 # test for first class\n",
    "    print('Processing class ',class_value)\n",
    "    rand_features_single_class=rand_samples_features[rand_samples_features[class_attr]==class_value].reset_index(drop=True)\n",
    "    np_rand_features=rand_features_single_class.to_numpy()[:,1:]\n",
    "    if optimal_clusters[class_value] is None:\n",
    "        n_cluster_optimal,kmeans_model_optimal,labels_optimal=find_clusters_KMeans(np_rand_features,min_cluster=5,max_cluster=20)\n",
    "    else:\n",
    "        n_cluster_optimal,kmeans_model_optimal,labels_optimal=find_clusters_KMeans(np_rand_features,min_cluster=optimal_clusters[class_value],max_cluster=optimal_clusters[class_value])\n",
    "\n",
    "        # subset original training points for this class\n",
    "    td_single_class=training_features[training_features[class_attr]==class_value].reset_index(drop=True)\n",
    "    print('Number of training pints for the class: ',len(td_single_class))\n",
    "    np_td_single_class=td_single_class.to_numpy()[:,-9:-3]\n",
    "    # predict clustering labels\n",
    "    labels_kmeans = kmeans_model_optimal.predict(np_td_single_class)\n",
    "    # append clustering results to pixel coordinates\n",
    "    td_single_class['cluster']=labels_kmeans\n",
    "\n",
    "    cluster_frequency=td_single_class['cluster'].map(td_single_class['cluster'].value_counts(normalize=True)) # calculate cluster frequencies for the training samples\n",
    "    td_single_class['cluster_frequency']=cluster_frequency # append as a column\n",
    "    td_single_class_filtered=td_single_class[td_single_class['cluster_frequency']>=frequency_threshold] # filter by cluster frequency\n",
    "    print('Number of training data after filtering: ',len(td_single_class_filtered))\n",
    "    \n",
    "    # append the filtered training points of this class to final filtered training data\n",
    "    if training_features_filtered is None:\n",
    "        training_features_filtered=td_single_class_filtered\n",
    "    else:\n",
    "        training_features_filtered=pd.concat([training_features_filtered, td_single_class_filtered])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export filtered training features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"Results/Training_features_Rwanda_filtered.txt\"\n",
    "training_features_filtered.iloc[:,:-5].to_csv(output_file, header=True, index=None, sep=' ')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

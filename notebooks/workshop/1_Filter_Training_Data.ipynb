{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4555d86-4eb4-4185-93d8-52f55da43df9",
   "metadata": {},
   "source": [
    "# Clean and Extract Training Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f767b5b-dd6e-48f8-aba4-259d72d8804a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Background\n",
    "\n",
    "It is not uncommon that existing training data were collected at different time period than the study period. This means the dataset may not reflect the real ground cover due to temporal changes. FAO adopted a training data filtering method for any given reference year that is within a time span (e.g. 5 years) from an existing baseline, and tested the method in the production of land cover mapping for Lesotho. It is assumed that the majority of reference labels will remain valid from one year to the previous/next. Based on this assumption, the reference labels which have changed are the minority, and should be detectable through the use of outlier detection methods like K-Means clustering. More details on the method and how it works for Lesotho can be found in the published paper ([De Simone et al 2022](https://www.mdpi.com/2072-4292/14/14/3294))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48ec80f-8f94-45f9-808c-712a572f8d89",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "This notebook will implement filtering of extracted training data on a per-class basis for a target year using K-Means clustering and a baseline land cover map. The steps include:\n",
    "1. Load extracted training features\n",
    "2. Collect stratified random samples and extract features using `random_sampling` and `collect_training_data`\n",
    "3. Train K-Means models using the features of the random samples\n",
    "4. Apply clustering on training points and filter out those unlikely to be valid for the target year\n",
    "5. Export the filtered training data to disk for use in subsequent scripts\n",
    "\n",
    "To run this analysis, run all the cells in the notebook, starting with the \"Load packages\" cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdba3177-6db9-4440-9c8b-d5437f41e7f4",
   "metadata": {},
   "source": [
    "### Load packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fccc7e0-768c-4479-a777-6ce9efbf4d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import datacube\n",
    "import warnings\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "from odc.io.cgroups import get_cpu_quota\n",
    "from odc.algo import xr_geomedian\n",
    "from deafrica_tools.datahandling import load_ard\n",
    "from deafrica_tools.bandindices import calculate_indices\n",
    "from deafrica_tools.classification import collect_training_data\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from rasterio.enums import Resampling\n",
    "from random_sampling import random_sampling # adapted from function by Chad Burton: https://gist.github.com/cbur24/04760d645aa123a3b1817b07786e7d9f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe1e0fd-8acd-427c-91d9-a44622c5a164",
   "metadata": {},
   "source": [
    "We now find the number of CPUs available in your environment for paralell processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097a8a6f-1ef1-44d9-944d-0001f32ab780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5a40c1-7574-473c-a719-2b89bfbe167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths and attributes\n",
    "traning_points_path = 'Data/trainning_samples_FNDS_II_SOM_2016.geojson'\n",
    "rf2017_path='Data/Landcover_map_ODC_Brazil_2015_2016.tif'\n",
    "tiles_shp='Data/Mozambique_tiles_biggest1.shp'\n",
    "class_name = 'LC_Class_I' # class label in integer format\n",
    "crs='epsg:32736' # WGS84/UTM Zone 36S\n",
    "\n",
    "# Load reference land cover survey points and reproject\n",
    "training_data2017= gpd.read_file(traning_points_path).to_crs(crs) # read training points as geopandas dataframe\n",
    "training_data2017=training_data2017[[class_name,'geometry']] # select attributes\n",
    "print('land cover survey points 2017:\\n',training_data2017)\n",
    "\n",
    "# get bounding boxes of tiles\n",
    "tiles=gpd.read_file(tiles_shp).to_crs(crs)\n",
    "tile_bboxes=tiles.bounds\n",
    "print('tile boundaries for Mozambique: \\n',tile_bboxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c42d4cf-ba19-45a8-b095-f42a070e4d92",
   "metadata": {},
   "source": [
    "The method also requires a baseline land cover map as a stratification layer to sample and train the K-Means model. In this example, we are using the existing national land cover map in 2016:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3ba8c5-601f-46af-bbff-6ebaf5719cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load initial classification map\n",
    "rf_2017_raster = xr.open_dataset(rf2017_path,engine=\"rasterio\").astype(np.uint8).squeeze(\"band\", drop=True)\n",
    "# # reproject the raster\n",
    "# rf_2017_raster= rf_2017_raster.rio.reproject(resolution=10, dst_crs=crs,resampling=Resampling.nearest)\n",
    "rf_2017_raster=rf_2017_raster.band_data\n",
    "print('Reference land cover classifcation raster:\\n',rf_2017_raster) # note: 255 is nodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ff1b5f8-3028-49a2-88cc-a136fc693d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "land cover classes:\n",
      " [3 5 1 2 4]\n"
     ]
    }
   ],
   "source": [
    "lc_classes=training_data2017[class_name].unique() # get class labels\n",
    "print('land cover classes:\\n',lc_classes)\n",
    "n_samples=1000 # number of random samples to optimise number of clusters for kmeans\n",
    "zonal_stats = None\n",
    "scaler = StandardScaler() # standard scaler for input data standardisation\n",
    "frequency_threshold=0.05 # threshold of cluter frequency\n",
    "fill_nan_value=-999 # value to replace nans in query results\n",
    "measurements = ['blue','green','red','red_edge_1','red_edge_2', 'red_edge_3','nir_1','nir_2','swir_1','swir_2']\n",
    "query = {\n",
    "    'time': ('2021-01', '2021-12'),\n",
    "    'measurements': measurements,\n",
    "    'output_crs': crs,\n",
    "    'resolution': (-10, 10)\n",
    "}\n",
    "# define a function to feature layers\n",
    "def feature_layers(query): \n",
    "    #connect to the datacube\n",
    "    dc = datacube.Datacube(app='feature_layers')\n",
    "    ds = load_ard(dc=dc,\n",
    "                  products=['s2_l2a'],\n",
    "                  group_by='solar_day',\n",
    "                  verbose=False,\n",
    "#                   mask_filters=[(\"opening\", 2)], # morphological opening by 2 pixels to remove small masked regions\n",
    "                  **query)\n",
    "    ds = calculate_indices(ds,\n",
    "                           index=['NDVI'],\n",
    "                           drop=False,\n",
    "                           satellite_mission='s2')\n",
    "    # interpolate nodata using mean of previous and next observation\n",
    "#     ds=ds.interpolate_na(dim='time',method='linear',use_coordinate=False,fill_value='extrapolate')\n",
    "#     ds=ds.interpolate_na(dim='time',method='linear',use_coordinate=False)\n",
    "    # calculate geomedians within each two-month interval\n",
    "    ds=ds.resample(time='2MS').map(xr_geomedian)\n",
    "    # replace nan with a value so that the collect_training_data function will work\n",
    "#     ds=ds.fillna(fill_nan_value)\n",
    "    # stack multi-temporal measurements and rename them\n",
    "    n_time=ds.dims['time']\n",
    "    list_measurements=list(ds.keys())\n",
    "    ds_stacked=None\n",
    "    for j in range(len(list_measurements)):\n",
    "        for k in range(n_time):\n",
    "            variable_name=list_measurements[j]+'_'+str(k)\n",
    "            # print ('Stacking band ',list_measurements[j],' at time ',k)\n",
    "            measure_single=ds[list_measurements[j]].isel(time=k).rename(variable_name)\n",
    "            if ds_stacked is None:\n",
    "                ds_stacked=measure_single\n",
    "            else:\n",
    "                ds_stacked=xr.merge([ds_stacked,measure_single],compat='override')\n",
    "    return ds_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fd905a2-2137-4fb0-8c4b-3098c8c96b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing class  3\n",
      "stratified random sampling from tile  0\n",
      "Class 3: sampled at 103 coordinates\n",
      "stratified random sampling from tile  1\n",
      "Class 3: sampled at 153 coordinates\n",
      "stratified random sampling from tile  2\n",
      "Class 3: sampled at 151 coordinates\n",
      "stratified random sampling from tile  3\n",
      "Class 3: sampled at 71 coordinates\n",
      "stratified random sampling from tile  4\n",
      "Class 3: sampled at 227 coordinates\n",
      "stratified random sampling from tile  5\n",
      "Class 3: sampled at 131 coordinates\n",
      "stratified random sampling from tile  6\n",
      "Class 3: sampled at 12 coordinates\n",
      "stratified random sampling from tile  7\n",
      "Class 3: sampled at 1 coordinates\n",
      "stratified random sampling from tile  8\n",
      "Class 3: sampled at 44 coordinates\n",
      "stratified random sampling from tile  9\n",
      "Class 3: sampled at 10 coordinates\n",
      "radomly sampled points for class  3 \n",
      "                             geometry  LC_Class_I\n",
      "0     POINT (564331.117 8657665.275)           3\n",
      "1     POINT (313771.117 8332945.275)           3\n",
      "2     POINT (327481.117 8597815.275)           3\n",
      "3     POINT (309421.117 8537425.275)           3\n",
      "4     POINT (417361.117 8500015.275)           3\n",
      "..                               ...         ...\n",
      "898  POINT (1204501.117 8304985.275)           3\n",
      "899  POINT (1260181.117 8270755.275)           3\n",
      "900  POINT (1217431.117 8302255.275)           3\n",
      "901  POINT (1260421.117 8245315.275)           3\n",
      "902  POINT (1219711.117 8184745.275)           3\n",
      "\n",
      "[903 rows x 2 columns]\n",
      "Collecting training data in parallel mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53dd0407a6ec48cdb7c81c48530bc5d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/903 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of possible fails after run 1 = 0.0 %\n",
      "Removed 0 rows wth NaNs &/or Infs\n",
      "Output shape:  (892, 67)\n",
      "Calinski-Harabasz score for  5  clusters is:  121.18073402206959\n",
      "Calinski-Harabasz score for  6  clusters is:  115.22763779370413\n",
      "Calinski-Harabasz score for  7  clusters is:  110.11488805222984\n",
      "Calinski-Harabasz score for  8  clusters is:  104.62979928155579\n",
      "Calinski-Harabasz score for  9  clusters is:  99.14895585025577\n",
      "Calinski-Harabasz score for  10  clusters is:  94.31112159334593\n",
      "Calinski-Harabasz score for  11  clusters is:  89.47470646656937\n",
      "Calinski-Harabasz score for  12  clusters is:  85.65585932616916\n",
      "Calinski-Harabasz score for  13  clusters is:  82.20423822247736\n",
      "Calinski-Harabasz score for  14  clusters is:  80.66235832082143\n",
      "Calinski-Harabasz score for  15  clusters is:  75.79495030804776\n",
      "Calinski-Harabasz score for  16  clusters is:  74.6482449432701\n",
      "Calinski-Harabasz score for  17  clusters is:  71.2351973951531\n",
      "Calinski-Harabasz score for  18  clusters is:  69.114428275055\n",
      "Calinski-Harabasz score for  19  clusters is:  67.75284843020071\n",
      "Calinski-Harabasz score for  20  clusters is:  65.23558101075575\n",
      "Calinski-Harabasz score for  21  clusters is:  63.35851768515802\n",
      "Calinski-Harabasz score for  22  clusters is:  61.30565192888656\n",
      "Calinski-Harabasz score for  23  clusters is:  60.76497744139139\n",
      "Calinski-Harabasz score for  24  clusters is:  58.99792984698489\n",
      "Calinski-Harabasz score for  25  clusters is:  57.758895482911804\n",
      "Best number of clusters for class 3: 5\n",
      "Number of training data collected:  1291\n",
      "Collecting training data in parallel mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca5f9cda51a422aa5aa49faa979357f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of possible fails after run 1 = 0.0 %\n",
      "Removed 0 rows wth NaNs &/or Infs\n",
      "Output shape:  (1273, 69)\n",
      "Number of training data after removing Nans and Infs:  1273\n",
      "Number of training data after filtering:  1273\n",
      "Processing class  5\n",
      "stratified random sampling from tile  0\n",
      "Class 5: sampled at 97 coordinates\n",
      "stratified random sampling from tile  1\n",
      "Class 5: sampled at 190 coordinates\n",
      "stratified random sampling from tile  2\n",
      "Class 5: sampled at 197 coordinates\n",
      "stratified random sampling from tile  3\n",
      "Class 5: sampled at 106 coordinates\n",
      "stratified random sampling from tile  4\n",
      "Class 5: sampled at 165 coordinates\n",
      "stratified random sampling from tile  5\n",
      "Class 5: sampled at 84 coordinates\n",
      "stratified random sampling from tile  6\n",
      "Class 5: sampled at 5 coordinates\n",
      "stratified random sampling from tile  7\n",
      "Class 5: sampled at 0 coordinates\n",
      "stratified random sampling from tile  8\n",
      "Class 5: sampled at 39 coordinates\n",
      "stratified random sampling from tile  9\n",
      "Class 5: sampled at 6 coordinates\n",
      "radomly sampled points for class  5 \n",
      "                             geometry  LC_Class_I\n",
      "0     POINT (455881.117 8516365.275)           5\n",
      "1     POINT (658831.117 8491225.275)           5\n",
      "2     POINT (459121.117 8518195.275)           5\n",
      "3     POINT (556471.117 8619205.275)           5\n",
      "4     POINT (583591.117 8576215.275)           5\n",
      "..                               ...         ...\n",
      "884  POINT (1205941.117 8291335.275)           5\n",
      "885  POINT (1245811.117 8311915.275)           5\n",
      "886  POINT (1212031.117 8228335.275)           5\n",
      "887  POINT (1284781.117 8303035.275)           5\n",
      "888  POINT (1261561.117 8309905.275)           5\n",
      "\n",
      "[889 rows x 2 columns]\n",
      "Collecting training data in parallel mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "242a68757b294ac4b795fc1511212f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/889 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of possible fails after run 1 = 0.0 %\n",
      "Removed 0 rows wth NaNs &/or Infs\n",
      "Output shape:  (883, 67)\n",
      "Calinski-Harabasz score for  5  clusters is:  144.18639982439132\n",
      "Calinski-Harabasz score for  6  clusters is:  128.13543726901878\n",
      "Calinski-Harabasz score for  7  clusters is:  116.53747219247207\n",
      "Calinski-Harabasz score for  8  clusters is:  105.69295452474148\n",
      "Calinski-Harabasz score for  9  clusters is:  99.81753886119022\n",
      "Calinski-Harabasz score for  10  clusters is:  93.57639832543944\n",
      "Calinski-Harabasz score for  11  clusters is:  87.71112260763586\n",
      "Calinski-Harabasz score for  12  clusters is:  84.46097197713394\n",
      "Calinski-Harabasz score for  13  clusters is:  81.6384358480126\n",
      "Calinski-Harabasz score for  14  clusters is:  76.61572762426137\n",
      "Calinski-Harabasz score for  15  clusters is:  73.28570324580419\n",
      "Calinski-Harabasz score for  16  clusters is:  71.23521490415997\n",
      "Calinski-Harabasz score for  17  clusters is:  69.06506176761293\n",
      "Calinski-Harabasz score for  18  clusters is:  66.63911441528447\n",
      "Calinski-Harabasz score for  19  clusters is:  65.7240733868926\n",
      "Calinski-Harabasz score for  20  clusters is:  63.143736488544896\n",
      "Calinski-Harabasz score for  21  clusters is:  61.04056154907109\n",
      "Calinski-Harabasz score for  22  clusters is:  59.44709419523966\n",
      "Calinski-Harabasz score for  23  clusters is:  57.87550465113438\n",
      "Calinski-Harabasz score for  24  clusters is:  56.42935163111327\n",
      "Calinski-Harabasz score for  25  clusters is:  54.66014397251745\n",
      "Best number of clusters for class 5: 5\n",
      "Number of training data collected:  662\n",
      "Collecting training data in parallel mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58eeb147f2ee458ebd422e18a06f2ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/662 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of possible fails after run 1 = 0.0 %\n",
      "Removed 0 rows wth NaNs &/or Infs\n",
      "Output shape:  (659, 69)\n",
      "Number of training data after removing Nans and Infs:  659\n",
      "Number of training data after filtering:  659\n",
      "Processing class  1\n",
      "stratified random sampling from tile  0\n",
      "Class 1: sampled at 44 coordinates\n",
      "stratified random sampling from tile  1\n",
      "Class 1: sampled at 12 coordinates\n",
      "stratified random sampling from tile  2\n",
      "Class 1: sampled at 11 coordinates\n",
      "stratified random sampling from tile  3\n",
      "Class 1: sampled at 109 coordinates\n",
      "stratified random sampling from tile  4\n",
      "Class 1: sampled at 7 coordinates\n",
      "stratified random sampling from tile  5\n",
      "Class 1: sampled at 84 coordinates\n",
      "stratified random sampling from tile  6\n",
      "Class 1: sampled at 209 coordinates\n",
      "stratified random sampling from tile  7\n",
      "Class 1: sampled at 96 coordinates\n",
      "stratified random sampling from tile  8\n",
      "Class 1: sampled at 284 coordinates\n",
      "stratified random sampling from tile  9\n",
      "Class 1: sampled at 89 coordinates\n",
      "radomly sampled points for class  1 \n",
      "                             geometry  LC_Class_I\n",
      "0     POINT (674731.117 8610145.275)           1\n",
      "1     POINT (381871.117 8566375.275)           1\n",
      "2     POINT (494341.117 8515495.275)           1\n",
      "3     POINT (646081.117 8576635.275)           1\n",
      "4     POINT (656611.117 8702155.275)           1\n",
      "..                               ...         ...\n",
      "940  POINT (1255381.117 8030815.275)           1\n",
      "941  POINT (1504291.117 8254945.275)           1\n",
      "942  POINT (1583881.117 8250325.275)           1\n",
      "943  POINT (1221661.117 8073505.275)           1\n",
      "944  POINT (1229491.117 8166835.275)           1\n",
      "\n",
      "[945 rows x 2 columns]\n",
      "Collecting training data in parallel mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24089c7c1e304c518b4203b0365aa31d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/945 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of possible fails after run 1 = 0.0 %\n",
      "Removed 0 rows wth NaNs &/or Infs\n",
      "Output shape:  (927, 67)\n",
      "Calinski-Harabasz score for  5  clusters is:  630.0272931386039\n",
      "Calinski-Harabasz score for  6  clusters is:  588.961432052608\n",
      "Calinski-Harabasz score for  7  clusters is:  543.5268978554352\n",
      "Calinski-Harabasz score for  8  clusters is:  518.1819967306607\n",
      "Calinski-Harabasz score for  9  clusters is:  481.26736271835466\n",
      "Calinski-Harabasz score for  10  clusters is:  456.20394787242867\n",
      "Calinski-Harabasz score for  11  clusters is:  433.0182770774861\n",
      "Calinski-Harabasz score for  12  clusters is:  407.9174050325895\n",
      "Calinski-Harabasz score for  13  clusters is:  395.3818439075187\n",
      "Calinski-Harabasz score for  14  clusters is:  377.91637058087645\n",
      "Calinski-Harabasz score for  15  clusters is:  370.0486526639676\n",
      "Calinski-Harabasz score for  16  clusters is:  360.0579353060557\n",
      "Calinski-Harabasz score for  17  clusters is:  352.4434973608781\n",
      "Calinski-Harabasz score for  18  clusters is:  346.2061898825457\n",
      "Calinski-Harabasz score for  19  clusters is:  343.728261925754\n",
      "Calinski-Harabasz score for  20  clusters is:  333.442425912772\n",
      "Calinski-Harabasz score for  21  clusters is:  318.56165531354543\n",
      "Calinski-Harabasz score for  22  clusters is:  317.6208008032169\n",
      "Calinski-Harabasz score for  23  clusters is:  305.27135434128326\n",
      "Calinski-Harabasz score for  24  clusters is:  298.39895812012026\n",
      "Calinski-Harabasz score for  25  clusters is:  294.3680353718905\n",
      "Best number of clusters for class 1: 5\n",
      "Number of training data collected:  172\n",
      "Collecting training data in parallel mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6352b5e0eed432eb230dc367e76d558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/172 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of possible fails after run 1 = 0.0 %\n",
      "Removed 0 rows wth NaNs &/or Infs\n",
      "Output shape:  (168, 69)\n",
      "Number of training data after removing Nans and Infs:  168\n",
      "Number of training data after filtering:  61\n",
      "Processing class  2\n",
      "stratified random sampling from tile  0\n",
      "Class 2: sampled at 148 coordinates\n",
      "stratified random sampling from tile  1\n",
      "Class 2: sampled at 192 coordinates\n",
      "stratified random sampling from tile  2\n",
      "Class 2: sampled at 73 coordinates\n",
      "stratified random sampling from tile  3\n",
      "Class 2: sampled at 44 coordinates\n",
      "stratified random sampling from tile  4\n",
      "Class 2: sampled at 107 coordinates\n",
      "stratified random sampling from tile  5\n",
      "Class 2: sampled at 172 coordinates\n",
      "stratified random sampling from tile  6\n",
      "Class 2: sampled at 27 coordinates\n",
      "stratified random sampling from tile  7\n",
      "Class 2: sampled at 3 coordinates\n",
      "stratified random sampling from tile  8\n",
      "Class 2: sampled at 65 coordinates\n",
      "stratified random sampling from tile  9\n",
      "Class 2: sampled at 23 coordinates\n",
      "radomly sampled points for class  2 \n",
      "                             geometry  LC_Class_I\n",
      "0     POINT (626341.117 8503585.275)           2\n",
      "1     POINT (674311.117 8346175.275)           2\n",
      "2     POINT (594061.117 8468335.275)           2\n",
      "3     POINT (379651.117 8461795.275)           2\n",
      "4     POINT (319501.117 8387875.275)           2\n",
      "..                               ...         ...\n",
      "849  POINT (1217491.117 8176135.275)           2\n",
      "850  POINT (1269601.117 8290645.275)           2\n",
      "851  POINT (1217611.117 8174755.275)           2\n",
      "852  POINT (1294921.117 8265865.275)           2\n",
      "853  POINT (1238761.117 8232295.275)           2\n",
      "\n",
      "[854 rows x 2 columns]\n",
      "Collecting training data in parallel mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff813f66cd547eba614e42993d9b3ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of possible fails after run 1 = 0.0 %\n",
      "Removed 0 rows wth NaNs &/or Infs\n",
      "Output shape:  (845, 67)\n",
      "Calinski-Harabasz score for  5  clusters is:  164.98065674498488\n",
      "Calinski-Harabasz score for  6  clusters is:  152.73888752901402\n",
      "Calinski-Harabasz score for  7  clusters is:  141.89233961482572\n",
      "Calinski-Harabasz score for  8  clusters is:  132.43422595862216\n",
      "Calinski-Harabasz score for  9  clusters is:  122.05461776871876\n",
      "Calinski-Harabasz score for  10  clusters is:  114.52922831072557\n",
      "Calinski-Harabasz score for  11  clusters is:  107.56834058012703\n",
      "Calinski-Harabasz score for  12  clusters is:  101.29941813265646\n",
      "Calinski-Harabasz score for  13  clusters is:  97.5030978022485\n",
      "Calinski-Harabasz score for  14  clusters is:  93.99069862689755\n",
      "Calinski-Harabasz score for  15  clusters is:  90.57570280693758\n",
      "Calinski-Harabasz score for  16  clusters is:  85.77743297510757\n",
      "Calinski-Harabasz score for  17  clusters is:  81.32678763743982\n",
      "Calinski-Harabasz score for  18  clusters is:  79.31693081934323\n",
      "Calinski-Harabasz score for  19  clusters is:  76.09433803370352\n",
      "Calinski-Harabasz score for  20  clusters is:  74.36285962253679\n",
      "Calinski-Harabasz score for  21  clusters is:  71.77140486563358\n",
      "Calinski-Harabasz score for  22  clusters is:  70.62518845725928\n",
      "Calinski-Harabasz score for  23  clusters is:  68.49872301305255\n",
      "Calinski-Harabasz score for  24  clusters is:  66.20844650097207\n",
      "Calinski-Harabasz score for  25  clusters is:  63.84904641497926\n",
      "Best number of clusters for class 2: 5\n",
      "Number of training data collected:  339\n",
      "Collecting training data in parallel mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fb929d2836147d1ac6751a23fe0cdbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/339 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of possible fails after run 1 = 0.0 %\n",
      "Removed 0 rows wth NaNs &/or Infs\n",
      "Output shape:  (337, 69)\n",
      "Number of training data after removing Nans and Infs:  337\n",
      "Number of training data after filtering:  333\n",
      "Processing class  4\n",
      "stratified random sampling from tile  0\n",
      "Class 4: sampled at 24 coordinates\n",
      "stratified random sampling from tile  1\n",
      "Class 4: sampled at 174 coordinates\n",
      "stratified random sampling from tile  2\n",
      "Class 4: sampled at 282 coordinates\n",
      "stratified random sampling from tile  3\n",
      "Class 4: sampled at 165 coordinates\n",
      "stratified random sampling from tile  4\n",
      "Class 4: sampled at 73 coordinates\n",
      "stratified random sampling from tile  5\n",
      "Class 4: sampled at 83 coordinates\n",
      "stratified random sampling from tile  6\n",
      "Class 4: sampled at 61 coordinates\n",
      "stratified random sampling from tile  7\n",
      "Class 4: sampled at 6 coordinates\n",
      "stratified random sampling from tile  8\n",
      "Class 4: sampled at 32 coordinates\n",
      "stratified random sampling from tile  9\n",
      "Class 4: sampled at 37 coordinates\n",
      "radomly sampled points for class  4 \n",
      "                             geometry  LC_Class_I\n",
      "0     POINT (358771.117 8539855.275)           4\n",
      "1     POINT (399721.117 8588485.275)           4\n",
      "2     POINT (362731.117 8546725.275)           4\n",
      "3     POINT (384241.117 8571955.275)           4\n",
      "4     POINT (382081.117 8575555.275)           4\n",
      "..                               ...         ...\n",
      "932  POINT (1253281.117 8198755.275)           4\n",
      "933  POINT (1301941.117 8262415.275)           4\n",
      "934  POINT (1313971.117 8278405.275)           4\n",
      "935  POINT (1229731.117 8168275.275)           4\n",
      "936  POINT (1249171.117 8195095.275)           4\n",
      "\n",
      "[937 rows x 2 columns]\n",
      "Collecting training data in parallel mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d46e8917bfaa49009d272fcec9d207bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of possible fails after run 1 = 0.0 %\n",
      "Removed 0 rows wth NaNs &/or Infs\n",
      "Output shape:  (921, 67)\n",
      "Calinski-Harabasz score for  5  clusters is:  604.1878025353604\n",
      "Calinski-Harabasz score for  6  clusters is:  554.6205299310844\n",
      "Calinski-Harabasz score for  7  clusters is:  526.494582318181\n",
      "Calinski-Harabasz score for  8  clusters is:  497.5040403392479\n",
      "Calinski-Harabasz score for  9  clusters is:  472.342480677431\n",
      "Calinski-Harabasz score for  10  clusters is:  449.93853019754107\n",
      "Calinski-Harabasz score for  11  clusters is:  426.78275785803095\n",
      "Calinski-Harabasz score for  12  clusters is:  402.5345159736822\n",
      "Calinski-Harabasz score for  13  clusters is:  380.7651914996268\n",
      "Calinski-Harabasz score for  14  clusters is:  364.8797728439266\n",
      "Calinski-Harabasz score for  15  clusters is:  349.317573378688\n",
      "Calinski-Harabasz score for  16  clusters is:  334.7366929523318\n",
      "Calinski-Harabasz score for  17  clusters is:  324.7321769606024\n",
      "Calinski-Harabasz score for  18  clusters is:  315.95966881835295\n",
      "Calinski-Harabasz score for  19  clusters is:  302.1533460233275\n",
      "Calinski-Harabasz score for  20  clusters is:  291.12004066075144\n",
      "Calinski-Harabasz score for  21  clusters is:  283.27462959972024\n",
      "Calinski-Harabasz score for  22  clusters is:  274.9043143236524\n",
      "Calinski-Harabasz score for  23  clusters is:  269.556264507073\n",
      "Calinski-Harabasz score for  24  clusters is:  263.7916141962321\n",
      "Calinski-Harabasz score for  25  clusters is:  262.056048852688\n",
      "Best number of clusters for class 4: 5\n",
      "Number of training data collected:  35\n",
      "Collecting training data in parallel mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8841165f17d4d51b4db05248add7bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of possible fails after run 1 = 0.0 %\n",
      "Removed 0 rows wth NaNs &/or Infs\n",
      "Output shape:  (35, 69)\n",
      "Number of training data after removing Nans and Infs:  35\n",
      "Number of training data after filtering:  35\n",
      "filtered training data for 2021:\n",
      "     LC_Class_I       blue_0       blue_1       blue_2       blue_3  \\\n",
      "0          3.0   498.881073   400.912933   366.908997   552.580688   \n",
      "1          3.0   477.645630   349.235870   251.920792   312.284973   \n",
      "2          3.0   401.701843   371.754852   286.077118   311.395172   \n",
      "3          3.0   461.556244   352.943115   286.713257   333.606384   \n",
      "4          3.0   627.746338   373.808105   325.894257   475.023315   \n",
      "..         ...          ...          ...          ...          ...   \n",
      "30         4.0   886.718567   761.163391   750.301697   786.533813   \n",
      "31         4.0  1294.000000   701.280823   322.233154   454.280548   \n",
      "32         4.0   481.076233   411.874603   601.250610   582.437378   \n",
      "33         4.0  1100.274414  1028.102539  1044.010254  1038.409790   \n",
      "34         4.0   635.127197  1224.000244  1081.172852   691.772705   \n",
      "\n",
      "         blue_4       blue_5      green_0      green_1      green_2  ...  \\\n",
      "0    891.667114   587.169983   736.959900   628.309265   614.594177  ...   \n",
      "1    815.291992   467.838013   679.119141   556.364136   422.957336  ...   \n",
      "2    773.798279   544.924988   581.433472   626.066772   458.531219  ...   \n",
      "3    664.090759   428.975952   650.195129   505.288574   466.255219  ...   \n",
      "4    869.010681   660.861877   888.449524   648.297852   601.561951  ...   \n",
      "..          ...          ...          ...          ...          ...  ...   \n",
      "30   902.330322  1000.976013  1154.549805   998.497437   957.611633  ...   \n",
      "31   609.102844   548.317017  1321.000000   771.698975   370.470032  ...   \n",
      "32   688.908081   627.869080   592.415405   632.214966   690.741882  ...   \n",
      "33  1115.950562  1095.232788  1318.300781  1185.110107  1296.309082  ...   \n",
      "34   792.117004   712.259155   855.415161  1322.000488  1211.241455  ...   \n",
      "\n",
      "      NDVI_1    NDVI_2    NDVI_3    NDVI_4    NDVI_5    x_coord    y_coord  \\\n",
      "0   0.663680  0.574681  0.347955  0.244552  0.498747   270155.0  8252815.0   \n",
      "1   0.787786  0.752591  0.578189  0.292008  0.688369   265935.0  8310425.0   \n",
      "2   0.724045  0.613975  0.495249  0.295919  0.430653   299135.0  8318075.0   \n",
      "3   0.821166  0.797617  0.674191  0.401102  0.670244   533785.0  8343745.0   \n",
      "4   0.711598  0.611005  0.465701  0.166813  0.391846   278295.0  8232705.0   \n",
      "..       ...       ...       ...       ...       ...        ...        ...   \n",
      "30  0.389979  0.249061  0.201383  0.183205  0.153962  1093315.0  8388975.0   \n",
      "31  0.391480  0.334731  0.271580  0.238941  0.275145   994665.0  8495285.0   \n",
      "32  0.627238  0.363976  0.292156  0.230779  0.271680  1015795.0  8321565.0   \n",
      "33  0.268892  0.218386  0.216904  0.211288  0.197992  1146985.0  8326645.0   \n",
      "34  0.379424  0.373591  0.347502  0.313622  0.326036  1123035.0  8289515.0   \n",
      "\n",
      "                           geometry  cluster  cluster_frequency  \n",
      "0    POINT (270155.000 8252815.000)        2           0.095291  \n",
      "1    POINT (265935.000 8310425.000)        1           0.270179  \n",
      "2    POINT (299135.000 8318075.000)        3           0.331839  \n",
      "3    POINT (533785.000 8343745.000)        1           0.270179  \n",
      "4    POINT (278295.000 8232705.000)        3           0.331839  \n",
      "..                              ...      ...                ...  \n",
      "30  POINT (1093315.000 8388975.000)        2           0.302932  \n",
      "31   POINT (994665.000 8495285.000)        2           0.302932  \n",
      "32  POINT (1015795.000 8321565.000)        2           0.302932  \n",
      "33  POINT (1146985.000 8326645.000)        2           0.302932  \n",
      "34  POINT (1123035.000 8289515.000)        2           0.302932  \n",
      "\n",
      "[2361 rows x 72 columns]\n"
     ]
    }
   ],
   "source": [
    "td2021_filtered=None # filtered training data\n",
    "# filtering training data for each class\n",
    "# for i in lc_classes[8:]:\n",
    "for i in lc_classes:\n",
    "    #i=1 # test for first class\n",
    "    print('Processing class ',i)\n",
    "    gpd_samples=None\n",
    "    n_total=np.sum(rf_2017_raster.to_numpy()==i)\n",
    "    # generate randomly sampled data to fit and optimise a kmeans clusterer\n",
    "    for n in range(len(tile_bboxes)):\n",
    "        print('stratified random sampling from tile ',n)\n",
    "        da_mask=rf_2017_raster.rio.clip([tiles.iloc[n].geometry],crs=crs,drop=True)\n",
    "        da_mask=da_mask.rio.reproject(dst_crs=crs,resampling=Resampling.nearest)\n",
    "        n_samples_tile=n_samples*np.sum(da_mask.to_numpy()==i)/n_total\n",
    "        gpd_samples_tile=random_sampling(da_mask,n_samples_tile,sampling='manual',\n",
    "                                         manual_class_ratios={str(i):n_samples_tile},out_fname=None)\n",
    "        if gpd_samples is None:\n",
    "            gpd_samples=gpd_samples_tile\n",
    "        else:\n",
    "            gpd_samples=pd.concat([gpd_samples,gpd_samples_tile])\n",
    "    # get data array\n",
    "#     da_mask=da_mask.where(da_mask==i,np.nan) # replace other class values as nan so they won't be sampled (comment due to large memory required)\n",
    "#     gpd_samples=random_sampling(da_mask,n_samples,sampling='stratified_random',manual_class_ratios=None,out_fname=None)\n",
    "#     gpd_samples=random_sampling(da_mask,n_samples,sampling='manual',manual_class_ratios={str(i):n_samples},out_fname=None)\n",
    "    gpd_samples=gpd_samples.reset_index(drop=True).drop(columns=['spatial_ref','class']) # drop this attribute derived from random_sampling function\n",
    "    gpd_samples[class_name]=i # add attribute field so that we can use collect_training_data function\n",
    "    if gpd_samples.crs is None:\n",
    "        gpd_samples=gpd_samples.set_crs(crs)\n",
    "    print('radomly sampled points for class ',i,'\\n',gpd_samples)\n",
    "    # extract data for the random samples\n",
    "    column_names, sampled_data = collect_training_data(gdf=gpd_samples,\n",
    "                                                          dc_query=query,\n",
    "                                                          ncpus=ncpus,\n",
    "#                                                           ncpus=1,\n",
    "                                                          field=class_name, \n",
    "                                                          zonal_stats=zonal_stats,\n",
    "                                                          feature_func=feature_layers,\n",
    "                                                          return_coords=False)\n",
    "    # standardise features\n",
    "    scaler=scaler.fit(sampled_data[:,1:])\n",
    "    sampled_data=scaler.transform(sampled_data[:,1:])\n",
    "#     sampled_data[:,-6:]=sampled_data[:,-6:]*10000\n",
    "#     sampled_data=sampled_data[:,1:]\n",
    "    # fit kmeans model using the sample training data\n",
    "    # first find optimal number of clusters based on Calinski-Harabasz index\n",
    "    highest_score=-999\n",
    "    n_cluster_optimal=5\n",
    "    kmeans_model_optimal=None # initialise optimal model parameters\n",
    "    labels_optimal=None\n",
    "    for n_cluster in range(5,26):\n",
    "        kmeans_model = KMeans(n_clusters=n_cluster, random_state=1).fit(sampled_data)\n",
    "        labels=kmeans_model.predict(sampled_data)\n",
    "        score=metrics.calinski_harabasz_score(sampled_data, labels)\n",
    "#         score=metrics.davies_bouldin_score(sampled_data, labels)\n",
    "        print('Calinski-Harabasz score for ',n_cluster,' clusters is: ',score)\n",
    "#         print('Davies-Bouldin score for ',n_cluster,' clusters is: ',score)\n",
    "        if (highest_score==-999)or(highest_score<score):\n",
    "#         if (highest_score==-999)or(highest_score>score):\n",
    "            highest_score=score\n",
    "            n_cluster_optimal=n_cluster\n",
    "            kmeans_model_optimal=kmeans_model\n",
    "            labels_optimal=labels\n",
    "    print('Best number of clusters for class %s: %s'%(i,n_cluster_optimal))\n",
    "    \n",
    "    # subset original training points for this class\n",
    "    td_single_class=training_data2017[training_data2017[class_name]==i].reset_index(drop=True)\n",
    "    print('Number of training data collected: ',len(td_single_class))\n",
    "    column_names, model_input = collect_training_data(gdf=td_single_class,\n",
    "                                                      dc_query=query,\n",
    "                                                      ncpus=ncpus,\n",
    "                                                      field=class_name,\n",
    "                                                      zonal_stats=zonal_stats,\n",
    "                                                      feature_func=feature_layers,\n",
    "                                                      return_coords=True)\n",
    "    print('Number of training data after removing Nans and Infs: ',model_input.shape[0])\n",
    "    # first covert the training data to pandas\n",
    "    td_single_class_filtered=pd.DataFrame(data=model_input,columns=column_names)\n",
    "    # then to geopandas dataframe\n",
    "    td_single_class_filtered=gpd.GeoDataFrame(td_single_class_filtered, \n",
    "                                    geometry=gpd.points_from_xy(model_input[:,-2], model_input[:,-1],\n",
    "                                                                crs=crs))\n",
    "    # normalisation before clustering\n",
    "    model_input=scaler.transform(model_input[:,1:-2])\n",
    "#     model_input=model_input[:,1:-2]\n",
    "#     model_input[:,-6:]=model_input[:,-6:]*10000\n",
    "    # predict clustering labels\n",
    "    labels_kmeans = kmeans_model_optimal.predict(model_input)\n",
    "    # append clustering results to pixel coordinates\n",
    "    td_single_class_filtered['cluster']=labels_kmeans\n",
    "    # append frequency of each cluster\n",
    "    labels_optimal=pd.DataFrame(data=labels_optimal,columns=['cluster']) # calculate cluster frequencies of the random samples\n",
    "    cluster_frequency=td_single_class_filtered['cluster'].map(labels_optimal['cluster'].value_counts(normalize=True))\n",
    "    td_single_class_filtered['cluster_frequency']=cluster_frequency\n",
    "#     print('filtered training data: \\n',td_single_class_filtered[td_single_class_filtered['cluster_frequency']<frequency_threshold])\n",
    "    # filter by cluster frequency\n",
    "    td_single_class_filtered=td_single_class_filtered[td_single_class_filtered['cluster_frequency']>=frequency_threshold]\n",
    "    print('Number of training data after filtering: ',len(td_single_class_filtered))\n",
    "    # export filtered training data for this class as shapefile (will encounter 10-character limit for attributes)\n",
    "#     td_single_class_filtered.to_file('Results/landcover_td2021_filtered_DEAfrica_new_class_'+str(i)+'.shp')\n",
    "    # export filtered training data for this class as geojson file\n",
    "    td_single_class_filtered.to_file('Results/landcover_td2021_filtered_class_'+str(i)+'.geojson', driver=\"GeoJSON\")\n",
    "    # append the filtered training points of this class to final filtered training data\n",
    "    if td2021_filtered is None:\n",
    "        td2021_filtered=td_single_class_filtered\n",
    "    else:\n",
    "        td2021_filtered=pd.concat([td2021_filtered, td_single_class_filtered])\n",
    "        \n",
    "# save training data for all classes\n",
    "print('filtered training data for 2021:\\n',td2021_filtered)\n",
    "td2021_filtered.to_file('Results/landcover_td2021_filtered.geojson', driver=\"GeoJSON\")\n",
    "\n",
    "# export the filtered training data as txt file\n",
    "output_file = \"Results/landcover_td2021_filtered.txt\"\n",
    "td2021_filtered.to_csv(output_file, header=True, index=None, sep=' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

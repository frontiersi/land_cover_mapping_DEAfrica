{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f13adbce-103d-40c4-88bd-bb94d3d848f1",
   "metadata": {},
   "source": [
    "# Post-process: Smoothing and Reclassify Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5fb223-9745-4711-9a51-a1384dbcc63e",
   "metadata": {},
   "source": [
    "## Description\n",
    "In this notebook we use external layers that contain reliable information on centain classes and/or have higher-spatial resolution to reclassify classes that may be misclassified by the random forest classifier. These external layers have been prepared and uploaded into 'Data/' folder. We'll also conduct a median filtering to reduce the 'salt and pepper' effect resulted from pixel-based classification. This notebook will demonstrate how to do these and visualise the comparison before and after the post-processing.\n",
    "\n",
    "To run this analysis, run all the cells in the notebook, starting with the \"Load packages\" cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44f4e28-0a6a-4d30-973d-e2f1b20acf2a",
   "metadata": {},
   "source": [
    "### Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4986f5-2e04-4e64-8ff0-25119e9468ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import datacube\n",
    "import warnings\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "from rasterio.enums import Resampling\n",
    "from datacube.utils.cog import write_cog\n",
    "from deafrica_tools.spatial import xr_rasterize\n",
    "from deafrica_tools.plotting import rgb, display_map\n",
    "from skimage.morphology import binary_dilation,disk\n",
    "from skimage.filters.rank import modal\n",
    "from odc.algo import xr_reproject\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e74765-a79f-4bb2-baa5-240c6cacc41e",
   "metadata": {},
   "source": [
    "## Analysis parameters\n",
    "* `prediction_maps_path`: A list of file paths and name of the classification maps produced in the previous notebook.\n",
    "* `dict_map`: A dictionary map of class names corresponding to pixel values.\n",
    "* `output_crs`: Coordinate reference system for output raster files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269eb27c-1692-4461-830b-185ffaa8008b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_maps_path=['Results/Rwanda_land_cover_prediction_2021_location_0.tif',\n",
    "'Results/Rwanda_land_cover_prediction_2021_location_1.tif',\n",
    "'Results/Rwanda_land_cover_prediction_2021_location_2.tif'] # list of prediction map files\n",
    "dict_map={1:'Forest',5:'Grassland',7:'Shrubland',9:'Perennial Cropland',10:'Annual Cropland',11:'Wetland',12:'Water Body',13:'Urban Settlement'}\n",
    "output_crs='epsg:32735' # WGS84/UTM Zone 35S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef9884a-c98d-4d0a-8dca-d1cadb986c36",
   "metadata": {},
   "source": [
    "## External Layers\n",
    "A few external layers were sourced and prepared in the 'Data/' folder, which are helpful to provide information on specific classes, e.g. Urban Settlements and Water Body. which include:\n",
    "* `hand_raster`: Hydrologically adjusted elevations, i.e. Height Above the Nearest Hrainage (hand) derived from the [MERIT Hydro dataset](https://developers.google.com/earth-engine/datasets/catalog/MERIT_Hydro_v1_0_1#description).\n",
    "* `river_network_shp`: OSM river network shapefile. The OSM layers were sourced from the [Humanitarian OpenStreetMap Team (HOT)](https://data.humdata.org/organization/hot) website.\n",
    "* `road_network_shp`: OSM road network shapefile.\n",
    "* `google_building_raster`: A rasterised layer of [Google Open Building polygons](https://developers.google.com/earth-engine/datasets/catalog/GOOGLE_Research_open-buildings_v2_polygons), which consist of outlines of buildings derived from high-resolution 50 cm satellite imagery. As there are many polygons in the original vector layer, we rasterised the layer to reduce disk storage and memory required for processing.\n",
    "* `wsf2019_raster`: 2019 [World Settlement Footprint (WSF) layer](https://gee-community-catalog.org/projects/wsf/), a 10m resolution binary mask outlining the extent of human settlements globally derived by means of 2019 multitemporal Sentinel-1 and Sentinel-2 imagery.  \n",
    "\n",
    "> Note: In this notebook we have made the data prepared for you to run through the demonstration. If you would like to apply it to your own project, you may need to spend some time sourcing the datasets and do some pre-processing if needed, e.g. clipping to your study area, filtering, rasterisation or vectorisation. Alternatively you can revise this notebook depending on your data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12234399-7fda-4885-bce2-478634840400",
   "metadata": {},
   "outputs": [],
   "source": [
    "river_network_shp='Data/hotosm_rwa_waterways_lines_filtered.shp' # OSM river network data\n",
    "road_network_shp='Data/hotosm_rwa_roads_lines_filtered.shp' # OSM road network data\n",
    "google_building_raster='Data/GoogleBuildingLayer_Rwanda_rasterised.tif' # rasterised google bulding layer\n",
    "hand_raster='Data/hand_Rwanda.tif' # Hydrologically adjusted elevations, i.e. height above the nearest drainage (hand)\n",
    "wsf2019_raster='Data/WSF2019_v1_Rwanda_clipped.tif' # 2019 World Settlement Footprint layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e2b93c-e69f-46b1-9df4-715dc11f0b04",
   "metadata": {},
   "source": [
    "## Load layers\n",
    "First let's load the land cover maps generated from the previous notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775c855d-7100-4d48-8a8b-5219ddcf0f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import land cover map of 2021 and reproject\n",
    "prediction_maps=[]\n",
    "for i in range(0, len(prediction_maps_path)):\n",
    "    prediction_maps[i]=rioxarray.open_rasterio(prediction_maps_path[i]).astype(np.uint8).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f64fc6c-856d-4185-926d-76d44872243c",
   "metadata": {},
   "source": [
    "We then load other layers. The SOM road network layer contains multi-lines with various surface attributes. We'll select some major road types and buffer them by 10 metres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616870ab-3aad-439d-bbae-9833ab9e3b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import OSM road network data and reproject\n",
    "road_network=gpd.read_file(road_network_shp).to_crs(output_crs) \n",
    "road_network=road_network.loc[road_network['surface'].isin(['asphalt', 'paved', 'compacted', 'cobblestone', \n",
    "                                                             'concrete', 'metal', 'paving_stones', \n",
    "                                                             'paving_stones:30'])] # select road network by attributes\n",
    "road_network.geometry=road_network.geometry.buffer(10) # buffer the road network by 10m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e53bad2-84e5-4f26-80ed-2009c9a98670",
   "metadata": {},
   "source": [
    "Similaryly we'll select major waterways from the OSM river network layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c785f9c0-8461-47f9-94db-7015abcec29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "river_network=gpd.read_file(river_network_shp).to_crs(output_crs) # import OSM river network data and reproject\n",
    "river_network=river_network.loc[river_network['waterway'].isin(['canal','river'])] # select river network by attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8469a6-6e9b-44f1-a975-622f258eb170",
   "metadata": {},
   "source": [
    "We now load the Google buildings, WSF 2019 and 'hand' rasters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c28d0d-b5a2-4a83-9567-6e2e17a6b42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_buildings=xr.open_dataset(google_building_raster,engine=\"rasterio\").squeeze() # import google bulding layer\n",
    "hand=xr.open_dataset(hand_raster,engine=\"rasterio\").squeeze() # import hand layer\n",
    "wsf2019=xr.open_dataset(wsf2019_raster,engine=\"rasterio\").astype(np.uint8).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47515c1-b690-4499-a2a4-3b8eb127b8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and reproject hand layer\n",
    "\n",
    "hand=xr_reproject(hand, ds_geobox, resampling=\"average\")\n",
    "np_hand=hand.to_array().squeeze().to_numpy()\n",
    "# import 2019 wsf layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc9fc6c-0340-4e18-a4fb-efc9cdfe35cd",
   "metadata": {},
   "source": [
    "## Morphological filtering\n",
    "To reduce salt-and-pepper noise in the classification map, we can impliment a major filtering. In this example we use a filtering size of 2.5 metres below. It is advised that you adjust the size depending on your data and study area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d7b8e2-9494-47ea-962c-65c23abdc0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode filtering for a smoother classification map\n",
    "np_landcover2021_post=modal(np_landcover2021,selem=disk(2.5),mask=np_landcover2021!=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83a45c1-9d8c-4448-84af-c9b1fba79f51",
   "metadata": {},
   "source": [
    "We can plot the map before and after filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400c86ef-8726-4893-a674-2a8e5bb0e85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(24, 8))\n",
    "\n",
    "# Plot classified image before filtering\n",
    "np_landcover2021.plot(ax=axes[0], \n",
    "#                    cmap='Greens', \n",
    "               add_labels=False, \n",
    "               add_colorbar=True)\n",
    "\n",
    "# Plot classified image after filtering\n",
    "np_landcover2021_post.plot(ax=axes[1], \n",
    "#                    cmap='Greens', \n",
    "               add_labels=False, \n",
    "               add_colorbar=True)\n",
    "\n",
    "# Add plot titles\n",
    "axes[0].set_title('Classified Image Before Majority Filtering')\n",
    "axes[1].set_title('Classified Image After Majority Filtering')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13da1d39-cf4f-4488-ac50-160c2e6d7638",
   "metadata": {},
   "source": [
    "## Apply Rules using other layers\n",
    "We'll use the loaded layers and some set rules to reclassify some classes. First, we reclassify pixels classified as water occuring at bottom of watersheds or fallen within OSM river networks as water class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8717ac4-1089-41c6-aee4-4e1dd74b822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of the map before applying the rules\n",
    "np_landcover_copy=np_landcover2021_post.copy()\n",
    "river_network_mask=xr_rasterize(gdf=river_network,\n",
    "                                  da=landcover2021_tile.squeeze(),\n",
    "                                  transform=ds_geobox.transform,\n",
    "                                  crs=output_crs)\n",
    "np_river_network_mask=river_network_mask.to_numpy()\n",
    "np_landcover2021_post[((np_landcover2021==dict_map['Open Water'])&(np_hand<=45))|(np_river_network_mask==1)]=dict_map['Open Water']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7277ce2a-363b-482c-b254-93da232b77eb",
   "metadata": {},
   "source": [
    "We then assign pixels overlapping google building polygons or wsf mask as built-up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e72cd0-ee13-4332-b6b7-430873016db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_buildings_mask=xr_rasterize(gdf=google_buildings,\n",
    "                                  da=landcover2021_tile.squeeze(),\n",
    "                                  transform=ds_geobox.transform,\n",
    "                                  crs=croutput_crss)\n",
    "np_google_buildings_mask=google_buildings_mask.to_numpy()\n",
    "wsf2019=xr_reproject(wsf2019, ds_geobox, resampling=\"nearest\")\n",
    "np_wsf2019=wsf2019.to_array().squeeze().to_numpy()\n",
    "np_landcover2021_post[(np_google_buildings_mask==1)|(np_wsf2019==1)]=dict_map['Settlements']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7da357-4159-4cda-91f6-03e170887daa",
   "metadata": {},
   "source": [
    "We assume that wetlands should not be too close (e.g. within 50m) to built-up areas and reclassify these misclassified pixels as croplands instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c5f6ff-1d92-49a5-8335-96ef4188284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "urban_buffered=binary_dilation(np_landcover2021==dict_map['Settlements'],selem=disk(5))\n",
    "np_landcover2021_post[(urban_buffered==1)&(np_landcover2021==dict_map['Vegetated Wetland'])]=dict_map['Cropland']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e009f314-7a4e-4e07-83b8-c2879e09fcfb",
   "metadata": {},
   "source": [
    "In addition, we assign pixels overlapping OSM road network as built-up class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65662eec-9b48-400b-bac1-c24465bec233",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_network_mask=xr_rasterize(gdf=road_network,\n",
    "                              da=landcover2021_tile.squeeze(),\n",
    "                              transform=ds_geobox.transform,\n",
    "                              crs=output_crs)\n",
    "np_road_network_mask=road_network_mask.to_numpy()\n",
    "np_landcover2021_post[np_road_network_mask==1]=dict_map['Settlements']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3918b4-ad54-47e4-a7e4-ff11bc23c6ae",
   "metadata": {},
   "source": [
    "We can plot the maps to see a comparison before and after applying the rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173e248c-d5dc-4d3b-bc27-0362e452edce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(24, 8))\n",
    "\n",
    "# Plot classified image before applying the rules\n",
    "np_landcover_copy.plot(ax=axes[0], \n",
    "#                    cmap='Greens', \n",
    "               add_labels=False, \n",
    "               add_colorbar=True)\n",
    "\n",
    "# Plot classified image after applying the rules\n",
    "np_landcover2021_post.plot(ax=axes[1], \n",
    "#                    cmap='Greens', \n",
    "               add_labels=False, \n",
    "               add_colorbar=True)\n",
    "\n",
    "# Add plot titles\n",
    "axes[0].set_title('Classified Image Before Applying Rules')\n",
    "axes[1].set_title('Classified Image After Applying Rules')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5690f01c-0333-4da0-8c22-c66cbf347be8",
   "metadata": {},
   "source": [
    "## Save as geotiff\n",
    "We can now export our predictions to sandbox disk as Cloud-Optimised GeoTIFFs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2077ff-46cb-47c0-8889-3739cf0a3afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert back result back to DataArray\n",
    "landcover2021_tile_post=xr.DataArray(data=np_landcover2021_post,dims=['y','x'],\n",
    "                                     coords={'y':landcover2021_tile.y.to_numpy(), 'x':landcover2021_tile.x.to_numpy()})\n",
    "landcover2021_tile_post.rio.write_crs(output_crs, inplace=True)\n",
    "# export as geotiff\n",
    "write_cog(landcover2021_tile_post, 'Results/Land_cover2021_postproc_add_all_others_tile_'+str(i)+'.tif', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c77d5018-3925-49cf-b357-d28bc8109b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing tile  0 with bbox of  706710.6451945585 9734601.615224078 736778.9456614424 9764669.916827785\n",
      "Processing tile  1 with bbox of  706571.951193417 9704669.970329456 736654.9786463858 9734752.998859746\n",
      "Processing tile  2 with bbox of  706418.4618659335 9674738.4230786 736516.2033688526 9704836.165599158\n",
      "Processing tile  3 with bbox of  736962.4177453369 9824310.06328279 767001.3429964046 9854348.989904791\n",
      "Processing tile  4 with bbox of  736868.0657618204 9794363.364797598 766921.7626612171 9824417.063008774\n",
      "Processing tile  5 with bbox of  736758.9000742742 9764416.736721337 766827.3563398367 9794485.194239335\n",
      "Processing tile  6 with bbox of  736634.9232347194 9734470.189283589 766718.1262457089 9764553.393487478\n",
      "Processing tile  7 with bbox of  736496.13814132 9704523.732704137 766594.0749397537 9734621.670635745\n",
      "Processing tile  8 with bbox of  736342.5480382751 9674577.37719173 766455.2053302713 9704690.035556989\n",
      "Processing tile  9 with bbox of  766901.72682136 9824223.029297957 796955.5440196586 9854276.84792412\n",
      "Processing tile  10 with bbox of  766807.3106536514 9794261.500699764 796875.9077080423 9824330.099122647\n",
      "Processing tile  11 with bbox of  766698.070721615 9764300.044902222 796781.434994251 9794383.410483783\n",
      "Processing tile  12 with bbox of  766574.0095863969 9734338.672482966 796672.1280997 9764436.79224543\n",
      "Processing tile  13 with bbox of  766435.1301565208 9704377.394009726 796547.9895945289 9734490.254636947\n",
      "Processing tile  14 with bbox of  766281.4356877807 9674416.220039086 796409.0223975065 9704543.807877887\n",
      "Processing tile  15 with bbox of  796935.508105151 9854112.366660533 826989.4284901392 9884166.288589913\n",
      "Processing tile  16 with bbox of  796855.8619333096 9824135.933097513 826924.5833758411 9854204.65602504\n",
      "Processing tile  17 with bbox of  796761.3793677231 9794159.563799836 826844.8892151774 9824243.07507269\n",
      "Processing tile  18 with bbox of  796652.0626300345 9764183.269703174 826750.3478875457 9794281.55632629\n",
      "Processing tile  19 with bbox of  796527.9142906107 9734207.061734464 826640.9616224151 9764320.110371888\n",
      "Processing tile  20 with bbox of  796388.9372684445 9704230.950810647 826516.7329992424 9734358.747786883\n",
      "Processing tile  21 with bbox of  796235.1348310462 9674254.94783739 826377.6649473748 9704397.479138788\n",
      "Processing tile  22 with bbox of  826904.5375239602 9854040.05988729 856973.3655577735 9884108.889523048\n",
      "Processing tile  23 with bbox of  826824.8334971385 9824048.772630481 856908.471836748 9854132.412512414\n",
      "Processing tile  24 with bbox of  826730.2823120176 9794057.55169744 856828.7179476267 9824155.988815552\n",
      "Processing tile  25 with bbox of  826620.8861982946 9764066.408374507 856734.105776671 9794179.629375365\n",
      "Processing tile  26 with bbox of  826496.6477356538 9734075.353939196 856624.6375614875 9764203.345127294\n",
      "Processing tile  27 with bbox of  826357.569853667 9704084.399658918 856500.315890949 9734227.146998053\n",
      "Processing tile  28 with bbox of  856888.4160390527 9853967.698083118 886972.1643869209 9884051.448090686\n",
      "Processing tile  29 with bbox of  856808.6522776132 9823961.545838425 886907.220524319 9854060.115684986\n",
      "Processing tile  30 with bbox of  856714.0302432461 9793955.461983467 886827.4050204703 9824068.838300494\n",
      "Processing tile  31 with bbox of  856604.552173788 9763949.45815653 886732.7197685668 9794077.627230864\n",
      "Processing tile  32 with bbox of  856480.2206583386 9733943.545986995 886623.1670144428 9764086.493762206\n",
      "Processing tile  33 with bbox of  886887.1547721326 9853895.279534072 916985.8364565923 9883993.96293619\n",
      "Processing tile  34 with bbox of  886807.3293895744 9823874.250655366 916920.8409119246 9853987.763835305\n",
      "Processing tile  35 with bbox of  886712.6342681092 9793853.29223998 916840.9619001417 9823981.62146932\n",
      "Processing tile  36 with bbox of  886603.0716537999 9763832.416279454 916746.2013214437 9793975.547483923\n",
      "Processing tile  37 with bbox of  886478.6441452604 9733811.634756314 916636.5614299764 9763969.553517174\n",
      "Processing tile  38 with bbox of  886339.3546935583 9703790.959642775 916512.0448337386 9733963.651198218\n",
      "Processing tile  39 with bbox of  916820.8762992157 9823786.885007707 946949.3448256478 9853915.355249666\n",
      "Processing tile  40 with bbox of  916726.1058445752 9793751.040040135 946869.4004057175 9823894.336256294\n",
      "Processing tile  41 with bbox of  916616.4560867834 9763715.279963266 946774.5622460672 9793873.387716848\n",
      "Processing tile  42 with bbox of  916491.9296340691 9733679.617114097 946664.8326092388 9763852.521622647\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(tile_bboxes)):\n",
    "# for i in range(0,3):\n",
    "    x_min,y_min,x_max,y_max=tile_bboxes.iloc[i]\n",
    "    print('Processing tile ',i,'with bbox of ',x_min,y_min,x_max,y_max)\n",
    "    # clip land cover maps to tile boundary\n",
    "    landcover2021_tile=landcover2021.rio.clip_box(minx=x_min,miny=y_min,maxx=x_max,maxy=y_max)\n",
    "    ds_geobox=landcover2021_tile.geobox\n",
    "    np_landcover2021=landcover2021_tile.squeeze().to_numpy()\n",
    "    np_landcover2021_post=np_landcover2021.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b058a2b7-83a2-4925-8327-614ae1e799d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('geoenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "01a9736267bf300689e8e016092cd01f0c67384dd94651ae6e139a291bc8cc97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e1b4eb1",
   "metadata": {},
   "source": [
    "This notebook implements morphological filtering and rule-based reclassification using external layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4be218a",
   "metadata": {},
   "source": [
    "## load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c15f173",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import datacube\n",
    "import warnings\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "from rasterio.enums import Resampling\n",
    "from datacube.utils.cog import write_cog\n",
    "from deafrica_tools.spatial import xr_rasterize\n",
    "from skimage.morphology import binary_dilation,disk,area_closing,remove_small_holes\n",
    "from skimage.filters.rank import modal\n",
    "from skimage.segmentation import expand_labels\n",
    "from odc.algo import xr_reproject\n",
    "import matplotlib.pyplot as plt\n",
    "from deafrica_tools.bandindices import calculate_indices\n",
    "from deafrica_tools.coastal import get_coastlines\n",
    "from glob import glob\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a1cf9d",
   "metadata": {},
   "source": [
    "### set input layers and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90ef50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_crs='epsg:32736' # output crs: WGS84/UTM Zone 36S \n",
    "dict_map={'Tree crops':11,'Field crops':12,'Forest plantations':21,'Grassland':31,\n",
    "                 'Wetland':41,'Water body':44,\n",
    "                 'Settlements':51,'Bare soils':61,'Mangrove':70,'Mecrusse':71,\n",
    "                'Broadleaved (Semi-) evergreen forest':72,'Broadleaved (Semi-) deciduous forest':74,'Mopane':75} # a dictionary of pixel value for each class\n",
    "# file paths\n",
    "mozambique_boundary_shp='Data/Mozambique_boundary.shp'\n",
    "river_network_shp='Data/hotosm_moz_waterways_lines_filtered.shp' # OSM river network data\n",
    "road_network_shp='Data/hotosm_moz_roads_lines_filtered.shp' # OSM road network data\n",
    "google_building_raster='Data/GoogleBuildingLayer_Mozambique_rasterised.tif' # google bulding layer\n",
    "hand_raster='Data/hand_Mozambique_UInt16.tif' # Hydrologically adjusted elevations, i.e. height above the nearest drainage (hand)\n",
    "wsf2019_raster='Data/WSF2019_v1_Mozambique_clipped.tif' # 2019 WSF raster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73816345",
   "metadata": {},
   "source": [
    "## load layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62bc8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mozambique boundary and get bounding box\n",
    "mozambique_boundary=gpd.read_file(mozambique_boundary_shp).to_crs(output_crs)\n",
    "# load and pre-process external vector layers\n",
    "road_network=gpd.read_file(road_network_shp).to_crs(output_crs) # import OSM road network data and reproject\n",
    "road_network=road_network.loc[road_network['surface'].isin(['asphalt', 'paved', 'compacted', 'cobblestone', \n",
    "                                                             'concrete', 'metal', 'paving_stones', \n",
    "                                                             'paving_stones:30'])] # select road network by attributes\n",
    "road_network.geometry=road_network.geometry.buffer(10) # buffer the road network by 10m\n",
    "\n",
    "river_network=gpd.read_file(river_network_shp).to_crs(output_crs) # import OSM river network data and reproject\n",
    "river_network=river_network.loc[river_network['waterway'].isin(['canal','river'])] # select river network by attribute\n",
    "\n",
    "# load coastline layer and buffer\n",
    "shorelines_gdf = get_coastlines(mozambique_boundary.bounds.iloc[0],crs=output_crs,layer='shorelines').to_crs(output_crs)\n",
    "shorelines_gdf_2021=shorelines_gdf[shorelines_gdf['year']=='2021'] # select only 2021\n",
    "shorelines_gdf_2021.geometry=shorelines_gdf_2021.geometry.buffer(50000) # buffer the road network by 50km"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5923bb4",
   "metadata": {},
   "source": [
    "### Find prediction tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf78895",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification2021_rasters=glob(\"Results/Mozmabique_land_cover_prediction_tile_*.tif\")\n",
    "len(classification2021_rasters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9080cf9",
   "metadata": {},
   "source": [
    "### loop through tiles for reclassification and export as geotiffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467c5a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through tiles for reclassification\n",
    "# for classification2021_raster in classification2021_rasters:\n",
    "for classification2021_raster in classification2021_rasters:\n",
    "    print('processing ',classification2021_raster)\n",
    "    outname_postprocessed=classification2021_raster.replace('prediction','prediction_postprocessed')\n",
    "    if os.path.exists(outname_postprocessed):\n",
    "        print('tile processed, skipping...')\n",
    "        continue\n",
    "        \n",
    "    # clip raster to tile extent\n",
    "    tile_shp='Results/Mozambique_tile_extent.shp' # output tile extent\n",
    "    if os.path.exists(tile_shp):\n",
    "        os.remove(tile_shp)\n",
    "    google_building_clipped=google_building_raster[:-4]+'_clipped.tif' # clipped google bulding mask layer\n",
    "    hand_raster_clipped=hand_raster[:-4]+'_clipped.tif' # clipped hand layer\n",
    "    wsf2019_raster_clipped=wsf2019_raster[:-4]+'_clipped.tif' # clipped WSF 2019 layer\n",
    "    subprocess.run(['gdaltindex',tile_shp,classification2021_raster])\n",
    "    subprocess.run(['gdalwarp','-cutline',tile_shp,'-crop_to_cutline', '-t_srs',output_crs,'-tr','10','10',\n",
    "                    '-r','near',google_building_raster,google_building_clipped,'-overwrite','-ot','Byte'])\n",
    "    subprocess.run(['gdalwarp','-cutline',tile_shp,'-crop_to_cutline','-t_srs',output_crs,'-tr','10','10',\n",
    "                    '-r','bilinear',hand_raster,hand_raster_clipped,'-overwrite','-ot','UInt16'])\n",
    "    subprocess.run(['gdalwarp','-cutline',tile_shp,'-crop_to_cutline', '-t_srs',output_crs,'-tr','10','10',\n",
    "                    '-r','near',wsf2019_raster,wsf2019_raster_clipped,'-overwrite','-ot','Byte'])\n",
    "    \n",
    "    # read in tiled raster\n",
    "    landcover2021=rioxarray.open_rasterio(classification2021_raster).astype(np.uint8).squeeze()\n",
    "    # get geobox\n",
    "    ds_geobox=landcover2021.geobox\n",
    "    \n",
    "    # load s2 annual geomedian and calcualte MNDWI\n",
    "    bbox=ds_geobox.extent.boundingbox\n",
    "    dc = datacube.Datacube(app='s2_geomedian')\n",
    "    query_geomedian= {\n",
    "        'time': ('2021'),\n",
    "        'x': (bbox[0],bbox[2]),\n",
    "        'y': (bbox[1],bbox[3]),\n",
    "        'resolution':(-10, 10),\n",
    "        'crs':output_crs,\n",
    "        'output_crs': output_crs,\n",
    "        'measurements':['green','swir_1']\n",
    "    }\n",
    "    ds_geomedian = dc.load(product=\"gm_s2_annual\", **query_geomedian)\n",
    "    ds_MNDWI = calculate_indices(ds=ds_geomedian, index='MNDWI', satellite_mission='s2',drop=True).squeeze()\n",
    "    \n",
    "    # load DE Africa crop mask 2019\n",
    "    dc = datacube.Datacube(app='cropland_extent')\n",
    "    query = {\n",
    "        'time': ('2019'),\n",
    "        'x': (bbox[0],bbox[2]),\n",
    "        'y': (bbox[1],bbox[3]),\n",
    "        'resolution':(-10, 10),\n",
    "        'crs':output_crs,\n",
    "        'output_crs': output_crs,\n",
    "    }\n",
    "    # now load the crop-mask using the query\n",
    "    cm = dc.load(product='crop_mask',**query).squeeze()\n",
    "    np_crop_mask=cm['mask'].to_numpy()\n",
    "    \n",
    "    # data array to numpy array\n",
    "    np_landcover2021=landcover2021.squeeze().to_numpy()\n",
    "    \n",
    "    # initialise post-processed numpy array\n",
    "    np_landcover2021_post=np_landcover2021.copy() \n",
    "    \n",
    "    # mode filtering for a smoother classification map\n",
    "    np_landcover2021_post=modal(np_landcover2021,footprint=disk(2),mask=np_landcover2021!=0)\n",
    "    \n",
    "#     # assign Field crops pixels outside DE Africa 2019 cropland mask as Grassland\n",
    "#     np_landcover2021_post[(np_landcover2021_post==dict_map['Field crops'])&(np_crop_mask!=1)]=dict_map['Grassland']\n",
    "    \n",
    "    # assgin Grassland pixels inside DE Africa 2019 cropland mask as tree crops\n",
    "    np_landcover2021_post[(np_landcover2021_post==dict_map['Grassland'])&(np_crop_mask==1)]=dict_map['Tree crops']\n",
    "    \n",
    "    # assign bare soil pixels inside DE Africa 2019 cropland mask as Field crops\n",
    "    np_landcover2021_post[(np_landcover2021_post==dict_map['Bare soils'])&(np_crop_mask==1)]=dict_map['Field crops']\n",
    "    \n",
    "    # assign Wetland pixels inside DE Africa 2019 cropland mask as Field crops\n",
    "    np_landcover2021_post[(np_landcover2021_post==dict_map['Wetland'])&(np_crop_mask==1)]=dict_map['Field crops']\n",
    "    \n",
    "    # reassign forest classes smaller than 1 hectare to surrounding class\n",
    "    forest_mask=np.full(np_landcover2021_post.shape,True)\n",
    "    forest_mask[(np_landcover2021_post==dict_map['Broadleaved (Semi-) evergreen forest'])\n",
    "                |(np_landcover2021_post==dict_map['Broadleaved (Semi-) deciduous forest'])\n",
    "                |(np_landcover2021_post==dict_map['Forest plantations'])]=0 # identify all forest pixels\n",
    "    forest_mask_filled=remove_small_holes(forest_mask, area_threshold=100, connectivity=2) # fill holes smaller than 100 pixels\n",
    "    forest_mask=(forest_mask!=forest_mask_filled) # identify the filled small regions\n",
    "    lc_copy=np_landcover2021_post.copy()\n",
    "    lc_copy[forest_mask==1]=0 # assign the regions as background\n",
    "    lc_copy_filled=expand_labels(lc_copy,distance=10000) # expand surrounding classes\n",
    "    mask=(lc_copy_filled!=lc_copy) # identify filled/changed areas\n",
    "    np_landcover2021_post[mask]=lc_copy_filled[mask] # copy the filled/changed pixels\n",
    "    \n",
    "    # Make sure water is (only occuring at bottom of watersheds) or fallen within OSM river networks\n",
    "    # assign water pixels outside these areas as surrounding class\n",
    "    hand=xr.open_dataset(hand_raster_clipped,engine=\"rasterio\").squeeze() # import hand layer\n",
    "    hand=xr_reproject(hand, ds_geobox, resampling=\"average\")\n",
    "    np_hand=hand.to_array().squeeze().to_numpy()\n",
    "    del hand\n",
    "    np_river_network_mask=xr_rasterize(gdf=river_network,da=landcover2021.squeeze(),\n",
    "                                    transform=landcover2021.geobox.transform,crs=output_crs) # rasterise OSM river network layer\n",
    "    np_river_network_mask=xr_reproject(np_river_network_mask, ds_geobox, resampling=\"nearest\")\n",
    "    np_river_network_mask=np_river_network_mask.squeeze().to_numpy() # data array to numpy array\n",
    "    temp=np_landcover2021_post.copy()\n",
    "    temp[(np_landcover2021_post==dict_map['Water body'])&(np_hand>45)&(np_river_network_mask!=1)]=0\n",
    "    temp_closed=expand_labels(temp,distance=10000)\n",
    "    mask=(temp!=temp_closed)\n",
    "    np_landcover2021_post[mask]=temp_closed[mask]\n",
    "    \n",
    "    # assign pixels overlapping OSM river network as Water Body\n",
    "    np_landcover2021_post[np_river_network_mask==1]=dict_map['Water body']\n",
    "    \n",
    "    # assign Wetland pixels outside DE Africa 2019 cropland mask and hand>90m as surrounding classes\n",
    "    temp=np_landcover2021_post.copy()\n",
    "    temp[(np_landcover2021_post==dict_map['Wetland'])&(np_hand>90)&(np_crop_mask!=1)]=0\n",
    "    temp_closed=expand_labels(temp,distance=10000)\n",
    "    mask=(temp!=temp_closed)\n",
    "    np_landcover2021_post[mask]=temp_closed[mask]\n",
    "    \n",
    "    # assign pixels overlapping google building polygons or WSF 2019 as built-up\n",
    "    google_buildings=xr.open_dataset(google_building_clipped,engine=\"rasterio\").astype(np.int8).squeeze() # import google bulding layer\n",
    "    google_buildings=xr_reproject(google_buildings, ds_geobox, resampling=\"nearest\")\n",
    "    np_google_buildings=google_buildings.to_array().squeeze().to_numpy() # data array to numpy array\n",
    "    del google_buildings\n",
    "    np_wsf2019=xr.open_dataset(wsf2019_raster_clipped,engine=\"rasterio\").astype(np.int32).squeeze() # import WSF2019 layers\n",
    "    np_wsf2019=xr_reproject(np_wsf2019, ds_geobox, resampling=\"nearest\") # load and clip WSF layers\n",
    "    np_wsf2019=np_wsf2019.to_array().squeeze().to_numpy()\n",
    "    np_landcover2021_post[(np_google_buildings==1)|(np_wsf2019==255)]=dict_map['Settlements'] # apply rules\n",
    "    \n",
    "    # assign pixesl overlapping buffered OSM road network as built-up class\n",
    "    np_road_network_mask=xr_rasterize(gdf=road_network,da=landcover2021.squeeze(),\n",
    "                                   transform=ds_geobox.transform,crs=output_crs) # # rasterise buffered OSM road network layer\n",
    "    np_road_network_mask=np_road_network_mask.squeeze().to_numpy() # data array to numpy array\n",
    "    np_landcover2021_post[np_road_network_mask==1]=dict_map['Settlements'] # burn in buffered OSM road network polygons\n",
    "    \n",
    "#     # reclassify wetlands around (within 50m of) built-up areas as tree crops\n",
    "#     urban_buffered=binary_dilation(np_landcover2021_post==51,footprint=disk(5)) # dilating built-up regions\n",
    "#     np_landcover2021_post[(urban_buffered==1)&(np_landcover2021_post==41)]=11 # apply rule\n",
    "    \n",
    "    # reassign water using NDWI calculated from annual S2 geomedian\n",
    "    np_MNDWI=ds_MNDWI['MNDWI'].to_numpy()\n",
    "    np_landcover2021_post[np_MNDWI>=0]=dict_map['Water body']\n",
    "    \n",
    "    # reassign mangroves outside 50km of coastline as Forest Plantation\n",
    "    np_shorelines_2021_mask=xr_rasterize(gdf=shorelines_gdf_2021,da=landcover2021.squeeze(),\n",
    "                                    transform=ds_geobox.transform,crs=output_crs) # rasterise layer\n",
    "    np_shorelines_2021_mask=np_shorelines_2021_mask.squeeze().to_numpy()\n",
    "    np_landcover2021_post[(np_shorelines_2021_mask==0)&(np_landcover2021_post==dict_map['Mangrove'])]=dict_map['Forest plantations']\n",
    "    \n",
    "    # convert back result back to DataArray\n",
    "    landcover2021_post=xr.DataArray(data=np_landcover2021_post,dims=['y','x'],coords={'y':landcover2021.y.to_numpy(), 'x':landcover2021.x.to_numpy()})\n",
    "    landcover2021_post.rio.write_crs(output_crs, inplace=True)\n",
    "    \n",
    "    # export as geotiff\n",
    "    write_cog(landcover2021_post, outname_postprocessed, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadfbe56-893a-487a-bfc1-02d69c3462b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "01a9736267bf300689e8e016092cd01f0c67384dd94651ae6e139a291bc8cc97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements outlier removal method to filter training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load packages and get number of cpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import datacube\n",
    "import warnings\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from odc.io.cgroups import get_cpu_quota\n",
    "from datacube.utils.cog import write_cog\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from rasterio.enums import Resampling\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "ncpus=round(get_cpu_quota())\n",
    "print('ncpus = '+str(ncpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load input files and set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths and attributes\n",
    "training_signature_path='Results/train_poly_848_20171124_signatures_2021.geojson' # extracted training features\n",
    "rf2017_path='Data/moz_lulc2016_28082019_final.tif' # reference map\n",
    "\n",
    "crs='epsg:32736' # WGS84/UTM Zone 36S\n",
    "measurements = ['blue','green','red','red_edge_1','red_edge_2', 'red_edge_3','nir_1','swir_1','swir_2','NDVI']\n",
    "measurements_MAD=['smad','emad','bcmad']\n",
    "class_name = 'Class_I' # class label in integer format\n",
    "column_names=[class_name]\n",
    "for measurement in measurements:\n",
    "    for i in range(6):\n",
    "        column_names.append(measurement+'_'+str(i))\n",
    "for measurement in measurements_MAD:\n",
    "    for i in range(2):\n",
    "        column_names.append(measurement+'_'+str(i))\n",
    "        \n",
    "# dictionary of class value - class name before and after merging\n",
    "dict_map={11:'Tree crops',12:'Field crops',21:'Forest plantations',31:'Grassland',\n",
    "          33:'Shrubland',41:'Aquatic or regularly flooded shrublands',42:'Aquatic or regularly flooded herbaceous vegetation',\n",
    "          44:'Water body',51:'Settlements',61:'Bare soils',62:'Bare rocks',70:'Mangrove',\n",
    "          71:'Mecrusse',72:'Closed broadleaved (Semi-) evergreen mountaineous forest',73:'Gallery forest',\n",
    "          74: 'Broadleaved (Semi-) deciduous closed forest',75:'Mopane',76:'Open broadleaved (Semi-) evergreen mountaineous forest',\n",
    "          77:'Coastal open woody vegetation',78:'Mopane open',79:'Miombo open'}\n",
    "dict_map_merged={11:'Tree crops',12:'Field crops',21:'Forest plantations',31:'Grassland',\n",
    "                 41:'Aquatic or regularly flooded herbaceous vegetation',44:'Water body',\n",
    "                 51:'Settlements',61:'Bare soils',70:'Mangrove',71:'Mecrusse',\n",
    "                72:'Broadleaved (Semi-) evergreen forest',74:'Broadleaved (Semi-) deciduous forest',75:'Mopane'} # dictionary of merged classes\n",
    "\n",
    "# Load extracted features and reproject\n",
    "training_data2017= gpd.read_file(training_signature_path).to_crs(crs) # read training points as geopandas dataframe\n",
    "column_names.append('geometry')\n",
    "training_data2017=training_data2017[column_names] # select attributes\n",
    "training_data2017[class_name]=training_data2017[class_name].astype(int)\n",
    "print('land cover survey points 2017:\\n',training_data2017)\n",
    "\n",
    "# load initial classification map\n",
    "rf_2017_raster = xr.open_dataset(rf2017_path,engine=\"rasterio\").astype(np.uint8).squeeze(\"band\", drop=True)\n",
    "# # reproject the raster\n",
    "rf_2017_raster= rf_2017_raster.rio.reproject(resolution=30, dst_crs=crs,resampling=Resampling.nearest)\n",
    "rf_2017_raster=rf_2017_raster.band_data\n",
    "print('Reference land cover classifcation raster:\\n',rf_2017_raster) # note: 255 is nodata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oringal and merged class values\n",
    "original_class=[11, 12, 21, 31,33, 41,42, 44, 51, 61,62, 70, 71, 72,73,76,77, 75,78, 74,79]\n",
    "original_class=dict_map.keys()\n",
    "mapped_class=[11, 12, 21, 31, 31,41,41, 44, 51, 61, 61,70, 71, 72,72,72,72, 75,75, 74,74]\n",
    "rf_2017_mapped=rf_2017_raster.copy()\n",
    "crs_copy_2017=rf_2017_raster.rio.crs\n",
    "\n",
    "# merge classes on reference map\n",
    "for i in range(len(original_class)):\n",
    "    rf_2017_mapped=xr.where(rf_2017_raster==original_class[i],mapped_class[i],rf_2017_mapped)\n",
    "if rf_2017_mapped.rio.crs is None: # reassign crs which was lost during last step of using xr.where\n",
    "    rf_2017_mapped.rio.write_crs(crs_copy_2017,inplace=True)\n",
    "if rf_2017_mapped.rio.crs!=crs: # reproject 2015 land cover map if needed\n",
    "    rf_2017_mapped=rf_2017_mapped.rio.reproject(resolution=30, dst_crs=crs,resampling=Resampling.nearest)\n",
    "\n",
    "# # export class-merged reference map\n",
    "# write_cog(rf_2017_mapped, 'Results/moz_lulc2016_28082019_final_remapped.tif', overwrite=True)\n",
    "\n",
    "# merge classes on training data \n",
    "training_data2017.loc[training_data2017[class_name]==33,class_name]=31\n",
    "training_data2017.loc[training_data2017[class_name]==42,class_name]=41\n",
    "training_data2017.loc[training_data2017[class_name]==62,class_name]=61\n",
    "training_data2017.loc[(training_data2017[class_name]==73)|(training_data2017[class_name]==76)\n",
    "                     |(training_data2017[class_name]==77),class_name]=72\n",
    "training_data2017.loc[training_data2017[class_name]==78,class_name]=75\n",
    "training_data2017.loc[training_data2017[class_name]==79,class_name]=74\n",
    "\n",
    "## export class-merged training data\n",
    "# training_data2017.to_file('Results/train_poly_848_20171124_signatures_2021_remapped.geojson', driver=\"GeoJSON\")\n",
    "\n",
    "# get merged class labels\n",
    "lc_classes=training_data2017[class_name].unique() \n",
    "print('land cover classes:\\n',lc_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter out a pre-defined percentage of samples using the Local Outlier Factor (LOF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td2021_filtered=None # filtered training data\n",
    "scaler = StandardScaler() # standard scaler for input data standardisation\n",
    "# filtering training data for each class\n",
    "for i in lc_classes:\n",
    "    print('Processing class ',i)\n",
    "    # subset original training points for this class\n",
    "    td_single_class=training_data2017[training_data2017[class_name]==i].reset_index(drop=True)\n",
    "    print('Number of training data collected: ',len(td_single_class))\n",
    "    # normalisation before clustering\n",
    "    model_input=scaler.fit_transform(td_single_class.to_numpy()[:,1:-1])\n",
    "    clf = LocalOutlierFactor(contamination=0.15) # 15% samples were assumed outliers\n",
    "    y_pred=clf.fit_predict(model_input)\n",
    "    # append prediction to features dataframe\n",
    "    td_single_class_filtered=td_single_class.copy()\n",
    "    td_single_class_filtered['LOF_pred']=y_pred\n",
    "    td_single_class_filtered=td_single_class_filtered[td_single_class_filtered['LOF_pred']==1]\n",
    "    print('Number of training data after filtering: ',len(td_single_class_filtered))\n",
    "    # save filtered results for single class\n",
    "    td_single_class_filtered.to_file('Results/train_poly_848_20171124_signatures_2021_force_15pct_filtered_class_'+str(i)+'.geojson', driver=\"GeoJSON\")\n",
    "    # append the filtered training points of this class to final filtered training data\n",
    "    if td2021_filtered is None:\n",
    "        td2021_filtered=td_single_class_filtered\n",
    "    else:\n",
    "        td2021_filtered=pd.concat([td2021_filtered, td_single_class_filtered])\n",
    "        \n",
    "# remove NaNs which were somehow export as zeros during extraction of training data\n",
    "td2021_filtered=td2021_filtered.loc[(td2021_filtered!=0).all(axis=1)].reset_index(drop=True)\n",
    "print('training data after removing nans\\n',td2021_filtered)\n",
    "\n",
    "# save training data for all classes\n",
    "td2021_filtered.to_file('Results/train_poly_848_20171124_signatures_2021_force_15pct_filtered.geojson', driver=\"GeoJSON\")\n",
    "\n",
    "# export the filtered training data as txt file\n",
    "output_file = \"Results/train_poly_848_20171124_signatures_2021_force_15pct_filtered.txt\"\n",
    "td2021_filtered.to_csv(output_file, header=True, index=None, sep=' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('geoenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "01a9736267bf300689e8e016092cd01f0c67384dd94651ae6e139a291bc8cc97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook extracts training features from the Open Data Cube (ODC) of Sentinel-2 multispectral images, using unfiltered) training data in a previous year. The features include three-month rolling geomedians of Sentinel-2 bands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load packages and get number of cpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import datacube\n",
    "import warnings\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from odc.io.cgroups import get_cpu_quota\n",
    "from odc.algo import xr_geomedian\n",
    "from deafrica_tools.plotting import map_shapefile\n",
    "from deafrica_tools.datahandling import load_ard\n",
    "from deafrica_tools.bandindices import calculate_indices\n",
    "from deafrica_tools.classification import collect_training_data\n",
    "from datacube.utils.cog import write_cog\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input files and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_path = 'Data/train_poly_848_20171124.shp'\n",
    "input_map_path='Data/moz_lulc2016_28082019_final.tif' # Note: this data provided by FNDS is too large to be uploaded to github\n",
    "class_attr = 'Class_I' # class label in integer format\n",
    "output_crs='epsg:32736' # WGS84/UTM Zone 36S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load input data shapefile\n",
    "training_data= gpd.read_file(training_data_path) # read training points as geopandas dataframe\n",
    "training_data=training_data[[class_attr,'geometry']] # select attributes\n",
    "# Plot first five rows\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class merging for training data and reference map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_map={'Tree crops': 11, 'Field crops': 12, 'Forest plantations': 21, 'Grassland': 31, 'Shrubland': 33, 'Aquatic or regularly flooded shrublands': 41,\n",
    " 'Aquatic or regularly flooded herbaceous vegetation': 42, 'Water body': 44, 'Settlements': 51, 'Bare soils': 61,\n",
    " 'Bare rocks': 62, 'Mangrove': 70, 'Mecrusse': 71, 'Closed broadleaved (Semi-) evergreen mountaineous forest': 72,\n",
    " 'Gallery forest': 73, 'Broadleaved (Semi-) deciduous closed forest': 74, 'Mopane': 75, 'Open broadleaved (Semi-) evergreen mountaineous forest': 76,\n",
    " 'Coastal open woody vegetation': 77, 'Mopane open': 78, 'Miombo open': 79}\n",
    "\n",
    "training_data.loc[training_data[class_attr]==dict_map['Shrubland'],class_attr]=dict_map['Grassland']\n",
    "training_data.loc[training_data[class_attr]==dict_map['Aquatic or regularly flooded herbaceous vegetation'],\n",
    "                  class_attr]=dict_map['Aquatic or regularly flooded shrublands']\n",
    "training_data.loc[training_data[class_attr]==dict_map['Bare rocks'],class_attr]=dict_map['Bare soils']\n",
    "training_data.loc[(training_data[class_attr]==dict_map['Gallery forest'])|\n",
    "                  (training_data[class_attr]==dict_map['Open broadleaved (Semi-) evergreen mountaineous forest'])\n",
    "                  |(training_data[class_attr]==dict_map['Coastal open woody vegetation']),class_attr]=dict_map['Closed broadleaved (Semi-) evergreen mountaineous forest']\n",
    "training_data.loc[training_data[class_attr]==dict_map['Mopane open'],class_attr]=dict_map['Mopane']\n",
    "training_data.loc[training_data[class_attr]==dict_map['Miombo open'],class_attr]=dict_map['Broadleaved (Semi-) deciduous closed forest']\n",
    "\n",
    "# optionally export class merged training data\n",
    "out_folder='Results'\n",
    "if not os.path.exists(out_folder):\n",
    "    os.makedirs(out_folder)\n",
    "training_data.to_file('Results/train_poly_848_20171124_class_merged.geojson', driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_map=xr.open_dataset(input_map_path,engine=\"rasterio\").astype(np.uint8)\n",
    "classification_map=classification_map.to_array().squeeze()\n",
    "classification_map=classification_map.where(classification_map!=dict_map['Shrubland'],dict_map['Grassland'])\n",
    "classification_map=classification_map.where(classification_map!=dict_map['Aquatic or regularly flooded herbaceous vegetation'],\n",
    "                                            dict_map['Aquatic or regularly flooded shrublands'])\n",
    "classification_map=classification_map.where(classification_map!=dict_map['Bare rocks'],\n",
    "                                            dict_map['Bare soils'])\n",
    "classification_map=classification_map.where((classification_map!=dict_map['Gallery forest'])\n",
    "                                            &(classification_map!=dict_map['Open broadleaved (Semi-) evergreen mountaineous forest'])\n",
    "                                            &(classification_map!=dict_map['Coastal open woody vegetation']),\n",
    "                                            dict_map['Closed broadleaved (Semi-) evergreen mountaineous forest'])\n",
    "classification_map=classification_map.where(classification_map!=dict_map['Mopane open'],\n",
    "                                            dict_map['Mopane'])\n",
    "classification_map=classification_map.where(classification_map!=dict_map['Miombo open'],\n",
    "                                            dict_map['Broadleaved (Semi-) deciduous closed forest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export class merged map for later use\n",
    "write_cog(classification_map, 'Results/moz_lulc2016_28082019_final_remapped.tif', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check if S2 rolling geomedian products are fully available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app='check rolling geomedians')\n",
    "list_products=list(dc.list_products()['name'])\n",
    "if 'gm_s2_rolling' in list(list_products):\n",
    "    check_query = {\"x\": (36.602, 36.603),\n",
    "                   \"y\": (-16.665,-16.664),\n",
    "                   \"time\": (\"2021-01-01\", \"2021-03-01\"),\n",
    "                   \"output_crs\": output_crs,\n",
    "                   \"resolution\": (-10,10)}\n",
    "    ds_check = dc.load(product=\"gm_s2_annual\",\n",
    "                 **check_query)\n",
    "    if ds_check.dims['time']>1:\n",
    "        gm_s2_available=True\n",
    "    else:\n",
    "        gm_s2_available=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define query and feature layer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements = ['blue','green','red','red_edge_1','red_edge_2', 'red_edge_3','nir_1','nir_2','swir_1','swir_2']\n",
    "resolution = (-10,10)\n",
    "if gm_s2_available:\n",
    "    query = {\n",
    "        'time': ('2021-01', '2021-12'),\n",
    "        'measurements': measurements,\n",
    "        'output_crs': output_crs,\n",
    "        'resolution': resolution\n",
    "    }\n",
    "    # define a function to feature layers\n",
    "    def feature_layers(query): \n",
    "        # connect to the datacube so we can access DE Africa data\n",
    "        dc = datacube.Datacube(app='rolling geomedians')\n",
    "        # load rolling geomedians\n",
    "        ds = dc.load(product='gm_s2_rolling',measurements=measurements,\n",
    "                     group_by='solar_day',**query)\n",
    "        ds = calculate_indices(ds,\n",
    "                           index=['NDVI'],\n",
    "                           drop=False,\n",
    "                           satellite_mission='s2')\n",
    "        n_time=ds.dims['time'] # 12\n",
    "        list_measurements=list(ds.keys())\n",
    "        ds_stacked=None\n",
    "        for j in range(len(list_measurements)):\n",
    "            for k in range(1,n_time,2): # extract the six months 2021-01, 2021-03, 2021-05,... 2021-11\n",
    "                variable_name=list_measurements[j]+'_'+str(k)\n",
    "                measure_single=ds[list_measurements[j]].isel(time=k).rename(variable_name)\n",
    "                if ds_stacked is None:\n",
    "                    ds_stacked=measure_single\n",
    "                else:\n",
    "                    ds_stacked=xr.merge([ds_stacked,measure_single],compat='override')\n",
    "        return ds_stacked\n",
    "else:\n",
    "    query = {\n",
    "        'time': ('2020-12', '2021-12'),\n",
    "        'measurements': measurements,\n",
    "        'output_crs': output_crs,\n",
    "        'resolution': resolution\n",
    "    }\n",
    "    # define a function to feature layers\n",
    "    def feature_layers(query):\n",
    "        dc = datacube.Datacube(app='rolling geomedians')\n",
    "        # load Sentinel-2 analysis ready data\n",
    "        ds = load_ard(dc=dc,\n",
    "                      products=['s2_l2a'],\n",
    "                      group_by='solar_day',\n",
    "                      verbose=False,\n",
    "                      **query)\n",
    "        ds = calculate_indices(ds,\n",
    "                               index=['NDVI'],\n",
    "                               drop=False,\n",
    "                               satellite_mission='s2')\n",
    "        # calculate rolling geomedians\n",
    "        time_slices=[('2020-12','2021-02'),('2021-02','2021-04'),('2021-04','2021-06'),\n",
    "                     ('2021-06','2021-08'),('2021-08','2021-10'),('2021-10','2021-12')]\n",
    "        ds_rolling=None\n",
    "        for i in range(len(time_slices)):\n",
    "            ds_single=xr_geomedian(ds.sel(time=slice(time_slices[i][0],time_slices[i][1]))).assign_coords({'time':time_slices[i][0]})\n",
    "            if ds_rolling is None:\n",
    "                ds_rolling=ds_single\n",
    "            else:\n",
    "                ds_rolling=xr.concat([ds_rolling,ds_single],dim='time')\n",
    "        # stackmulti-temporal measurements and rename them\n",
    "        n_time=ds_rolling.dims['time']\n",
    "        list_measurements=list(ds_rolling.keys())\n",
    "        list_stack_measures=[]\n",
    "        for j in range(len(list_measurements)):\n",
    "            for k in range(n_time):\n",
    "#                 variable_name=list_measurements[j]+'_'+str(k)\n",
    "                variable_name=list_measurements[j]+'_'+str(2*k+1) # to keep consistent with above case\n",
    "                measure_single=ds_rolling[list_measurements[j]].isel(time=k).rename(variable_name)\n",
    "                list_stack_measures.append(measure_single)\n",
    "        ds_stacked=xr.merge(list_stack_measures,compat='override')\n",
    "        return ds_stacked    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect the number of CPUs\n",
    "ncpus=round(get_cpu_quota())\n",
    "print('ncpus = '+str(ncpus))\n",
    "\n",
    "# collect training data\n",
    "column_names, model_input = collect_training_data(\n",
    "    gdf=training_data, \n",
    "    dc_query=query,\n",
    "    ncpus=1, # adapt here based on your sandbox instance\n",
    "    field=class_attr,\n",
    "    zonal_stats=None,\n",
    "    feature_func=feature_layers,\n",
    "    return_coords=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export training features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data to geopandas dataframe\n",
    "pd_training_features=pd.DataFrame(data=model_input,columns=column_names)\n",
    "gpd_training_features=gpd.GeoDataFrame(pd_training_features, \n",
    "                                geometry=gpd.points_from_xy(model_input[:,-2], model_input[:,-1],\n",
    "                                                            crs=output_crs))\n",
    "#set the name and location of the output file\n",
    "output_file = \"Results/Mozambique_training_features.txt\"\n",
    "#Export files to disk\n",
    "gpd_training_features.to_csv(output_file, header=True, index=None, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "01a9736267bf300689e8e016092cd01f0c67384dd94651ae6e139a291bc8cc97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

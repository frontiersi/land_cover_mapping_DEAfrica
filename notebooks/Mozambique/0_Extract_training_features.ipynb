{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook extracts training features from the Open Data Cube (ODC) of Sentinel-2 multispectral images, using unfiltered) training data in a previous year. The features include three-month rolling geomedians of Sentinel-2 bands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load packages and get number of cpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import datacube\n",
    "import warnings\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from odc.io.cgroups import get_cpu_quota\n",
    "from odc.algo import xr_geomedian\n",
    "from deafrica_tools.plotting import map_shapefile\n",
    "from deafrica_tools.datahandling import load_ard\n",
    "from deafrica_tools.bandindices import calculate_indices\n",
    "from deafrica_tools.classification import collect_training_data\n",
    "from datacube.utils.cog import write_cog\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input files and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_path = 'Data/train_poly_848_20171124.shp'\n",
    "input_map_path='Data/moz_lulc2016_28082019_final.tif'\n",
    "class_attr = 'Class_I' # class label in integer format\n",
    "output_crs='epsg:32736' # WGS84/UTM Zone 36S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class_I</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>POLYGON ((1617790.363 -1879014.857, 1617787.18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76</td>\n",
       "      <td>POLYGON ((1632621.302 -1883379.171, 1632620.43...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42</td>\n",
       "      <td>POLYGON ((1626447.303 -1892631.641, 1626447.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76</td>\n",
       "      <td>POLYGON ((1619226.349 -1895421.518, 1619226.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>POLYGON ((1624004.000 -1903092.189, 1624003.70...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class_I                                           geometry\n",
       "0       51  POLYGON ((1617790.363 -1879014.857, 1617787.18...\n",
       "1       76  POLYGON ((1632621.302 -1883379.171, 1632620.43...\n",
       "2       42  POLYGON ((1626447.303 -1892631.641, 1626447.01...\n",
       "3       76  POLYGON ((1619226.349 -1895421.518, 1619226.05...\n",
       "4       41  POLYGON ((1624004.000 -1903092.189, 1624003.70..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load input data shapefile\n",
    "training_data= gpd.read_file(training_data_path) # read training points as geopandas dataframe\n",
    "training_data=training_data[[class_attr,'geometry']] # select attributes\n",
    "# Plot first five rows\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class merging for training data and reference map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_map={'Tree crops': 11, 'Field crops': 12, 'Forest plantations': 21, 'Grassland': 31, 'Shrubland': 33, 'Aquatic or regularly flooded shrublands': 41,\n",
    " 'Aquatic or regularly flooded herbaceous vegetation': 42, 'Water body': 44, 'Settlements': 51, 'Bare soils': 61,\n",
    " 'Bare rocks': 62, 'Mangrove': 70, 'Mecrusse': 71, 'Closed broadleaved (Semi-) evergreen mountaineous forest': 72,\n",
    " 'Gallery forest': 73, 'Broadleaved (Semi-) deciduous closed forest': 74, 'Mopane': 75, 'Open broadleaved (Semi-) evergreen mountaineous forest': 76,\n",
    " 'Coastal open woody vegetation': 77, 'Mopane open': 78, 'Miombo open': 79}\n",
    "\n",
    "training_data.loc[training_data[class_attr]==dict_map['Shrubland'],class_attr]=dict_map['Grassland']\n",
    "training_data.loc[training_data[class_attr]==dict_map['Aquatic or regularly flooded herbaceous vegetation'],\n",
    "                  class_attr]=dict_map['Aquatic or regularly flooded shrublands']\n",
    "training_data.loc[training_data[class_attr]==dict_map['Bare rocks'],class_attr]=dict_map['Bare soils']\n",
    "training_data.loc[(training_data[class_attr]==dict_map['Gallery forest'])|\n",
    "                  (training_data[class_attr]==dict_map['Open broadleaved (Semi-) evergreen mountaineous forest'])\n",
    "                  |(training_data[class_attr]==dict_map['Coastal open woody vegetation']),class_attr]=dict_map['Closed broadleaved (Semi-) evergreen mountaineous forest']\n",
    "training_data.loc[training_data[class_attr]==dict_map['Mopane open'],class_attr]=dict_map['Mopane']\n",
    "training_data.loc[training_data[class_attr]==dict_map['Miombo open'],class_attr]=dict_map['Broadleaved (Semi-) deciduous closed forest']\n",
    "\n",
    "# optionally export class merged training data\n",
    "out_folder='Results'\n",
    "if not os.path.exists(out_folder):\n",
    "    os.makedirs(out_folder)\n",
    "training_data.to_file('Results/train_poly_848_20171124_class_merged.geojson', driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_map=xr.open_dataset(input_map_path,engine=\"rasterio\").astype(np.uint8)\n",
    "classification_map=classification_map.to_array().squeeze()\n",
    "classification_map=classification_map.where(classification_map!=dict_map['Shrubland'],dict_map['Grassland'])\n",
    "classification_map=classification_map.where(classification_map!=dict_map['Aquatic or regularly flooded herbaceous vegetation'],\n",
    "                                            dict_map['Aquatic or regularly flooded shrublands'])\n",
    "classification_map=classification_map.where(classification_map!=dict_map['Bare rocks'],\n",
    "                                            dict_map['Bare soils'])\n",
    "classification_map=classification_map.where(classification_map!=dict_map['Gallery forest'],\n",
    "                                            dict_map['Open broadleaved (Semi-) evergreen mountaineous forest'])\n",
    "classification_map=classification_map.where(classification_map!=dict_map['Coastal open woody vegetation'],\n",
    "                                            dict_map['Closed broadleaved (Semi-) evergreen mountaineous forest'])\n",
    "classification_map=classification_map.where(classification_map!=dict_map['Mopane open'],\n",
    "                                            dict_map['Mopane'])\n",
    "classification_map=classification_map.where(classification_map!=dict_map['Miombo open'],\n",
    "                                            dict_map['Broadleaved (Semi-) deciduous closed forest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('Results/moz_lulc2016_28082019_final_remapped.tif')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export class merged map for later use\n",
    "write_cog(classification_map, 'Results/moz_lulc2016_28082019_final_remapped.tif', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 11, 12, 21, 24, 26, 31, 41, 44, 51, 61, 70, 71, 72, 74, 75, 76],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(classification_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define query and feature layer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up our inputs to collect_training_data\n",
    "zonal_stats = None\n",
    "# Set up the inputs for the ODC query\n",
    "time = ('2021')\n",
    "# using spectral bands with 10~20 m spatial resolution\n",
    "measurements = ['blue','green','red','red_edge_1','red_edge_2', 'red_edge_3','nir_1','nir_2','swir_1','swir_2']\n",
    "resolution = (-10,10)\n",
    "query = {\n",
    "    'time': time,\n",
    "    'measurements': measurements,\n",
    "    'output_crs': output_crs,\n",
    "    'resolution': resolution\n",
    "}\n",
    "# define a function to feature layers\n",
    "def feature_layers(query): \n",
    "    # connect to the datacube so we can access DE Africa data\n",
    "    dc = datacube.Datacube(app='rolling geomedians')\n",
    "    \n",
    "    # load Sentinel-2 analysis ready data\n",
    "    ds = load_ard(dc=dc,\n",
    "                  products=['s2_l2a'],\n",
    "                  group_by='solar_day',\n",
    "                  verbose=False,\n",
    "                  **query)\n",
    "    \n",
    "    # calculate NDVI\n",
    "    ds = calculate_indices(ds,\n",
    "                           index=['NDVI'],\n",
    "                           drop=False,\n",
    "                           satellite_mission='s2')\n",
    "\n",
    "    # calculate bi-monthly geomedian\n",
    "    ds=ds.resample(time='2MS').map(xr_geomedian)\n",
    "    \n",
    "    # stack multi-temporal measurements and rename them\n",
    "    n_time=ds.dims['time']\n",
    "    list_measurements=list(ds.keys())\n",
    "    list_stack_measures=[]\n",
    "    for j in range(len(list_measurements)):\n",
    "        for k in range(n_time):\n",
    "            variable_name=list_measurements[j]+'_'+str(k)\n",
    "            measure_single=ds[list_measurements[j]].isel(time=k).rename(variable_name)\n",
    "            list_stack_measures.append(measure_single)\n",
    "    ds_stacked=xr.merge(list_stack_measures,compat='override')\n",
    "    return ds_stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect the number of CPUs\n",
    "ncpus=round(get_cpu_quota())\n",
    "print('ncpus = '+str(ncpus))\n",
    "\n",
    "# collect training data\n",
    "column_names, model_input = collect_training_data(\n",
    "    gdf=training_data, # replace with gdf=training_data if you are extracting all the training data\n",
    "    dc_query=query,\n",
    "    ncpus=ncpus,\n",
    "    field=class_attr,\n",
    "    zonal_stats=zonal_stats,\n",
    "    feature_func=feature_layers,\n",
    "    return_coords=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export training features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data to geopandas dataframe\n",
    "pd_training_features=pd.DataFrame(data=model_input,columns=column_names)\n",
    "#set the name and location of the output file\n",
    "output_file = \"Results/Mozambique_training_features.txt\"\n",
    "#Export files to disk\n",
    "pd_training_features.to_csv(output_file, header=True, index=None, sep=' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "01a9736267bf300689e8e016092cd01f0c67384dd94651ae6e139a291bc8cc97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d00a1c87",
   "metadata": {},
   "source": [
    "This notebook implements national land cover prediciton using the pre-trained random forest model generated from previous step. DE Africa's semiannual MADs products are included as features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fe68d4",
   "metadata": {},
   "source": [
    "### load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577d95f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import datacube\n",
    "import warnings\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from odc.io.cgroups import get_cpu_quota\n",
    "from odc.algo import xr_geomedian\n",
    "import xarray as xr\n",
    "from joblib import load\n",
    "from deafrica_tools.classification import predict_xr\n",
    "from deafrica_tools.dask import create_local_dask_cluster\n",
    "from deafrica_tools.datahandling import load_ard\n",
    "from deafrica_tools.bandindices import calculate_indices\n",
    "from deafrica_tools.plotting import display_map\n",
    "from datacube.utils.cog import write_cog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d02cdc2",
   "metadata": {},
   "source": [
    "### load data and set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2c43d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths and attributes\n",
    "lesotho_tiles_shp='Data/Mozambique_50km_sample_regions.geojson' # covering the entire country\n",
    "rf_model_path= 'Results/RF_model_using_filtered_15ptc_td_Mozambique_2021.joblib' # trained random forest model\n",
    "\n",
    "# class_name = 'LC_Class_I' # class label in integer format\n",
    "class_name = 'Class_I' # class label in integer format\n",
    "crs='epsg:32736' # # output crs: WGS84/UTM Zone 36S\n",
    "# fill_nan_value=-999 # value to replace nans in query results\n",
    "\n",
    "# load and get bounding boxes of tiles covering Mozambique\n",
    "lesotho_tiles=gpd.read_file(lesotho_tiles_shp).to_crs('epsg:4326')\n",
    "tile_bboxes=lesotho_tiles.bounds\n",
    "print('tile boundaries for Mozambique: \\n',tile_bboxes)\n",
    "\n",
    "# load trained classifier\n",
    "rf_models = load(rf_model_path).set_params(n_jobs=1)\n",
    "print('loaded random forest model:\\n',rf_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca066c1",
   "metadata": {},
   "source": [
    "### define feature layer function - same as extracting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f25a5f8-7a17-43cf-b69f-87b46e8939aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to feature layers\n",
    "def feature_layers(query):\n",
    "    measurements = ['blue','green','red','red_edge_1','red_edge_2', 'red_edge_3','nir_1','swir_1','swir_2']\n",
    "    measurements_MAD=['smad','emad','bcmad']\n",
    "\n",
    "    #connect to the datacube\n",
    "    dc = datacube.Datacube(app='feature_layers')\n",
    "\n",
    "    # load data\n",
    "    ds = load_ard(dc=dc,\n",
    "                  products=['s2_l2a'],\n",
    "                  measurements=measurements,\n",
    "                  group_by='solar_day',\n",
    "                  verbose=False,\n",
    "                  #mask_filters=[(\"opening\", 2)], # morphological opening by 2 pixels to remove small masked regions\n",
    "                  **query)\n",
    "\n",
    "    # calcualte NDVI\n",
    "#     ds_index = calculate_indices(ds,index=['NDVI'],drop=False,collection='s2')\n",
    "    ds_index = calculate_indices(ds,index=['NDVI'],drop=False,satellite_mission='s2')\n",
    "    # interpolate nodata using mean of previous and next observation\n",
    "#     ds=ds.interpolate_na(dim='time',method='linear',use_coordinate=False)\n",
    "\n",
    "    # calculate geomedians within each two-month interval\n",
    "    ds_geomedian=ds_index.resample(time='2MS').map(xr_geomedian)\n",
    "\n",
    "    # stack multi-temporal measurements and rename them\n",
    "    n_time=ds_geomedian.dims['time']\n",
    "    list_measurements=list(ds_geomedian.keys())\n",
    "    list_stack_measures=[]\n",
    "#     ds_stacked=None\n",
    "    for j in range(len(list_measurements)):\n",
    "        for k in range(n_time):\n",
    "            variable_name=list_measurements[j]+'_'+str(k)\n",
    "            measure_single=ds_geomedian[list_measurements[j]].isel(time=k).rename(variable_name)\n",
    "            list_stack_measures.append(measure_single)\n",
    "    ds_stacked=xr.merge(list_stack_measures,compat='override')\n",
    "\n",
    "    # load semiannual MADs\n",
    "    ds_mads=dc.load(product='gm_s2_semiannual',\n",
    "                    measurements=measurements_MAD,\n",
    "                    **query\n",
    "                   )\n",
    "    # stack multi-temporal measurements and rename them\n",
    "    n_time=ds_mads.dims['time']\n",
    "    list_measurements=list(ds_mads.keys())\n",
    "    for j in range(len(list_measurements)):\n",
    "        for k in range(n_time):\n",
    "            variable_name=list_measurements[j]+'_'+str(k)\n",
    "            measure_single=ds_mads[list_measurements[j]].isel(time=k).rename(variable_name)\n",
    "            ds_stacked=xr.merge([ds_stacked,measure_single],compat='override')\n",
    "    return ds_stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0f9fd4",
   "metadata": {},
   "source": [
    "### set up dask cluster for parallel processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5478a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a dask cluster\n",
    "create_local_dask_cluster(n_workers=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff544e3",
   "metadata": {},
   "source": [
    "### run prediction for all tiles and export geotiffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d782ae8b-bcc8-4b3e-8e67-2fa2f910daef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# iterate through each tile\n",
    "for i in range(len(tile_bboxes)):\n",
    "    minx,miny,maxx,maxy=tile_bboxes.iloc[i]\n",
    "    print('bounding box for tile ',i,': minx: ',minx,'miny: ',miny,'maxx: ',maxx,'maxy: ',maxy)\n",
    "\n",
    "    # load Sentinel-2 data\n",
    "    query = {\n",
    "        'x': (minx,maxx),\n",
    "        'y': (miny,maxy),\n",
    "        'time': ('2021-01', '2021-12'),\n",
    "#         'measurements': measurements,\n",
    "        'resolution': (-10, 10),\n",
    "        'crs':'epsg:4326',\n",
    "        'output_crs':crs,\n",
    "#         'dask_chunks' : {'x':-1, 'y':-1}\n",
    "        'dask_chunks' : {'x':2000, 'y':2000} # change this based on your tile size and sandbox instance\n",
    "    }\n",
    "\n",
    "    # calculate features\n",
    "    all_data = feature_layers(query) # making sure feature order is the same to training data\n",
    "    print('stacked Sentinel-2 dataset:\\n',all_data)\n",
    "\n",
    "    # timing how long it takes for the prediction\n",
    "    start_time = time.time()\n",
    "    predicted = predict_xr(rf_models,all_data,persist=False,clean=True).compute() # predict classes of all data using the RF model\n",
    "    print(\"%s seconds spent on predicting\" % (time.time() - start_time))\n",
    "\n",
    "    # write final prediction as cog file\n",
    "    print('writing cog file...')\n",
    "    outname_prediction='Results/Land_cover_prediction_15pct_td_Mozambique_50km_sample_region_'+str(i)+'.tif'\n",
    "    write_cog(predicted.Predictions, outname_prediction, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44df0cc2",
   "metadata": {},
   "source": [
    "### merge all tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc66bf69-1e02-4fc4-b10b-454f58bca40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "! gdal_merge.py -o Results/Land_cover_prediction_15pct_td_Mozambique_50km_sample_regions_mosaic.tif -co COMPRESS=Deflate -ot Byte Results/Land_cover_prediction_15pct_td_Mozambique_50km_sample_region_*.tif"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('geoenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 05:37:49) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "01a9736267bf300689e8e016092cd01f0c67384dd94651ae6e139a291bc8cc97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

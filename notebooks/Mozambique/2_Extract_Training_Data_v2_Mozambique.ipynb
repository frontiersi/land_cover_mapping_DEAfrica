{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bed71faf-13df-4e20-a384-a115d19e8baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ncpus = 31\n",
      "Training points in 2016:\n",
      "       LC_Class_I                         geometry\n",
      "0              3   POINT (225040.711 8330067.212)\n",
      "1              3   POINT (232906.211 8289456.399)\n",
      "2              3   POINT (264976.866 8243769.646)\n",
      "3              3   POINT (265932.457 8310425.297)\n",
      "4              5   POINT (259119.061 8241013.601)\n",
      "...          ...                              ...\n",
      "2494           5  POINT (1293515.402 8572615.673)\n",
      "2495           5  POINT (1298558.374 8598529.543)\n",
      "2496           3  POINT (1285206.553 8469601.675)\n",
      "2497           5  POINT (1316834.224 8283879.633)\n",
      "2498           5  POINT (1284216.688 8260744.431)\n",
      "\n",
      "[2499 rows x 2 columns]\n",
      "Collecting training data in parallel mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4945ac497b13445699c7c2d6514cc336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2499 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n",
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of possible fails after run 1 = 0.0 %\n",
      "Removed 0 rows wth NaNs &/or Infs\n",
      "Output shape:  (2499, 69)\n",
      "Number of training data after removing Nans and Infs:  2499\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import datacube\n",
    "import warnings\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from odc.io.cgroups import get_cpu_quota\n",
    "from odc.algo import xr_geomedian\n",
    "from deafrica_tools.datahandling import load_ard\n",
    "from deafrica_tools.bandindices import calculate_indices\n",
    "from deafrica_tools.classification import collect_training_data\n",
    "\n",
    "ncpus=round(get_cpu_quota())\n",
    "print('ncpus = '+str(ncpus))\n",
    "\n",
    "# file paths and attributes\n",
    "traning_points_path = 'Data/trainning_samples_FNDS_II_SOM_2016.geojson'\n",
    "class_name = 'LC_Class_I' # class label in integer format\n",
    "crs='epsg:32736' # WGS84/UTM Zone 36S\n",
    "zonal_stats = None\n",
    "\n",
    "training_points_2016= gpd.read_file(traning_points_path).to_crs(crs) # read training points as geopandas dataframe\n",
    "training_points_2016=training_points_2016[[class_name,'geometry']] # select attributes\n",
    "print('Training points in 2016:\\n',training_points_2016)\n",
    "\n",
    "measurements = ['blue','green','red','red_edge_1','red_edge_2', 'red_edge_3','nir_1','nir_2','swir_1','swir_2']\n",
    "query = {\n",
    "    'time': ('2017-01', '2017-12'),\n",
    "    'measurements': measurements,\n",
    "    'output_crs': crs,\n",
    "    'resolution': (-10, 10)\n",
    "}\n",
    "# define a function to feature layers\n",
    "def feature_layers(query): \n",
    "    #connect to the datacube\n",
    "    dc = datacube.Datacube(app='feature_layers')\n",
    "    ds = load_ard(dc=dc,\n",
    "                  products=['s2_l2a'],\n",
    "                  group_by='solar_day',\n",
    "                  verbose=False,\n",
    "#                   mask_filters=[(\"opening\", 2)], # morphological opening by 2 pixels to remove small masked regions\n",
    "                  **query)\n",
    "    ds = calculate_indices(ds,\n",
    "                           index=['NDVI'],\n",
    "                           drop=False,\n",
    "                           satellite_mission='s2')\n",
    "    # interpolate nodata using mean of previous and next observation\n",
    "    ds=ds.interpolate_na(dim='time',method='linear',use_coordinate=False,fill_value='extrapolate')\n",
    "#     ds=ds.interpolate_na(dim='time',method='linear',use_coordinate=False)\n",
    "    # calculate geomedians within each two-month interval\n",
    "    ds=ds.resample(time='2MS').map(xr_geomedian)\n",
    "    # replace nan with a value so that the collect_training_data function will work\n",
    "#     ds=ds.fillna(fill_nan_value)\n",
    "    # stack multi-temporal measurements and rename them\n",
    "    n_time=ds.dims['time']\n",
    "    list_measurements=list(ds.keys())\n",
    "    ds_stacked=None\n",
    "    for j in range(len(list_measurements)):\n",
    "        for k in range(n_time):\n",
    "            variable_name=list_measurements[j]+'_'+str(k)\n",
    "            # print ('Stacking band ',list_measurements[j],' at time ',k)\n",
    "            measure_single=ds[list_measurements[j]].isel(time=k).rename(variable_name)\n",
    "            if ds_stacked is None:\n",
    "                ds_stacked=measure_single\n",
    "            else:\n",
    "                ds_stacked=xr.merge([ds_stacked,measure_single],compat='override')\n",
    "    return ds_stacked\n",
    "\n",
    "column_names, model_input = collect_training_data(gdf=training_points_2016,\n",
    "                                                  dc_query=query,\n",
    "                                                  ncpus=30,\n",
    "                                                  field=class_name,\n",
    "                                                  zonal_stats=zonal_stats,\n",
    "                                                  feature_func=feature_layers,\n",
    "                                                  return_coords=True)\n",
    "print('Number of training data after removing Nans and Infs: ',model_input.shape[0])\n",
    "training_data_2016=pd.DataFrame(data=model_input,columns=column_names)\n",
    "# export the filtered training data as txt file\n",
    "output_file = \"Results/Mozambique_landcover_td2017.txt\"\n",
    "training_data_2016.to_csv(output_file, header=True, index=None, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b4e45a-3a9f-456d-90fc-d1a4ad6436e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
